# 操作系统考点梳理

## 待归档

习题：https://github.com/chyyuu/os_course_exercises

习题+解答：https://chyyuu.gitbooks.io/os_course_exercises/content/all/04-2-quiz.html

习题2：https://blog.csdn.net/yuanren201/article/details/106951328

## 一、操作系统基本概念

### 操作系统的特征

| 基本特征 |                                                              |
| -------- | ------------------------------------------------------------ |
| 并发     | 通过分时实现。对于单处理机来说，宏观上程序并发，微观上程序交替执行。 |
| 共享     | 1. 互斥共享（临界资源/独占资源，如打印机、磁带） 2. 同时访问（一段时间内允许多个进程对资源进行访问） |
| 虚拟     | 1. 虚拟处理器（多道程序并发，感觉上有多个处理器）—— 时分复用 2. 虚拟存储器（逻辑上扩充存储器用量）—— 空分复用 |
| 异步     | 服务的完成时间不确定，也可能失败                             |

### 操作系统的发展

单用户 $\rightarrow$ 批处理 $\rightarrow$ 多道 $\rightarrow$ 分时 $\rightarrow$ 个人电脑 $\rightarrow$ 分布式 $\rightarrow$ AIot分布式多设备

> (2009计算机统考)单处理器系统中，可并行执行或工作的对象是（ ）
>
> 1)进程与进程
>
> 2)处理器与设备
>
> 3)处理器与通道
>
> 4)设备与设备
>
> A 1) 2) 3)
>
> B 1) 2) 4)
>
> C 1) 3) 4)
>
> D 2) 3) 4)
>
> *答案：D*
>
> *解析：*同一时刻单个处理器只能执行一个进程

### 操作系统的结构

简单结构 $\rightarrow$ 单体分层结构 $\rightarrow$ 微内核（灵活、安全，但是性能差） $\rightarrow$ 外核结构（让程序去决定如何处理操作系统的物理资源，保护与控制分离） $\rightarrow$ 虚拟机结构（每个虚拟机都是一个原始计算机系统的有效副本，并能完成所有的处理器指令）

## 二、从OS角度看计算机系统

### 隔离

运行的程序通常都是隔离的单元

目的：防止破坏、监视、恶意进程

主要的隔离方法：

1. 地址空间：仅能*寻址*自己的地址空间
2. 特权模式：应用程序不能执行内核模式的*特权*操作（程序状态字寄存器psw，其中一个二进制位用来区分当前处于用户态还是内核态）

### 中断机制

中断指令是异步发生的

Timer：稳定定时产生中断，防止应用程序死占着CPU不放，同时让OS Kernel能周期性地进行资源管理

### RISC-V

更好的特权架构：U、S、H、M四种模式

设置CSR（控制状态寄存器）实现隔离

同样也有基于地址空间、特权模式的隔离手段

Timer：高特权模式下的软件能周期性地获得CPU的控制权，还能授权低特权模式软件处理中断

## 三、中断、异常、系统调用

### 系统启动

<img src="image\os19.png" alt="image-20220929170134828" style="zoom:80%;" />

> BIOS为什么不直接加载操作系统内核呢？
>
> 这其实取决于BIOS的能力问题，因为刚开始对BIOS的设计，它完成的功能就只是能加载一个扇区。
>
> 而操作系统的代码容量是大于512字节的。让BIOS去加载一个庞大的操作系统难度是很大的，倒不如让其只加载一个扇区，让扇区中的代码完成后续的加载工作，扇区中的代码称为bootloader。

<img src="image\os20.png" alt="image-20220929170320913" style="zoom:80%;" />

### 中断、异常、系统调用

|          | 定义                                                         | 源头                                                     | 响应方式   | 处理机制                                       |
| -------- | ------------------------------------------------------------ | -------------------------------------------------------- | ---------- | ---------------------------------------------- |
| 中断     | 来自*硬件设备*的处理请求                                     | 外设                                                     | 异步       | 持续，对用户应用程序透明                       |
| 异常     | 非法指令或其他原因导致当前*指令执行失败*（如除零、内存出错）后的处理请求 | 应用程序意想不到的行为（执行内核代码时也有可能产生异常） | 同步       | 杀死或重新执行出错的的应用程序指令             |
| 系统调用 | 应用程序*主动*向操作系统发出的服务请求                       | 应用程序主动请求                                         | 异步或同步 | 等待或持续（第一次系统调用时需要建立内核堆栈） |

| 中断处理机制 |                                                              |
| ------------ | ------------------------------------------------------------ |
| 硬件处理     | 在CPU初始化时设置中断使能标志，依据内部或外部事件设置中断标志，依据中断向量调用相应中断服务例程 |
| 软件处理     | 现场保存（CPU+编译器），中断服务处理（服务例程），清除中断标记（服务例程），现场恢复（CPU+编译器） |

中断嵌套：

* 硬件中断服务例程可被打断
* 异常服务例程可被打断
* 异常服务例程可嵌套

> (2012统考)下列选项中，不可能在用户态发生的是（ ）
>
> A 系统调用
>
> B 外部中断
>
> C 进程切换
>
> D 缺页
>
> *答案：C*
>
> *解析：*系统调用由用户态发出，进入内核态执行；外部中断随时有可能发生；应用程序执行时有可能发生缺页；进程切换完全由内核控制
>
> 
>
> (2012统考)中断处理和子程序调用都需要压栈以保护现场。中断处理一定会保存而子程序调用不需要保存其内容的是（ ）
>
> A 程序计数器
>
> B 程序状态字寄存器
>
> C 通用数据寄存器
>
> D 通用地址寄存器
>
> *答案：B*
>
> *解析：*程序状态字寄存器psw用于记录当前处理器的状态和控制指令的执行顺序，并保留与运行程序相关的各种信息，主要用于实现程序状态的保存和恢复。因此中断需要保存psw。而子程序调用在进程内部执行，不会更改psw。
>
> 
>
> 用户程序通过__向操作系统提出访问外部设备的请求（）
>
> A I/O指令
>
> B 系统调用
>
> C 中断
>
> D 创建新的进程
>
> *答案：B*
>
> 
>
> (西北工业大学)CPU执行操作系统代码的时候称为处理机处于（ ）
>
> A 自由态
>
> B 目态
>
> C 管态
>
> D 就绪态
>
> *答案：C*
>
> 
>
> (2013统考)下列选项中，会导致用户进程从用户态切换到内核态的操作是（ ） 1）整数除以0 2）sin()函数调用 3）read系统调用
>
> A 1、2
>
> B 1、3
>
> C 2、3
>
> D 1、2、3
>
> *答案：B*

### uCore系统调用

![image-20220929171220112](image\os21.png)

> 1. 用户态int进入到内核之后，这实际上是一个软中断，会进入到alltraps中，在这里获取到中断所需要的相关信息组成的数据结构。
>
> 2. T_SYSCALL是系统调用对应的中断向量
>
> 3. eax即系统调用编号，从而知道调用的是什么功能
>
> 4. 从堆栈中获取参数
>
> 5. 从用户态进入内核态，实现读取文件
>
> 6. 将读到内容的长度返回给用户态

## 四、内存管理

### 内存的存储结构

硬件（CPU $\rightarrow$ L1缓存 $\rightarrow$ L2缓存） $\overset{高速缓存未命中}\rightarrow$ 操作系统（内存 $\overset{缺页}\rightarrow$ 外存（虚拟内存））

操作系统的内存管理目标
* 抽象：逻辑地址空间
* 保护：独立地址空间
* 共享：访问相同内存（指的是都需要使用操作系统内核）
* 虚拟化：更大的地址空间

操作系统的内存管理方式
* 重定位、分段、分页、虚拟存储

### 地址空间

逻辑地址生成：编译、汇编、链接（链接函数库）、程序加载（重定位）

生成时机：编译时（不允许加装软件）、加载时、执行时（虚拟存储的系统）

地址检查：偏移量是否越界，加上偏移量后的地址是否越界

操作系统建立了逻辑地址和物理地址的映射，但每一次逻辑地址和物理地址的转换则是由硬件完成

### 连续内存分配

给进程分配一块不小于指定大小的连续的物理内存区域 (整个进程独占一整块连续的区域)

内存碎片：不能利用的空闲内存

* 外碎片：两块分配单元之间未使用的内存
* 内碎片：分配单元内部未使用的内存

### 动态分区分配

当程序被加载执行时，分配一个进程指定大小可变的分区(块、内存块) 

分区的地址是连续的 

|            | 最先匹配策略（FF）                                           | 最佳匹配策略（BF）                                           | 最差匹配策略（WF）                                           |
| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 思路       | 使用*第一个*可用的空间比所需空间大的空闲块                   | 使用不小于所需空间的*最小*空闲分区                           | 使用不小于所需空间的*最大*空闲分区                           |
| 原理与实现 | 1. 空闲分区列表*按地址顺序排序* 2. 分配时，搜索一个合适的分区 3. 释放时，检查是否可与临近的空闲分区合并 | 1. 空闲分区列表*按大小顺序排序* 2. 分配时，搜索一个合适的分区 3. 释放时，检查是否可与临近的空闲分区合并 | 1. 空闲分区列表*按由大到小排序* 2. 分配时，选最大的分区 3. 释放时，检查是否可与临近的空闲分区合并，并调整空闲分区列表顺序 |
| 优点       | 1. 简单 2. 在高地址空间有大块的空闲分区                      | 1. 大部分分配的尺寸较小时，效果很好 2. 可避免大的空闲分区被拆分 | 1. 中等大小的分配较多时，效果最好 2. 避免出现太多的小碎片    |
| 缺点       | 1. 外部碎片 2. 分配大块时慢                                  | 1. 外部碎片 2. 释放分区较慢 3. 容易产生很多很小的碎片        | 1. 外部碎片 2. 释放分区较慢 3. 后期可能分配不到大块的空间    |

碎片整理：通过调整进程占用的分区位置来减少或避免分区碎片

|      | 碎片紧凑                                              | 分区对换                                                     |
| ---- | ----------------------------------------------------- | ------------------------------------------------------------ |
| 含义 | *移动*分配给进程的内存分区，以合并外部碎片            | *抢占并回收*处于等待状态的进程所占用的资源                   |
| 要求 | 需要各进程都支持动态重定位                            |                                                              |
| 问题 | 1. 什么时候开始移动？（在进程处于等待状态时） 2. 开销 | 1. 需要交换哪些程序 2. 早期时候，用对换区的方式实现多进程的交替运行，解决内存紧张问题，但是开销非常大（内存和外存之间速度差得很远） |

> 在使能分页机制的情况下，更合适的外碎片整理方法是()
>
> A 紧凑(compaction)
>
> B 分区对换(Swapping in/out)
>
> C 都不是
>
> *答案：A*
>
> *解析：*分页方式不会产生外碎片
>
> 
>
> 操作系统中可采用的内存管理方式包括()
>
> A 重定位(relocation)
>
> B 分段(segmentation
>
> C 分页(paging)
>
> D 段页式（segmentation+paging）
>
> *答案：ABCD*

### 伙伴系统

二维数组：【空闲块的大小，由小到大排成第一维】【相同大小的空闲块按照地址排序排成第二维】

整个可分配分区大小为 $2^U$，如果足够折一半，则将当前分区划分为两个大小为 $2^{U-1}$ 的空闲分区，直到 $2^{i-1}<s\leqslant 2^{i}$，则将整块空间分配给该进程

同时会产生*外部*碎片和*内部*碎片

![image-20220929172132019](image\os22.png)

> 释放B以后，对应的256K空闲区不会与旁边的64K空闲区合并，因为合并之后的大小就不是2的幂次了
>
> 释放C以后，对应的64K空闲区可以与旁边64K的空闲区合并成128K，合并完后是2的幂次，所以可以合并。释放E之后的情况同理

合并时需要两个相邻的空闲分区大小都是 $2^i$，低地址的空闲块起始地址为 $2^{i+1}$ 的倍数

> 描述伙伴系统(Buddy System)特征正确的是()
>
> A 多个小空闲空间可合并为大的空闲空间
>
> B 会产生外碎片
>
> C 会产生内碎片
>
> D 都不对
>
> *答案：ABC*

### SLAB分配器

分配非常小的内存块（如，远小于4K）

为每种使用的内核对象建立单独的缓冲区

两种状态：已分配、空闲

三类缓冲区队列：Full，Partial（优先从中分配），Empty

### 非连续内存分配

连续分配的缺点：

* 分配给程序的物理内存必须连续
* 存在外碎片和内碎片
* 内存分配的动态修改困难
* 内存利用率较低

非连续分配的设计目标

* 提高内存利用效率和管理灵活性
* 允许一个程序使用非连续的物理地址空间
* 允许共享代码与数据
* 支持动态加载和动态链接

#### 段式存储管理

![image-20220928163142665](image\os1.png)

![image-20220928163229532](image\os2.png)

段的概念：

* 访问方式和存储数据等属性相同的一段地址空间（各部分之间很少有跨越的访问，因此可以分离开）
* 对应一个连续的内存“块”
* 若干个段组成进程的逻辑地址空间

段的访问：

* （段号，段内偏移）

#### 页式存储管理

物理空间 $\rightarrow$ 页帧（帧号，帧内偏移）

逻辑地址 $\rightarrow$ 页面（页号，页内偏移）

帧与页的大小必须相同

逻辑地址页号连续，物理空间帧号不连续

帧（内存物理地址）：（f帧号，o帧内偏移），物理地址 $f\times 2^s+o$

> 假定 $16$ bit 的地址空间，$9$ bit ($512$ byte) 大小的页帧，物理地址表示$= (3,\, 6)$，计算其实际物理地址。
>
> *解答：*实际物理地址$=3\times 512 + 6 = 1542$

页（进程逻辑地址）：（p页号，o页内偏移），虚拟地址 $p\times 2^s+o$

页表：保存逻辑地址——物理地址映射关系

* 每个进程都有一个页表（页表基址寄存器）
* 每个页面对应一个页表项（帧号+页表项标志位（如“存在位”））

![image-20220928164459264](image\os3.png)

![image-20220928164944028](image\os4.png)

页表基址寄存器：指出页表的起始位置

标志位：

* 存在位：是否有一个物理帧与逻辑页号相对应。若有，存在位是1；否则是0。
* 修改位：对应的页面中的内容是否有修改
* 引用位：过去一段时间，是否有对页面的引用，是否访问过这个页面中的某一个存储单元

性能问题：

* 需要*两次访存*（页表项+数据）
* 页表可能非常大

解决方法：

* 缓存
* 间接访问

> 页表项标志位包括()
>
> A 存在位(resident bit)
>
> B 修改位(dirty bit)
>
> C 引用位(clock/reference bit)
>
> D 只读位(read only OR read/write bit)
>
> *答案：ABCD*

##### 快表（TLB）

* 缓存近期访问的页表项
* 使用*关联存储*实现，访问快速
* TLB命中：不需要访存即可获取到物理页号（*一次访存*）
* TLB未命中：更新对应的表项到TLB中（*两次访存*）

![image-20220928165016782](image\os5.png)

> 快表————利用缓存的机制来减少对内存的访问
>
> 多级页表————通过间接引用的方式来减少页表的长度

##### 多级页表

* 建立页表树
* 减少每级页表的长度

![image-20220928165132587](image\os6.png)

> 整个访问的次数是k+1
>
> 
>
> 每一个子页表的基址填在上一级页表的表项当中，即：
>
> 第一级页表中的表项是各第二级页表的基址
>
> 第二级页表中的表项是各第三级页表的基址
>
> 
>
> 第一级页表的基址存储在PTBR（页表基址寄存器,x86中为CR3）当中
>
> 
>
> 设p1段有$i$位，设p2段有$j$位，设p3段有$k$位：
>
> 第一级页表的表项数为$2^i$个
>
> 每个第二级页表的表项数为$2^j$个
>
> 每个第三级页表的表项数为$2^k$个
>
> 
>
> 具体的访问过程：
>
> p1段作为第一级页表的偏移，找到对应的第二级页表的基址
>
> p2段作为第二级页表的偏移，找到对应的第三级页表的基址
>
> p3段作为第三级页表的偏移，找到与逻辑地址对应的物理页面的基址

* 建立多级页表的目的在于建立索引，*不必浪费主存空间去储存无用的页表项*，也不用盲目式地查询页表项
* 如果说所有页表项对应的地址空间都存在，多级页表并不能节省空间。但实际上我们并不会用到整个的地址空间，故而可以通过页表项的存在位，把不存在的给省掉

##### 大地址空间问题

对于大地址空间（64-bits）系统，多级页表变得繁琐：页表级数高，逻辑（虚拟）地址空间增长速度快于物理地址空间

解决方案：页寄存器、反置页表

* 不让页表与逻辑地址空间的大小相对应
* 让页表与*物理地址空间*的大小相*对应*

页寄存器

* 每一个帧与一个页寄存器关联

![image-20220928170505526](image\os7.png)

> 注：占用页号————占用这一帧的逻辑页号

* 优点
  * 页表大小相对于物理内存而言很小
  * 页表大小与逻辑地址空间大小无关
* 缺点
  * 页表信息对调后，需要依据帧号找到页号
  * 在页寄存器中搜索逻辑地址中的页号

![image-20220928170953175](image\os8.png)

反置页表

![image-20220928171158720](image\os9.png)

反置页表和页寄存器做法的区别：反置页表把进程ID也考虑进来了

* 反置页表以页帧号排序

* 得到PTBR和Hash值相加所得的页表项后，还需要核对Hash之前的的进程ID和逻辑号与页表项中的进程ID和逻辑号是否一致，如果一致，说明就是要找的那一项，就可以得到相应的物理页号。如果不一样，即产生冲突。

![image-20220929162309850](image\os13.png)

> 这个例子就是产生了Hash冲突的情况：
>
> 一个逻辑地址加上它的进程ID做Hash，得到对应结果0x0，以0x0为index值到反置页表中去查找，找到的页表项中的进程ID与逻辑页号和原来的进程ID与逻辑页号不一致，即说明有Hash冲突。
>
> 根据next字段找到index值为0x18F1B的页表项，这个页表项中的进程ID和逻辑页号与原来的进程ID和逻辑地址一致，那么这一页表项的index值就是所要找的页帧号。再将该页帧号和页内偏移（offset）合在一起，就得到逻辑地址对应的的物理页号和页内偏移。
>
> 
>
> 到目前为止，有三种做法来缓解或者解决页表带来的麻烦：
>
> * 快表，它是通过缓存机制来减少对物理内存、对页表的访问
> * 多级页表，通过多级来减少页表的大小
> * 反置页表

> 可有效应对大地址空间可采用的页表手段是()
>
> A 多级页表
>
> B 反置页表
>
> C 页寄存器方案
>
> D 单级页表
>
> *答案：BC*

### 段页式存储管理

段式：内存保护方面有优势

页式：内存利用和优化转移到后备存储方面有优势

相结合——段页式存储管理：在段式存储管理的基础上，给每一段加上一级页表

![image-20220929141630627](image\os10.png)

* 逻辑地址=段号+页号+页内偏移，如果页表是多级页表，那么页号还可以继续划分成多级

* 段表项中有相应段的段长度和段基址

* 段表的基址从STBR获得，页表的基址从段表项中获得，页表项中有物理页帧号

> 非连续内存分配的几种做法：段式、页式和段页式
>
> 其共同点就是，分配给一个进程的内存块可以是不连续的
>
> 其区别是，分配块的大小有不同，段式分配的块很大，以一个段为单位；页式分配的块是很小的；段页式是把两种结合起来

![image-20220929141654093](image\os11.png)

> 描述段管理机制正确的是()
>
> A 段的*大小可以不一致*
>
> B 段*可以有重叠*
>
> C 段*可以有特权级*
>
> D 段与段之间是*可以不连续的*
>
> *答案：ABCD*

## 五、虚拟存储

| 三种应对内存不够用的方法 |                                                              |
| ------------------------ | ------------------------------------------------------------ |
| 覆盖技术                 | 应用程序手动把需要的指令和数据保存在内存中（一个程序不同模块之间，需要程序员参与——给出模块间的覆盖结构） |
| 交换技术                 | 操作系统自动把暂时不能执行的程序保存到外存中（多个程序之间，交换的单位是一个进程的*整个地址空间*） |
| 虚拟存储                 | 在有限容量的内存中，以页为单位自动装入更多更大的程序（相较于交换，虚拟存储可以选择性地把进程的*一部分地址空间*换出去） |

局部性原理：时间局部性、空间局部性、分支局部性（执行两次相同的分支跳转，可能是去往同一个内存地址）

![image-20220929152700730](image\os12.png)

### 虚拟页式存储管理

在页式存储管理基础上，增加请求调页和页面置换

<img src="image\os14.png" alt="image-20220929163320322" style="zoom:50%;" />

标志位：

* 驻留位：该页是否在内存

> 虚拟页式存储的地址转换与页式存储的地址转换机制完全一样，但是虚拟页式存储会在页表项中多一个标志位（驻留位），表征这一页是否在物理内存当中。如果不在，执行到查询页表项就会产生缺页异常，这个缺页异常就会由操作系统来接管。操作系统会将这一页调入内存，将该标志位置为有效。

* 修改位：在内存中的该页是否被修改过
* 访问位：该页是否被访问过（读或写）
* 保护位：只读、可写等

![image-20220929164216472](image\os15.png)

> 32位逻辑地址：12位的页内偏移，2个10位的二级页表项
>
> 32位物理地址：12位的页内偏移，20位的物理页帧号
>
> 一级页表的基址存储在CR3寄存器中
>
> 一个页表项占4字节，一页4KB，即一页中有1024个页表项。其实从Dir为10位也可以看出一级页表有1024个页表项；从Table为10位可以看出二级页表有1024个页表项。Dir字段的值是一级页表的index（或offset），Table字段的值是二级页表的index（或offset）

![image-20220929164439559](image\os16.png)

> U（用户态标志）：表征这一页表项是否可以在用户态访问，还是说只能是在内核态访问。
>
> AVL(保留位)：为了后续的改动留有空间。
>
> CD（Cache Disabled）：是否使用Cache，对于读写 I/O端口，实时性要求高，就不使能Cache了。

缺页异常的处理

![image-20220929165503994](image\os17.png)

外存管理

![image-20220929165752141](image\os18.png)

> 未被映射的页的两种保存方法：
>
> 1.设置一个分区，称为对换区（如Linux、Unix等）
>
> 2.用一个文件来保存，采用特殊的格式存储未被映射的页面
>
> 
>
> 上面PPT就是说代码段和动态加载的共享库程序段在外存中都各有存储的地方，不放到交换空间中；其它段则会放到交换空间中

虚拟页式存储管理的性能

* $有效存储访问时间EAT=访存时间\times(1-缺页率p)+缺页异常处理时间\times缺页率p\times(1+页修改概率q)$

## 六、页面置换算法

### 页面锁定

必须常驻内存的逻辑页面、操作系统的关键部分、要求响应速度的代码和数据

页表中的锁定标志位：实现页面锁定。实现了页面锁定的页面不参与页面置换，即不能把这些页放到外存当中

### 页面置换算法的分类

| 算法类型         | 置换页面的选择范围                                           | 相关算法                                                     |
| ---------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 局部页面置换算法 | 当前进程占用的物理页面（置换过程中每个进程各自所分配的页面总数不会变化） | 最优算法、先进先出算法、最近最久未使用算法、*时钟算法、最不常用算法（两者都是对最近最久未使用算法的近似）* |
| 全局页面置换算法 | 所有可换出的物理页面                                         | 工作集算法、缺页率算法                                       |

### 最优置换算法

置换**在未来最长时间不访问的页面**

* 理想，作为置换算法的性能评价依据

![image-20220930133950736](image\os23.png)

### 先进先出算法

置换**在内存驻留时间最长的页面**

* 实现简单，性能较差（Belady）

![image-20220930134144439](image\os24.png)

### 最近最久未使用算法

置换**最长时间未被引用的页面**

* 最优算法的近似

LRU算法的可能实现方法：页面链表、活动页面栈

![image-20220930134522479](image\os26.png)

> 这两种实现方法的开销主要不在置换的时候，而是在平时访问的时候

![image-20220930134250604](image\os25.png)

![image-20220930134732537](image\os27.png)

### 时钟置换算法

在页表项中增加**访问位**，各页面组织成**环形链表**，**指针**指向最先调入的页面

> 所谓的折中是在于它对过去的访问情况有考虑，做了统计，所以它不像FIFO完全不考虑。但是它又不像LRU考虑的很详细，只是说在过去一段时间，没有访问的就做置换。如果这段时间所有的页面都没有访问，时钟置换算法就退化成FIFO算法了。

![image-20220930135001841](image\os28.png)

![image-20220930135247782](image\os29.png)

> 注意：
>
> 刚开始指针指向*最先调入的页面*
>
> 发生换页后，指针停留的位置在*换页后的下一个位置*
>
> 如果题目直接给的是访问序列，内存中没有任何已有页，那么这些访问的页*第一次访问都算是缺页*
>
> 还需注意对于不缺页即在内存中的页，*访问过后要标记为1*

> *例6.1* 物理页帧数量为4，虚拟页访问序列为 0,3,2,0,1,3,4,3,1,0,3,2,1,3,4，请问采用CLOCK置换算法（用1个bit表示存在时间）的缺页次数为（）
>
> A 8
>
> B 9
>
> C 10
>
> D 11
>
> *答案：B*
>
> *解析：*注意每次缺页后，指针指向的是换页后的下一个位置
>
> <img src="https://cdn.nlark.com/yuque/0/2020/jpeg/1458680/1603039137347-5e3d9cf5-dc01-42c7-9afc-7e838f8d9b02.jpeg?x-oss-process=image%2Fresize%2Cw_1189%2Climit_0" alt="1603039080(1).jpg" style="zoom:50%;" />

#### 改进的时钟置换算法

减少修改页的缺页处理开销

![image-20220930140559862](image\os30.png)

> 读的时候只改访问位；写的时候既改访问位，也要改修改位。
>
> 访问位为0，修改位为1——前一轮转过的时候，修改过的地方还没写到外存中去，将修改位清0，这时会启动往外存中写的操作
>
> 改进的Clock算法在缺页中断产生时，对于修改过的页面，处理速度会比原来快，原因在于：延迟替换之后，后续有可能改动的页面的写出操作可能会被合并

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1601627351856-249218c6-4fea-4326-ae15-3e0ee8b8d090.png" alt="img" style="zoom:50%;" />

### 最不常用算法

置换**访问次数最少的页面**

  * 算法开销大（内存-硬盘之间的置换可以使用）
  * 开始时频繁使用，但以后不使用的页面很难置换
    * 解决方法：计数定期右移

![image-20220930144124821](image\os31.png)




### Belady现象

分配的物理页面数增加，缺页次数反而升高

原因：FIFO等算法的置换特征与进程访问内存的动态特征矛盾

哪些算法会Belady？可以证明，堆栈类算法不会出现Belady异常

* 产生Belady的算法：FIFO，CLOCK，改进CLOCK，不恢复计数的LFU

* 不产生Belady算法：OPT，LRU，恢复计数的LFU

### LRU、FIFO、Clock的比较

LRU算法性能好、系统开销大

FIFO系统开销小，但会产生Belady

Clock算法是它们的折中

* 对于未被访问的页面，CLock算法的表现和LRU一样好；对于被访问过的页面，Clock算法则不能准确记录它们的访问顺序（比FIFO好，比LRU差）

### 全局置换算法

为进程分配可变数目的物理页面

* 进程在不同阶段的内存需求是变化的
* 分配给进程的内存也需要在不同阶段有所变化

CPU利用率与并发进程数存在相互促进和制约的关系

* 进程数少时，提高并发进程数，可提高CPU利用率
* 并发进程导致内存访问增加
* 并发进程的内存访问会降低访存的局部性
* 局部性特征的下降会导致缺页率的上升和CPU利用率的下降

### 工作集置换算法

工作集：一个进程*当前正在使用*的逻辑页面集合（在一个定长的工作集窗口$\Delta$内所有访问页面组成的集合，）

常驻集：在当前时刻，进程*实际驻留在内存当中*的页面集合

* 工作集 $\subset$ 常驻集时，缺页较少
* 工作集发生剧烈变动（过渡）时，缺页较多
* 常驻集达到一定数目后，缺页率也不会明显下降

![image-20220930145828852](image\os32.png)

![image-20220930145850945](image\os33.png)

> 工作集置换算法为了维护访存链表，开销也是很大的
>
> 
>
> 其实如果把这个例子当作题来做，可以这样下手：
>
> 把$t=-2，t=-1$的逻辑页面状态也加到表中最前面，因为$\tau=4$，访问一次某个页面，就相当于给这个页面续4个点的命（往后点四个点）。如果随着时间推移，没有及时续命，点没了，就会将这个页面节点从链表中删去，将对应页面从内存中调出到外存
>
> <img src="https://steamuserimages-a.akamaihd.net/ugc/468764907929269622/4D8DF8B13B285C72E1D007C752E65C0B1EE61799/?imw=1024&imh=576&ima=fit&impolicy=Letterbox&imcolor=%23000000&letterbox=true" alt="img" style="zoom: 67%;" />

### 缺页率置换算法

$$缺页率=\dfrac{缺页次数}{内存访问次数},\,或=\dfrac{1}{缺页平均时间间隔}$$

![image-20220930151726930](image\os34.png)

* 访存时，设置运用位标志
* 缺页时，计算从上次缺页时间到现在的时间间隔。
  * 若时间间隔大于既定的T（表明缺页率比较低），则置换所有在此期间所有未被引用的页
  * 若不大于T（表明缺页率比较高（或正好）），则将缺失页增加到工作集中


![image-20220930151921287](image\os35.png)

> 和工作集置换算法的区别：工作集算法是在*每次访问页面的时候*都要判断淘汰哪一个，而缺页率算法则只需要在*缺页中断时*才完成置换工作，降低了开销

### 抖动

进程物理页面太少，不能包含工作集，造成大量缺页，频繁置换

* 随着驻留内存的进程数目增加，分给每个进程的物理页面数不断减少，缺页率不断上升

需要在并发水平和缺页率之间达成平衡

* 通过调节并发进程数（MPL）来进行系统负载控制

![image-20220930152324255](image\os36.png)

> 局部置换算法可以在一定范围内改善抖动问题
>
> 
>
> 解释：
>
> 控制每个工作集的大小，期望整个内存的总量是当前运行的各个进程的工作集的总和，即对应于图中的 $N_{max}$ 点。但是这个点在实际中是很难确定的，实际上，是期望系统工作在 $N_{I/O-BALANCE}$ 点和 $N_{max}$ 点区域之间，在这段区间中的点就可谓是负载均衡的平衡点了
>
> $N_{I/O-BALANCE}$ 点之前意味着$MTBF>PFST$，显然在 $MTBF$ 略大于 $PFST$ 的时候，系统处于均衡繁忙的状态，工作效率是较高的

### 面向缓存的页置换算法

* 大量的IO访问，导致用来缓存IO的空间不够用，同样会发生抖动

* LRU算法

  当存在“热点”数据时，LRU的效率很好

  但偶发性、周期性的批量操作会导致LRU命中率急剧下降

  且会造成缓存污染（不常用的数据被放入缓存，导致常用数据被替换出去）

* LRU为什么会失效：只考虑时间，没有考虑使用频率

* LRU+LFU=FBR（访问频率置换算法）

  新区域——中间区域——旧区域

  旧区域中引用次数最小的缓存块被置换

  中间区域可以作为一种过渡

  三个区域应当如何划分？

* 更为简洁的LRU+LFU：LRU-K（最近被访问过K次）

  实际应用中，LRU-2是综合最优的选择。LRU-3或更大的K值虽然命中率会更高，但在访问模式发生变化时，需要大量的数据访问才能将历史热点访问记录清除掉

* LRU队列需要排队，如何改进：2Q

  将LRU-2算法中的访问历史队列（不是缓存数据的队列）改为一个FIFO缓存队列，即有两个缓存队列（FIFO和LRU）

  第一次访问时放入FIFO，第二次访问时，则将其从FIFO移入LRU

* 2Q计算开销低于LRU-2，但要维护两个队列，如何改进：LIRS（Low Inter-reference Recency Set）

  分低IRR（LIR）和高IRR（HIR）块

  LIR一般常驻cache，而HIR则会较快地被替换出去

  如果块的IRR值很高，那么它的下一次IRR值也会很高，因此要替换掉

## 七、进程和线程

### 进程

具有**独立功能**的程序在一个**数据集合**上的一次**动态执行**过程

进程控制块
* 进程控制块的组织：同一状态的进程归入一个链表/索引表

进程的生命周期

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1602079169722-4aa87568-dd49-4a26-bf94-d8acfd6f053e.png?x-oss-process=image%2Fresize%2Cw_696%2Climit_0" alt="image.png" style="zoom:80%;" />

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1602079270960-52e84503-4a4e-415a-b2d7-20b13d14476f.png?x-oss-process=image%2Fresize%2Cw_661%2Climit_0" alt="image.png" style="zoom:80%;" />

三状态进程模型

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1602079886140-edf422cc-cfb3-44e5-a9b3-8e3b47bcec3b.png?x-oss-process=image%2Fresize%2Cw_825%2Climit_0" alt="image.png" style="zoom: 80%;" />

挂起进程模型

> 前面的进程状态模型主要讨论的是跟CPU相关的状态。但实际上进程的状态中，还有一类是跟存储相关，这种状态下进程的一部分存储是放在外存中的，与虚拟存储相关联，即挂起进程模型。

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1602080248597-7b2b9753-8814-4ebe-86d3-7d7d0421d8b2.png?x-oss-process=image%2Fresize%2Cw_662%2Climit_0" alt="image.png"  />

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1602080325949-63d7c6fa-0af1-4a67-b16f-67a9b275f712.png?x-oss-process=image%2Fresize%2Cw_687%2Climit_0" alt="image.png"  />

> 有高优先级进程等待，低优先级进程在内存中处于就绪状态。为了让高优先级等待进程进入内存之后有足够的空间，操作系统就把低优先级的就绪进程对换到外存当中，从而成为挂起就绪

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1602081227525-3e792c73-6805-4fbc-abb4-ff61d864015d.png?x-oss-process=image%2Fresize%2Cw_837%2Climit_0" alt="1602080756(1)_meitu_1.png" style="zoom: 80%;" />

> 操作系统来维护一组队列，表示系统中所有进程的当前状态，有关管理进程的描述正确的是（）
>
> A 就绪态进程维护在进程就绪队列中
>
> B 等待态进程维护在进程等待队列中
>
> C 运行态进程维护在进程运行队列中
>
> D zombie态进程不在任何队列中
>
> *答案：A B*
>
> *解析：*就绪队列、等待队列、僵尸队列

### 线程

进程的一部分，描述指令流执行状态。进程中*执行指令流*的最小单位，*CPU调度*的最小单位

* 一个进程可同时存在多个线程
* 各线程可并发（有多个指令指针）
* 各线程可共享内存和文件资源
* 一个线程崩溃，会导致其所属进程的所有线程崩溃

![image-20220930161340525](image\os38.png)

> 相比于单线程的进程，与*指令流相关*的东西就不放在进程中了，即*堆栈*——每个指令流有函数调用的时候，它必须有自己独立的堆栈。故多线程的进程将其从进程中剥离出来，作为线程的组成部分。若干个线程，各自有各自的堆栈，把相关的关于执行流状态的信息作为线程控制块。线程控制块从属于进程控制块
>
> 有多线程的进程，就有*多个指令指针*，*多个堆栈*和*多个CPU中的寄存器的现场保护*——现场保护是和执行流相关的

![image-20220930161730861](image\os39.png)

#### 用户线程

在用户空间里通过函数库的形式来支持线程的创建、删除和切换

* 用户线程可以更好地做针对应用的调度

![image-20220930162442453](image\os40.png)

> 在操作系统内核中，仍然只有进程控制块来描述处理机的调度情况，操作系统并不感知应用态有多线程的支持
>
> 而多线程的支持是用户的函数库支持的多线程，在应用程序内部，通过构造相应的线程控制块来控制一个进程内部多个线程的交替执行和同步

![image-20220930162459909](image\os41.png)

> 解释第一条：因为对于内核来讲，并不知道这个进程是多线程的，做不到一个线程堵塞的时候把另一个线程继续运行下去。要做到这一点的话，必须有内核的支持
>
> 解释第二条：操作系统没有办法让一个线程停下来，然后让这一个进程内部的另一个线程来运行，必须由当前运行的线程主动放弃，才可以做这种切换

#### 内核线程

由内核通过系统调用实现的线程机制，由内核完成线程的创建、管理和终止

> 用户线程的线程控制块是在用户态的，由用户的应用程序自己来维护
>
> 内核线程把线程控制块挪到内核态里来了
>
> 内核中，进程控制块中有指针指向它自己的相应的线程的线程控制块。所以线程的创建、切换和删除都是在内核中来进行的

![image-20220930162816218](image\os42.png)

> 进程的切换没有了，所有的切换都变成是线程的切换。（可能不太严谨）
>
> 原来通过函数库方式来实现同一个进程内部的线程切换的速度会快于用内核实现的同一个进程内的线程切换

#### 轻权进程

![image-20220930162924011](image\os43.png)

> 每一个轻权进程对应一个内核线程，每个轻权进程可以对应多个用户线程
>
> 永久绑定的线程相当于是在内核支持线程，因为在用户态跟它相对应的就只有一个线程
>
> 两个未绑定的轻权进程对应于上面三个未绑定的用户态线程。它们之间的切换可以由用户态来给出一些相应的策略，使得更好地提高应用的效率

#### 用户线程与内核线程对应关系

一对一：完全由内核线程来实现。对于用户态来说，*看到的就是内核线程*。用户线程和内核线程是一一对应的关系

多对一：内核中*一个进程只有一个线程*，即传统意义上的多进程系统。用户态可以实现自己的用户态线程

多对多：对应于轻权进程。而且在轻权进程中，这种*多对多的对应关系*可以在执行过程中*动态变化*

### 进程地址空间与熔断漏洞

侧信道攻击

熔断漏洞：虽然访问的地址空间非法，但可以利用另一段程序使用缓存读取到其中的数据

* 由乱序执行造成

内核页表隔离

## 八、进程控制

### 进程切换

![image-20221001130014779](image\os44.png)

![image-20221001130112869](image\os45.png)

> 三个队列：就绪队列、等待队列、僵尸队列（运行到了退出的状态）
>
> 僵尸进程：子进程结束，父进程还在调用它，故为僵尸
>
> 孤儿进程：父进程结束，子进程没有随之结束掉，故为孤儿

#### uCore的进程切换

![image-20221001130302688](image\os46.png)

> 第一类，进程的标识信息：执行的是哪一个可执行文件，进程ID，父进程
>
> 第二类，进程的状态信息：CPU中状态寄存器的相关信息，地址空间的起始地址，第一级页表的起始地址，进程的状态和是否允许调度
>
> 第三类，进程所占用的资源：占用的存储资源，所有分配给它的存储组织成相关的数据结构MM；占用的内核堆栈
>
> 第四类，用于保护现场：在中断和进程切换的时候，都需要保护现场，现场的内容要保存到进程控制块中
>
> 第五类，队列信息：相关的指针结构用于描述当前进程是在哪一个队列当中

![image-20221001130523215](image\os47.png)

> `mmap_list`：有哪些内存块，内存逻辑地址空间里头映射是在哪个地方，对应的地址空间是啥样的
>
> `pgdir`： 第一级页表的基址，地址空间的起始
>
> `map_count`：如果有共享的话，共享了几次
>
> `sm_priv`：如果有与外存之间的置换，置换相关的数据结构

![image-20221001130759008](image\os48.png)

> 双向链表，如果链表很长，检索的开销是非常大的。所以ucore中先加一级哈希队列，每一级队列中，哈希值相同的再组成自己相应的队列

![image-20221001130839047](image\os49.png)

> 修改进程状态：把前头一个改成就绪或者等待，把新的改成是运行状态

![image-20221001131245409](image\os50.png)

### 进程创建

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1602333411351-b76a8d66-d558-456e-b100-2b22359b7c9b.png?x-oss-process=image%2Fresize%2Cw_716%2Climit_0" alt="image.png" style="zoom:80%;" />

> 进程创建是操作系统提供给用户使用的一个系统调用，完成新进程的创建工作
>
> fork将一个进程复制成两个进程，这两个进程所执行的程序是一样的，但是它们的PID不同

![image-20221001131541350](image\os51.png)

> `int pid = fork()`执行完后系统中就有两个进程了，并且这两个进程的当前指令指针都指向fork完之后的这一行
>
> `if ( pid == 0 ) { exec… }` 只有子进程能执行，子进程通过执行exec被新程序重写。而父进程跳过，执行后边的代码



![image-20221001131720579](image\os52.png)

> 执行完`childPID = fork()`，进程从一个变成两个

![image-20221001132248696](image\os53.png)

> 在Linux程序中，fork会产生一个和父进程完全相同的子进程，但子进程在此后多会exec系统调用，出于效率考虑，linux中引入了“写时复制“技术，也就是只有进程空间的各段的内容要发生变化时，才会将父进程的内容复制一份给子进程

> 关于创建新进程的描述正确的是（）
>
> A fork() 创建子进程中，会复制父进程的所有变量和内存
>
> B 子进程的fork()返回0
>
> C 父进程的fork()在创建子进程成功后，返回子进程标识符
>
> D fork() 创建子进程中，会复制父进程的页表
>
> *答案：ABCD*

### 进程加载

![image-20221001132541547](image\os54.png)

> 系统中的第一个线程是在`proc_init()`中进行的，这个函数手工构造出一个进程控制块，然后把它放到就绪队列中，然后开始执行。它启动的第一个用户态程序就是`init_main()`。

> 关于进程加载执行的描述正确的是（）
>
> A 系统调用exec( )加载新程序取代当前运行进程
>
> B 系统调用exec( )允许进程“加载”一个完全不同的程序，并从main开始执行
>
> C exec调用成功时，它是相同的进程，但是运行了不同的程序
>
> D exec调用成功时，代码段、堆栈和堆(heap)等完全重写了
>
> *答案  ABCD*
>
> 注意A是对的

### 进程等待与退出

![1602335603(1).png](image\os55.png)

![image-20221001133014272](image\os56.png)

> 父进程会检查子进程是否存活，子进程也会检查父进程是否存活
>
> 子进程是执行exit的时候，检查父进程；父进程是在执行wait的时候检查子进程

![image-20221001133144053](image\os57.png)

> `fork()`导致一个新的进程创建
>
> 父进程执行`wait()`会导致父进程由运行状态进入等待状态
>
> `exit()`会导致当前进程由运行进入退出状态，同时子进程的`exit()`会导致由于`wait()`进入等待状态的父进程变成事件发生触发导致它进入就绪状态，以便于它能再进行执行的时候对子进程的返回的结果进行处理
>
> * 父进程等待子进程退出。当子进程执行exec的时候唤醒父进程，父进程执行时对子进程的退出做处理
>
> `exec()`是在执行过程当中的一种状态

## 九、处理机调度

### 传统调度策略

| 进程调度算法       | 特点                                         | 优点                                         | 缺点                                                         |                                                              |
| ------------------ | -------------------------------------------- | -------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| FCFS先来先服务     | 根据进程进入就绪状态的先后顺序排列           | 简单                                         | 1. 不公平 2. 平均等待时间波动较大 3. I/O资源和CPU资源的利用率较低 |                                                              |
| SPN短进程优先      | 选择就绪队列中执行时间最短的进程进入运行状态 | 具有最优平均周转时间                         | 1. 不公平，可能导致饥饿 2. 需要预知未来                      | 改进：SJF短作业优先；SRT短剩余时间优先                       |
| HRRN最高响应比优先 | 选择就绪队列中响应比R值最高的进程            | 避免无限期推迟，有利于短作业，又兼顾到长作业 |                                                              | $R=\dfrac{等待时间+执行时间}{等待时间}$，不可抢占            |
| RR时间片轮转       | 时间片结束时，按FCFS算法切换到下一个就绪进程 |                                              | 1. 额外的上下文切换 2. 公平，但大家都比较差                  | 时间片长度太小——产生大量上下文切换，影响系统吞吐量；太大——等待时间过长，极端情况退化成FCFS |
| MQ多级队列调度     | 就绪队列被划分为多个子列，执行不同的调度策略 |                                              |                                                              | 每个队列都得到一个确定能够进行调度其进程的CPU总时间          |
| MFQ多级反馈队列    | 进程可在不同队列间移动的MQ算法               | CPU密集型进程的优先级下降很快                |                                                              | CPU密集型进程的优先级会逐步降低，并且时间片会分得很大，切换的开销相对来说变小； |
| FSS公平共享调度    | FSS控制用户对系统资源的访问                  |                                              |                                                              |                                                              |

> MFQ：CPU密集型进程的优先级会逐步降低，并且时间片会分得很大，切换的开销相对来说变小；I/O密集型的进程会停留在高优先级上，因为它每一次计算的时间都很短，它的时间片没用完

![image-20221001142207235](image\os58.png)

> 进程1和进程2的处理过程是对称的、一致的
>
> 调度的时机就是在由内核态返回到用户态之前的时刻，这样既不影响中断的及时处理，又能让各个进程之间交替运行

![image-20221001142317769](image\os59.png)

> enqueue ：入队
>
> dequeue ：出队
>
> pick_next ：选择下一个进程
>
> proc_tick ：支持时钟中断

### 实时系统

<img src="image\os60.png" alt="image-20221001142450845" style="zoom:67%;" />

> 实时操作系统是*保证在一定时间限制内完成特定功能*的操作系统。
>
> 
>
> 静态优先级调度：静态是指事先把执行顺序排出来，然后照着排好的顺序调度，可以从理论上保证满足要求
>
> 动态优先级调度：执行的过程当中决定任务的执行顺序
>
> 
>
> 速率单调调度算法——静态优先级调度
>
> 最早截止时间优先算法——动态优先级调度

![image-20221001143621059](image\os61.png)

![image-20221001143640154](image\os62.png)

### 优先级反置

![image-20221001143840219](image\os63.png)

> 这个例子的意思就是说
>
> * T1占用资源L1，T2等着要用资源L1
> * T3在T1获得CPU资源之前进入了CPU进行处理，T1只好等着CPU资源，它所占用的资源也没有办法释放
> * 间接的，T2虽然优先级最高，也只能跟着等待CPU资源

解决方法

* 优先级继承
  * 占用资源的低优先级进程*继承*申请资源的高优先级进程的优先级
  * 只在占有资源的低优先级进程被阻塞时,才提高占有资源进程的优先级

* 优先级天花板协议
  * 占用资源进程的优先级和所有可能申请该资源的进程的*最高*优先级相同
  * 不管是否发生等待,都提升占用资源进程的优先级
  * 优先级高于系统中所有被锁定的资源的优先级上限，任务执行临界区时就不会被阻塞

> 在基于优先级的可抢占的调度机制中，当系统强制使高优先级任务等待低优先级任务时，会发生（）
>
> A 优先级反转
>
> B 优先级重置
>
> C 系统错误
>
> D 死循环
>
> *答案：A*

## 十、同步互斥

互斥：一个进程占用资源，其它进程不能使用

死锁：多个进程各占用部分资源，形成循环等待

饥饿：其他进程可能轮流占用资源，一个进程一直得不到资源

> 共享变量是指（）访问的变量
>
> A 只能被系统进程
>
> B 只能被多个进程互斥
>
> C 只能被用户进程
>
> D 可被多个进程
>
> *答案：D*

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1602829536274-b74316e6-d95b-4a01-bb23-8c882d20dc1d.png?x-oss-process=image%2Fresize%2Cw_796%2Climit_0" alt="image.png" style="zoom:80%;" />

![image.png](https://cdn.nlark.com/yuque/0/2020/png/1458680/1602829713209-90aaca5d-d14d-4ea1-a7f2-07ba5258bc65.png?x-oss-process=image%2Fresize%2Cw_598%2Climit_0)

> 忙则等待：假定进程Pi在其临界区内执行，其他任何进程将被排斥在自己的临界区之外
>
> 空闲则入：临界区虽没有进程执行，但有些进程需要进入临界区，不能无限期地延长下一个要进入临界区进程的等待时间
>
> 有限等待：在一个进程提出进入临界区的请求和该请求得到答复的时间内，其他进程进入临界区前的等待时间必须是有限的
>
> 让权等待：不能进入临界区的进程，应释放CPU（如转换到阻塞状态）

### 禁用硬件中断

![image-20221001151600974](image\os64.png)

> 通常情况下用一个宏来实现把当前的CPU的状态保存到存储单元当中，同时把中断禁止掉（如果不保存的话，等中断恢复之后，整个系统状态会发生变化）。然后进入临界区访问。访问结束之后，恢复系统的状态并且使能中断

![image-20221001151729265](image\os65.png)

> 禁用中断后，进程无法被停止，如果这时候正在执行的进程出了问题，会影响到整个系统

### 基于软件的同步方法

#### turn

不满足空闲则入

![image-20221001152223915](image\os66.png)

#### flag[2]

不满足忙则等待

![image-20221001152346852](image\os67.png)

#### flag[2]改

不满足空闲则如（而且这次造成了死锁）

![image-20221001152446284](image\os68.png)

#### Peterson算法

![image-20221001152513749](image\os69.png)

> 线程 i 中将 `turn` 设置为 j ，表示“如果 j 已经准备好了（ j 已经等在 `while` 循环处），那么就让 j 先进入临界区”。不过要是 j 还没准备好，即便 j 正好也刚刚把 `flag[j]` 标为了 1 ，随后 j 线程就会把 `turn` 改为 i，让线程 i 先进入临界区。
>
> 
>
> thread_j的进入区代码为：
>
> ```c
> flag [ j ] = true;
> turn = i;
> while ( flag [ i ] && turn == i );
> ```
>
> 退出区代码：
>
> ```c
> flag [ j ] = false;
> ```

#### N进程的软件方法

![image-20221001153320722](image\os70.png)

> 可以方便地扩展到多个线程

![image-20221001154241998](image\os71.png)

#### 评价

复杂：需要两个进程间的共享数据项

需要忙等待：浪费CPU时间

### 更高级的抽象方法

同步原语：中断禁用，原子操作指令等

更高级的编程抽象：锁、信号量，用硬件原语来构建

![image.png](https://cdn.nlark.com/yuque/0/2020/png/1458680/1602839436504-4eda9b13-4c52-44ad-ada4-060052f6eaba.png?x-oss-process=image%2Fresize%2Cw_585%2Climit_0)

![image.png](https://cdn.nlark.com/yuque/0/2020/png/1458680/1602839470439-a8e37d9c-635a-4753-8016-c0917722c556.png?x-oss-process=image%2Fresize%2Cw_628%2Climit_0)

> 解释：判断这个值是不是1，如果该值是1，返回True，保持该值不变；如果该值是0，返回False，将该值改写为1
>
> 原子操作不会被中断

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1602839489728-12a9a232-8227-4e61-b777-f8a6dd98ca6b.png" alt="image.png" style="zoom:67%;" />

#### 自旋锁

![image-20221001155050549](image\os72.png)

> 其机制：
>
> * *当value值为0时*，`test-and-set(value)`将value值置为1，并返回False，*进程不会陷入循环*
> * 而如果这*之后再有进程想获得锁*，因为此时value值为1，`test-and-set(value)`返回True，该进程*会陷入while循环当中*
> * *直到第一个进程*进入`Lock::Release()`将value值再置为0，即*将锁释放掉*以后，后面的那个进程才能从while循环中出来

#### 无忙等待锁

![image-20221001155339928](image\os73.png)

> `Lock::Acquire()` —— 先while进行判断，如果value = 1，`test-and-set(value)`返回值为True，*进入while循环*，把当前线程*放到等待队列*中，同时执行调度程序。其他进程可以继续执行。如果value = 0，`test-and-set(value)`返回值为False，也就*不会陷入while中*，就可以*进入到临界区*
>
> `Lock::Release()` —— 将 value 值置为 0，表示*释放锁*，之后把该线程*从等待队列中放入就绪队列中*。也就是说，线程在等待的过程中是*处于放弃CPU使用权的状态*
>
> 
>
> 无忙等待的过程也就实现了**让权等待**

![image-20221001155815970](image\os74.png)

> *中断禁用只适用于单处理机*。如果有多个处理机，*在一个处理机上禁止中断的响应，是不管用的*。另一个处理机上如果有中断响应，或者说有其他的进程执行，那它仍然可以修改共享的那些变量
>
> 
>
> 解释“死锁”：低优先级等CPU，高优先级等临界区资源

### 同步方法总结

| 禁用中断       | 软件方法 | 原子操作指令           |
| -------------- | -------- | ---------------------- |
| 仅限于单处理器 | 复杂     | 单处理器和多处理器均可 |

## 十一、信号量和管程

### 信号量

![image-20221002130503305](image\os75.png)

> 原子性：操作系统在执行它的代码的时候，它的优先级高于进程的用户代码，所以它能保证它在执行的过程当中不受应用进程的代码执行的干扰，从而保证了PV操作的原子性
>
> 不会无限期阻塞：这是由于操作系统在这里起的作用。在实际系统上，P操作后面有一个等的最长时限的参数，超时之后它直接错误返回
>
> 
>
> *自旋锁不能实现先进先出*，因为自旋锁需要占用CPU，一直保持查询。临界区使用者退出，将value值置0，临界区的下一个的进入者是第一个去查询的进程，即第一个执行test-and-set(value)的进程。那么就可能存在这样一种情况，某个等待临界区资源的进程虽然一直保持查询，但总是被其他等待临界区资源的进程抢先，即发生了饥饿现象。

![image-20221002130852677](image\os76.png)

> PV操作的原子性是由操作系统来保护的
>
> 软件方法的最大问题就在于`sem--`和后面的`if(sem<0){…}`中间可能会中断，就会产生很多的麻烦。现在有了操作系统的保护，PV操作的执行就不会被打断

![image-20221002131215926](image\os77.png)

信号量*不能处理死锁问题*

> 2元信号量可以初始化为（）
>
> A 0或1
>
> B 0或-1
>
> C 只能为1
>
> D 任意值
>
> *答案：A*
>
> 
>
> (2011年全国统考)有两个并发执行的进程P1和P2，共享初值为1的变量x。P1对x加1，P2对x减一。加1和减1操作的指令序列分别如下所示,两个操作完成后，x的值（）
>
> A 可能为-1或3
>
> B 只能为1
>
> C 可能为0、1或2
>
> D 可能为-1、0、1、1或2
>
> *答案：C*

### 管程

![image-20221002140741155](image\os81.png)

> 一个线程在临界区当中执行，必须执行到它退出临界区，它才可能放弃临界区的互斥访问
>
> 而管程*允许*在执行的过程当中*临时放弃*。在其临时放弃之后，其他线程就可以进到管程这个区域中

管程的组成：

* 一个锁：控制代码的互斥访问
* 0或多个条件变量：管理共享数据的并发访问
  * 每个条件变量表示一种等待原因，对应一个等待队列
  * `wait()`操作：将自己阻塞；唤醒一个等待者或释放管程的互斥访问
  * `signal()`操作：将等待队列中的一个线程唤醒；如果等待队列为空，则等同于空操作
* 条件变量和信号量的区别在于：条件变量的初值是0，而信号量的初值和资源数是一致的

![image-20221002141905014](image\os82.png)

#### Hansen管程和Hoare管程

![image-20221002143105195](image\os84.png)

在Hansen管程中，一个线程T1等待条件变量，那么它进入等待状态，这时候允许线程T2开始执行。在T2执行过程当中，等待的条件成立，T2就给了一个释放，允许x条件变量所对应的线程可以开始运行。但*释放完了以后T2还会继续执行*，一直到它放弃管程的互斥访问权限，然后T1才恢复执行。这种做法意味着*当前正在执行的这个线程更优先*

在Hoare管程中，第一个线程执行到等待条件变量的时候进入等待状态，T2开始执行。T2在T1等待的事件已经出现时，唤醒T1，*唤醒完之后*，它*立即放弃管程的互斥访问权*。这时候T1马上开始执行，等它结束之后，T2再继续执行。

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1602845381612-9a72ea11-b4ac-49d3-9a10-5b280f64e9fd.png?x-oss-process=image%2Fresize%2Cw_752%2Climit_0" alt="image.png" style="zoom:80%;" />

> 第二个效率低是因为它多了一次切换，但第二个的行为确定性会更好一些

> 管程的主要特点有（）
>
> A 局部数据变量只能被管程的过程访问
>
> B 一个进程通过调用管程的一个过程进入管程
>
> C 不会出现死锁
>
> D 在任何时候，只能有一个进程在管程中执行
>
> *答案：ABD*

### 生产者-消费者问题

![image-20221002131342737](image\os78.png)

#### 信号量解法

![image-20221002131504764](image\os79.png)

![image-20221002131529302](image\os80.png)

#### 管程解法

![image-20221002142621036](image\os83.png)

> 用*信号量*解决生产者-消费者问题的时候，*必须先检查缓冲区的状态*，然后再申请互斥操作
>
> 在*管程*中这两个步骤顺序先后颠倒也并无影响，管程在*内部检查*的时候，*如果不成功还可以放弃*管程的互斥访问权限
>
> 而对于信号量的实现，进入到临界区中，已经占用了对缓冲区的互斥访问，别的进程就再进不来了，因为进入临界区的进程不能够放弃
>
> 这就是这两者间的区别

### 哲学家就餐问题

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1602845910560-64505f16-6300-4bc2-be63-257ba916aee7.png?x-oss-process=image%2Fresize%2Cw_723%2Climit_0" alt="image.png" style="zoom:80%;" />

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1602846034880-b39b782b-22e3-4427-b308-1e476248cc50.png?x-oss-process=image%2Fresize%2Cw_701%2Climit_0" alt="image.png" style="zoom:80%;" />

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1602846436582-dda1551c-4f68-429b-91b3-b341636e3de3.png?x-oss-process=image%2Fresize%2Cw_708%2Climit_0" alt="image.png" style="zoom:80%;" />

### 读者-写者问题

#### 读者优先

![image-20221002151500888](image\os85.png)

#### 写者优先

![image-20221002151958998](image\os87.png)

![image-20221002151934481](image\os86.png)

> `(AW + WW) > 0`：如果*有写者正在写*或者*有写者在申请写*，就将读者置入等待队列。也就是说写者是优先的

![image-20221002152113683](image\os88.png)

> `(AW + AR) > 0`：*有写者正在写*或是*有读者正在读*，就等待；也就是说，如果*有等待申请读的读者，则不等待*。即写者优先
>
> 
>
> 优先唤醒等待写的写者；如果没有，唤醒等待读的读者
>
> 
>
> 从而可以看出，这整个管程实现是写者优先的
>
> 管程能够简化同步问题的实现方法

## 十二、死锁和进程通信

出现死锁的必要条件

* 互斥：任何时刻只能有一个进程使用一个资源实例
* 非抢占：资源只能在进程使用后自愿释放
* 持有并等待：进程保持至少一个资源，并正在等待获取其他进程持有的资源
* 循环等待：资源分配图成环

死锁处理方法

* 死锁预防：确保永远不会死锁
* 死锁避免：在使用前进行判断，只允许不会出现死锁的进程请求资源
* 死锁检测和恢复：在检测到运行系统进入了死锁状态后，进行恢复

### 死锁预防

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1603032737539-ca6798ef-c6e4-496f-9cba-bbbc03e6e2b1.png?x-oss-process=image%2Fresize%2Cw_742%2Climit_0" alt="image.png" style="zoom:80%;" />

### 死锁避免

![image-20221002153923617](image\os89.png)

#### 银行家算法

![image-20221002154141398](image\os90.png)

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1603033853262-e80f8443-9cb5-42e5-ad73-0127591dc7bb.png?x-oss-process=image%2Fresize%2Cw_727%2Climit_0" alt="image.png" style="zoom:80%;" />

### 死锁检测

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1603034322380-63764b86-2f28-403a-af8f-9d4ffe4f97c9.png?x-oss-process=image%2Fresize%2Cw_668%2Climit_0" alt="image.png" style="zoom:90%;" />

> 对于进程个数为n，资源类型为m的死锁检测算法的时间复杂度为（）
>
> A $O(mn^2)$
>
> B $O(m^2n)$
>
> C $O(m^2n^2)$
>
> D $O(mn)$
>
> *答案：A*
>
> *解析：*需要 $O(mn^2)$ 个操作才能检测出来

![image-20221002155433665](image\os91.png)

### 进程通信

#### 直接通信和间接通信

![image-20221002155829947](image\os92.png)

> 间接通信是*依赖于操作系统内核*完成的进程间的通信
>
> * 首先在通信进程和内核之间建立能够支持这种通信的机构，如建立消息队列
> * 一个进程可以把信息发送到内核的消息队列中，随后另一个进程从其中读出来，从而实现进程A和B之间的通信
> * 这个通信过程的*生命周期甚至可以不一样*，比如说A发信息的时候B还没有创建，而B接收数据的时候A可能已经关闭了
>
> 直接通信是在两个进程之间建立一个通信信道，即图中的*共享信道*
>
> * 因为它俩直接进行交流，两个进程*必须同时存在*才能够进行通信
> * 发方向共享信道发送数据，收方从共享信道中读取数据

![image-20221002160154905](image\os93.png)

![image-20221002160511712](image\os94.png)

> 消息队列与进程的之间的对应关系是多对多，一个消息队列可以与多个进程相关联，每一个进程也可以和多个消息队列进行共享

![image-20221002160609869](image\os95.png)

> 发方并不关心收方到底是谁，它关心的是消息队列是谁，接收也是一样

#### 阻塞与非阻塞通信

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1603035049868-11b41c05-5401-4bed-880b-ee676b07df9d.png?x-oss-process=image%2Fresize%2Cw_677%2Climit_0" alt="image.png" style="zoom:90%;" />

#### 通信链路缓冲

![image-20221002161344795](image\os96.png)

### 信号与管道

#### 信号

![image-20221003132505954](image\os97.png)

> 在一个进程执行过程当中，按 `Ctrl-C` 可以把这个进程停下来，就是通过信号来实现的
>
> 
>
> 信号仅仅是用来做一种快速的响应机制，它比别的通信机制要快

![image-20221003132643180](image\os98.png)

> 通过在`main()`中的`signal()`系统调用*注册*信号处理例程

![image-20221003132715060](image\os99.png)

#### 管道

两个进程要通信时，在内存中*建立一个临时文件*，把中间的数据放入其中

![image-20221003132936785](image\os100.png)

> 管道也算一种特殊的文件系统

![image-20221003133121479](image\os101.png)

![image-20221003133138121](image\os102.png)

### 消息队列和共享内存

#### 消息队列

![image-20221003135849181](image\os103.png)

#### 共享内存

优点：一个进程写入共享内存段，另一个进程立即可见。*没有系统调用，不需要进行用户和内核之间的切换*

避免一个进程在写共享内存段，还没有写完之前，另一进程就从共享内存段中读，因此需要*同步机制*

实现：两个进程各自的页表项将其各自的逻辑地址*映射到同一个物理内存地址*上

![image-20221003135922209](image\os104.png)

> 如果通信的双方是一个进程中的两个线程，这种共享内存是天然的，不需要额外的机制就已经实现了。

![image-20221003140149418](image\os105.png)

> 关于消息队列和共享内存的进程通信机制的阐述正确的是（）
>
> A 消息队列是由操作系统维护的以字节序列为基本单位的间接通信机制
>
> B 共享内存是把同一个物理内存区域同时映射到多个进程的内存地址空间的通信机制
>
> C 消息队列机制可用于进程间的同步操作
>
> D 共享内存机制可用于进程间的数据共享
>
> *答案：ABCD*
>
> *解析：*注意 C 也是对的，消息队列是可以用来通信的，通信可以分为同步和异步的方式，具体看你怎么规定的。所以当然是可以用于进程间的同步操作

## 十三、文件系统

### 文件系统和文件

*文件描述符*是打开文件的标识

文件系统中的基本操作单位是*数据块*

*目录*是一类特殊的文件

- 目录的内容是文件索引表<文件名, 指向文件的指针> 

#### 文件描述符

![image-20221003141348102](image\os106.png)

#### 文件的用户视图和系统视图

![image-20221003141458564](image\os107.png)

> 用户视图是指用户进程看到的文件是什么样的
>
> *数据块大小和扇区大小可能不一样*。通常情况下，几个扇区构成一个数据块，特别是对于容量比较大的磁盘而言是这样的

#### 访问模式

![image-20221003141626794](image\os108.png)

#### 文件共享和访问控制

![image-20221003141824222](image\os109.png)

![image-20221003141944568](image\os110.png)

### 目录

#### 目录实现

![image-20221003142146136](image\os111.png)

> 哈希表实现的目录表中的每一项的长度是固定的

#### 硬链接和软链接

![image-20221003142213707](image\os112.png)

> 软链接：链接文件中存的是另一个文件的完整路径
>
> 
>
> *硬链接*中，一个删除操作，只有*删掉最后一个指向文件的文件名*的时候，*才会把这个文件实体删掉*。而*软链接*中，删除别名和删除其他的文件是一样的，*删除别名*，实际上*文件不受任何影响*。*删除文件*之后，原来的*别名指向的文件就是不存在了*

#### 文件目录的循环访问

![image-20221003142400996](image\os113.png)

> 通常情况下，限制可以检索下去的长度，超过这个长度，就停止检索

#### 名字解析

名字解析：把逻辑名字转换成物理资源（如文件）

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1603174954331-fbd8a732-f117-4de4-8e0c-5066d44a4dc0.png" alt="image.png" style="zoom:67%;" />

### 文件系统的挂载

文件系统需要先挂载才能被访问

未挂载的文件系统被挂载在*挂载点*上

### 虚拟文件系统

维护各种文件系统所共同的一些数据结构和常用的操作算法，下边对各种不同的实际的文件系统提供相应的访问接口

![image-20221003143738596](image\os114.png)

![image-20221003144051055](image\os115.png)

> 文件卷控制块，即超级块
>
> 文件控制块，即索引节点
>
> 
>
> 目录是由目录项组成的，每个目录项对应着一个子目录或者一个文件。所有目录项的数据结构和树状的分层结构形成了文件系统的树状数据结构

### 文件缓存和打开文件

#### 数据块缓存和页缓存

文件缓存是指从磁盘上读数据到内存甚至于到CPU使用，中间有*多种缓存*

* 磁盘上通过磁盘控制器来完成对磁盘上扇区的读写，在磁盘控制器上有扇区的缓存

* 内存虚拟盘：用内存来虚拟一个逻辑的磁盘

  操作系统讨论的缓存是在内存当中的数据块缓存

![image-20221003144603123](image\os116.png)

> 从磁盘上读数据块到内存是*按需进*行的，在执行read操作的时候会把相应的一整块读到内存中，选择所需要的给相应的进程去使用。而在读的过程中，也可以*采取一定的预读机制*，可以先多读几块
>
> “写操作可能被缓存和延迟写入”——在写的时候，也有可能将写操作延迟到以后，也就相当于先把它写到内存的缓存中，然后后续再有修改的时候，可以把两个写合并到一起来往下写。当然这种合并之后写有一种风险，可能*在前一个写没有进行，第二个写也没有进行的时候*，系统出现故障，*第一个本来认为已经正常写进去的，也就可能会丢掉*
>
> 数据块缓存——读磁盘上的东西，放内存里，就*标记*这一块内存的东西*是磁盘的缓存*，以后要去读磁盘就先查这个地方

![image-20221003145158248](image\os117.png)

> 逻辑地址空间中的页面经过内核的虚拟存储管理机构把它映射到物理内存，或者把它映射到外存，这两者都是可以存数据的，所以可以利用这种方式来*扩展*进程可用的*逻辑地址空间*
>
> 除了映射到对换区，还可以对一些可执行文件，直接把它映射到可执行文件中去。这种机制实际上就和文件数据块的页缓存机制一致
>
> 此时，就可以提供一种反向的机制，即把文件缓存到内存当中，把文件读写转换成对内存的访问。这样一来，就可以把这两者统一起来。

进程的内存访问和文件读写都会转换成页缓存。如果内存中有要读写的数据块，如果没有再到文件系统中读写（而数据块缓存则没有）

![image-20221003145727134](image\os118.png)

![image-20221003145754851](image\os119.png)

#### 打开文件锁

![image-20221003150006786](image\os120.png)

### 文件分配

![image-20221003150112296](image\os121.png)

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1603181030475-8984f73d-d4b4-4ffd-9d09-b186edd89aa4.png?x-oss-process=image%2Fresize%2Cw_701%2Climit_0" alt="image.png" style="zoom:90%;" />

> 连续分配会产生外碎片

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1603181051488-5461d052-a5e1-48f5-85b9-aa6ebd778d53.png?x-oss-process=image%2Fresize%2Cw_712%2Climit_0" alt="image.png" style="zoom:90%;" />

> 单向链表（倒数的几块很难找）

![image.png](https://cdn.nlark.com/yuque/0/2020/png/1458680/1603181064063-c1344eb4-0ae6-4633-958a-b7098f3522ef.png?x-oss-process=image%2Fresize%2Cw_642%2Climit_0)

> IB 即索引数据块
>
> 大文件的索引分配
>
> * 链式索引块（IB $\rightarrow$ 一些数据块与下一个IB $\rightarrow$ 一些数据块与再下一个IB）
> * 多级索引块（一级IB $\rightarrow$ 多个二级IB $\rightarrow$ 数据块）

![image-20221003150738170](image\os122.png)

![image.png](https://cdn.nlark.com/yuque/0/2020/png/1458680/1603181098772-3bafbdeb-f0ff-439a-b2c4-c9b6dd9c33bd.png?x-oss-process=image%2Fresize%2Cw_641%2Climit_0)

> UFS，即 Unix File System

> 关于文件分配的阐述正确的是（）
>
> A 连续分配会产生外碎片
>
> B 链式分配会产生外碎片
>
> C 索引分配会产生外碎片
>
> D 多级索引分配可支持大文件
>
> *答案：AD*
>
> *解析：*链式分配和索引分配不会产生外碎片

### 空闲空间管理

#### 位图

用位图代表空闲数据块列表，如 $111111111111111001110101011101111\ldots$，用 $0$ 表示那一个数据块是空闲的

使用简单，但是可能会是一个大的很大向量表

> 160GB磁盘-> 40M数据块-> 5MB位图
>
> 假定空闲空间在磁盘中均匀分布，
>
> 则找到“0”之前要扫描 $\dfrac{磁盘上数据块的总数}{空闲块的数目}$

#### 链表与链式索引

 ![image-20221003151228421](image\os123.png)

### 冗余磁盘阵列RAID

**RAID-0**：多个磁盘并行访问，更大磁盘带宽，存取速度最快

**RAID-1**：向两个磁盘写入，从任何一个读取。可靠性强，读取性能增加

**RAID-4**：多个磁盘并行访问，有一个专用奇偶校验磁盘，可从任意故障磁盘中恢复

**RAID-5**：多个磁盘并行访问，将校验和的存放位置做了一个分布，从而把校验磁盘的访问瓶颈分摊开，提高它的性能，允许一个磁盘错误

**RAID-6**：多个磁盘并行访问，每组条带块有两个冗余块，允许两个磁盘错误

**RAID-0/4/5/6**：基于数据块

**RAID-3**：基于位

* 存取速度比较：

  RAID-0是条带化（并行访问）

  RAID1读速仅为2倍，写时不变

  RAID4和RAID5的读速度与RAID0接近，但由于带有校验，写速度都比RAID0慢

  综上，RAID-0的读速和写速都是最快的，存取速度最快

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1603182923860-09ae60d6-41ed-4f0b-aa50-058e52f86bc9.png?x-oss-process=image%2Fresize%2Cw_701%2Climit_0" alt="image.png" style="zoom:90%;" />

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1603182961429-74f67334-e7c0-4bf9-bd8e-d96b32c4de1c.png?x-oss-process=image%2Fresize%2Cw_718%2Climit_0" alt="image.png" style="zoom:90%;" />

> 图见《计算机组成原理考点梳理》

> 关于冗余磁盘阵列(RAID, Redundant Array of Inexpensive Disks)的阐述正确的是（）
>
> A 采用RAID机制可提高磁盘IO的吞吐量(通过并行)
>
> B 采用RAID机制可提高磁盘IO的可靠性和可用性 (通过冗余)
>
> C 采用RAID-0可提高磁盘IO的可靠性和可用性
>
> D 采用RAID-1可提高磁盘IO的吞吐量
>
> *答案：AB*
>
> *解析：*RAID-0提高并行性（吞吐量），RAID-1提高可靠性

![image-20221003151835738](image\os124.png)

> RAID0能够提高磁盘的性能，而RAID1能够提高磁盘的可靠性
>
> RAID 0+1 ——首先是两个磁盘之间做条带化，这时做磁盘读写的时候，性能会提高。然后在此基础上再做一个磁盘镜像，这时候可靠性也提高了
>
> RAID 1+0 —— 先做镜像，然后再在上面套一层RAID0，往两组RAID-1中同时写，也能够提高磁盘读写的性能和可靠性

## 十四、I/O系统

### I/O特点

|          | 常见设备                       | 特点           | 访问特征             | I/O命令                                             |
| -------- | ------------------------------ | -------------- | -------------------- | --------------------------------------------------- |
| 字符设备 | 键盘/鼠标、串口等              | 通常速度很慢   | 以字节为单位顺序访问 | get()、put()等；通常使用文件访问接口和语义          |
| 块设备   | 磁盘驱动器、磁带驱动器、光驱等 | 通常是存储设备 | 均匀的数据块访问     | 原始I/O或文件系统接口；内存映射文件访问             |
| 网络设备 | 以太网、无线、蓝牙等           |                | 格式化报文交换       | send/receive 网络报文；通过网络接口支持多种网络协议 |

![image-20221003153131793](image\os125.png)

阻塞IO：从发出请求到返回数据，期间进程是*要处于等待状态*的，一直到有数据回来

> 图：用户的请求首先通过系统调用到设备驱动，设备驱动会将用户请求*转换成实际的硬件控制命令*，绕过中间的中断处理，*中断只是在返回的时候有处理*，直接控制相应的硬件进行相应的操作。操作结束之后，产生中断请求，然后转到设备驱动，最后通过系统调用的返回返回到用户态，用户得到相应的结果

![image-20221003153147407](image\os126.png)

非阻塞IO：进程在执行的过程当中，把命令*发出之后不等待*。*可能读写不成功*，或者说读写的数据量与预想读写的数据量不一致

![image-20221003153202375](image\os127.png)

异步IO是把同步和异步两者结合起来

> 图：先通过系统调用把要写的数据告诉设备驱动，然后设备驱动*控制硬件设备进行操作*。控制完成之后，*不会等待结果直接返回*，而设备操作完成之后它会*通过中断返回相应的结果*

> 网络设备包括（）
>
> A 以太网卡
>
> B wifi网卡
>
> C 蓝牙设备
>
> D 网盘设备
>
> *答案：ABC*
>
> *解析：*网盘在模拟实现上应该算块设备

### I/O结构

![image-20221003153747346](image\os128.png)

> IO子系统用来处理各种设备共同的一些内容，比如说IO请求转换成驱动的IO请求，这是一种细化
>
> IO子系统还会缓存设备给出的一些结果，比如说要访问某一个磁盘上的某一个扇区的数据，前面已经做过一次这样的操作，IO子系统负责缓存并且第二次来访问的时候，直接给出结果

![image-20221003153831961](image\os129.png)

> 关于CPU与设备的通信方式包括（）
>
> A 轮询
>
> B 设备中断
>
> C DMA
>
> D PIPE
>
> *答案：ABC*
>
> *解析：*CPU和设备的通信方式：轮训、设备终端、DMA。而PIPE用于进程间通信

### I/O数据结构

#### 数据传输

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1603185190717-a9ea4002-e8ab-4329-b590-e6e9be4eb83a.png?x-oss-process=image%2Fresize%2Cw_723%2Climit_0" alt="image.png" style="zoom:80%;" />

> 如果做了内存映射，就是由load/store指令来完成设备和CPU之间的数据交换

#### 通知操作系统

CPU主动轮询

![image-20221003154458794](image\os130.png)

设备中断

![image-20221003154544741](image\os131.png)

> 高速网络设备，第一次采用中断方式进行响应，如果有数据包的接收，CPU会响应中断来处理这条数据
>
> 由于输入输出数据比较多，量比较大，后续的数据包如何继续用中断接收，开销就太大了，所以改用轮询

> 关于IO数据传输的阐述正确的是（）
>
> A 程序控制I/O(PIO, Programmed I/O)通过CPU的in/out或者load/store传输所有数据
>
> B DMA设备控制器可直接访问系统总线并直接与内存互相传输数据
>
> C DMA机制适合字符设备
>
> D PIO机制适合块设备
>
> *答案：AB*
>
> *解析：DMA*机制适合*块设备*，*PIO*机制适合简单，低速的*字符设备*等

### 磁盘调度

$访问时间T_a=寻道时间T_s+旋转延迟（平均半圈）\dfrac{1}{2r}+传输时间（\dfrac{传输的比特数b}{磁道上的比特数r\cdot 磁盘转速N}）\dfrac{b}{rN}$

磁盘调度算法

| 算法                     | 算法描述                                                     | 评价                                                         |
| ------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 先进先出（FIFO）         | 哪个先来就先去往哪里                                         | 公平；在有很多进程的情况下，接近随机访问的性能               |
| 最短服务时间优先（SSTF） | 在当前位置判断，哪个请求近，就去哪里                         | 磁头粘着（反复请求对某一个磁道的I/O操作，导致磁头停留在那里不动） |
| 扫描（SCAN）/电梯算法    | 一个方向走到底，再回头                                       | 磁头粘着                                                     |
| 循环扫描（C-SCAN）       | 限制扫描一个方向，扫描到最后一个磁道后直接返回另一端再扫一遍 | 磁头粘着                                                     |
| C-LOOK                   | 到达当前方向的最后一个请求后，就立即反转                     | 磁头粘着                                                     |
| N步扫描（N-step-SCAN）   | 分成长度为N的子队列，FIFO处理所有子队列，子队列中使用扫描算法 | 不会磁头粘着                                                 |
| 双队列扫描（FSCAN）      | 将磁盘请求分为两个队列，交替使用扫描算法处理一个队列         | 新生成的磁盘I/O请求放入另一个队列，所有的新请求都将被推迟到下一次扫描时处理 |

> 常用移臂调度算法包括（）
>
> A 先来先服务（FIFO）算法
>
> B 最短寻道时间优先（SSTF）算法
>
> C 电梯调度（SCAN）算法
>
> D 单向扫描（C-SCAN）算法
>
> *答案：ABCD*

### 磁盘缓存

磁盘缓存是磁盘扇区在*内存中*的缓存区

* 磁盘缓存的调度算法很类似虚拟存储调度算法
* 磁盘的访问频率远低于虚拟存储中的内存访问频率
* 通常磁盘缓存调度算法会比虚拟存储复杂

![image-20221003160320586](image\os132.png)

![image-20221003160357654](image\os133.png)

> 在磁盘访问的时候，有可能频繁访问某一个扇区中的数据
>
> 如果用LFU，那么计数会很快速地增加到很大，再往后用LFU就不能反映当前进行引用的真实情况

![image-20221003160645735](image\os134.png)

> 在设备管理子系统中，引入缓冲区的目的主要有()
>
> A 缓和CPU与I/O设备间速度不匹配的矛盾
>
> B 减少对CPU的中断频率，放宽对CPU中断响应时间的限制
>
> C 解决基本数据单元大小（即数据粒度）不匹配的问题
>
> D 提高CPU和I/O设备之间的并行性
>
> *答案：ABCD*

---







---







---

## 实验二、物理内存管理

### X86特权级

[CPU的运行环、特权级与保护](https://blog.csdn.net/drshenlei/article/details/4265101)

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1603188592147-e474fd6d-8e08-4acc-9f32-531afc285af1.png" alt="image.png" style="zoom: 67%;" />

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1603188786439-a8a36766-10e5-43be-a7af-1f59f7fab35a.png?x-oss-process=image%2Fresize%2Cw_733%2Climit_0" alt="image.png" style="zoom:80%;" />

* SS（堆栈段寄存器）、DS（数据段寄存器）、CS（代码段寄存器）

  RPL（请求特权级，Requested Privilege Level）：在*数据段*寄存器DS、ES、FS、GS的最低两位

  CPL（当前特权级，Current Privilege Level）：在*代码段*寄存器CS、SS的最低两位

  DPL（描述符特权级，Descriptor Privilege Level）：在段*描述符*、中断门描述符、陷入门描述符内

  CS中两位宽的CPL字段总是等于当前CPU的特权级

* CPU如何切换特权级：门描述符（系统类型的段描述符）

![x86的分段保护](https://p-blog.csdn.net/images/p_blog_csdn_net/drshenlei/EntryImages/20090612/3633804446316093750.PNG)

* *访问门时* $CPL\leqslant DPL[门]\ \&\ CPL\geqslant DPL[段]$

  因为越高的数值代表越低的特权，max挑出特权最低的一个，并与描述符特权级比较。如果DPL的值大于等于它，那么这个访问就获得许可了：

  *访问段时* $max\{CPL,\,RPL\}\leqslant DPL[段]$

> 80386 CPU保护模式下的特权级个数是()
>
> A 1
>
> B 2
>
> C 3
>
> D 4
>
> *答案：D*
>
> *解析：*80386中是有ring0-3四个的
>
> 
>
> 在ucore OS的管理下，如果CPU在ring3特权级执行访存指令，读属于ring0特权级的数据段中的内存单元，将出现的情况是（）
>
> A 产生外设中断
>
> B 产生访存异常
>
> C CPU继续正常执行
>
> D 系统重启
>
> *答案：B*
>
> *解析：*产生一般保护错（General Protection Fault）
>
> 
>
> CS段寄存器中的最低两位保存的是（）
>
> A DPL
>
> B CPL
>
> C RPL
>
> D NPL
>
> *答案：B*
>
> 
>
> DS段寄存器中的最低两位保存的是（）
>
> A DPL
>
> B CPL
>
> C RPL
>
> D NPL
>
> *答案：C*
>
> 
>
> CPU执行一条指令访问数据段时，硬件要做的特权级检查是（）
>
> A MAX(CPL, RPL) <= DPL[数据段]
>
> B MIN(CPL, RPL) <= DPL[数据段]
>
> C MAX(CPL, DPL) <= RPL[数据段]
>
> D MIN(CPL, DPL) <= RPL[数据段]
>
> *答案：A*
>
> 
>
> 对于Task State Segment（TSS）而言，uCore OS可以利用它做（）
>
> A 保存ring 0的SS
>
> B 保存ring 0的ESP
>
> C 保存中断描述符表的基址
>
> D 保存全局描述符表的基址
>
> *答案：AB*
>
> *解析：*TSS：任务状态段，用于存储大部分寄存器的值。寄存器esp0，esp1，esp2是0-2环的栈指针，ss0，ss1，ss2是0-2环的栈段选择子，用于提权、CPU切换栈时使用（为什么没有esp3和ss3？因为3环不需要切换堆栈）。uCore只有ring0和ring3，即这里的AB。（参考：[任务状态段](https://blog.51cto.com/u_14207158/2580337)）
>
> 
>
> 页目录表的基址是保存在寄存器（）
>
> A CR0
>
> B CR1
>
> C CR2
>
> D CR3
>
> *答案：D*
>
> *解析：*寄存器CR0-4与分页机制密切相关。CR0是一个控制寄存器，包括保护位、分页允许位、写保护（WP）位等；CR1未定义；CR2是页故障线性地址寄存器；CR3是页目录基址寄存器；CR4仅在Pentium处理器中才实现。（参考：[控制寄存器(CR0,CR1,CR2,CR3,CR4)](https://blog.csdn.net/whatday/article/details/24851197)）
>
> 
>
> 在启动页机制后，不可能进行的操作包括（）
>
> A 取消段机制，只保留页机制
>
> B 取消页机制，只保留段机制
>
> C 取消页机制，也取消段机制
>
> D 保留页机制，也保留段机制
>
> *答案：A*
>
> *解析：*不可能取消段机制，只保留页机制。有页就一定有段
>
> 
>
> 给定一个虚页地址和物理页地址，在建立二级页表并建立正确虚实映射关系的过程中，需要完成的事务包括()
>
> A 给页目录表动态分配空间，给页表分配空间
>
> B 让页基址寄存器的高20位内容为页目录表的高20位物理地址
>
> C 在虚地址高10位的值为index的页目录项中的高20位填写页表的高20位物理地址，设置有效位
>
> D 在虚地址中10位的值为index的页表项中中的高20位填写物理页地址的高20位物理地址，设置有效位
>
> *答案：ABCD*

### X86 内存管理单元 MMU

// TODO: 待补充

## 实验三、虚拟内存管理

> lab3中虚存管理需要直接借助的机制包括()
>
> A 页映射机制
>
> B 段映射机制
>
> C 中断异常处理机制
>
> D IDE硬盘读写机制
>
> *答案：ACD*
>
> *解析：*段映射机制不直接需要
>
> 
>
> lab3中访问“合法”虚拟页产生缺页异常的原因是（）
>
> A 页表项的P bit为0
>
> B 页目录项的I/D bit为0
>
> C 页表项的U/S bit为0
>
> D 页目录项的W/R bit位0
>
> *答案：A*
>
> *解析：*页表项的P bit为0，表示此页不存在
>
> X86：
>
> * P-位0是*存在*（Present）标志，用于指明表项对地址转换是否有效。P=1表示有效；P=0表示无效。
>
>   在页转换过程中，如果说涉及的页目录或页表的表项无效，则会导致一个异常。
>
>   如果P=0，那么除表示表项无效外，其余位可供程序自由使用。例如，操作系统可以使用这些位来保存已存储在磁盘上的页面的序号。
>
> * R/W-位1是*读/写*（Read/Write）标志。如果等于1，表示页面可以被读、写或执行。如果为0，表示页面只读或可执行。
>
>   当处理器运行在超级用户特权级（级别0、1或2）时，则R/W位不起作用。
>
>   页目录项中的R/W位对其所映射的所有页面起作用。
>
> * U/S-位2是*用户/超级用户*（User/Supervisor）标志。如果为1，那么运行在任何特权级上的程序都可以访问该页面。如果为0，那么页面只能被运行在超级用户特权级（0、1或2）上的程序访问。
>
>   页目录项中的U/S位对其所映射的所有页面起作用。
>
> * A-位5是*已访问*（Accessed）标志。当处理器访问页表项映射的页面时，页表表项的这个标志就会被置为1。当处理器访问页目录表项映射的任何页面时，页目录表项的这个标志就会被置为1。
>
>   处理器只负责设置该标志，操作系统可通过定期地复位该标志来统计页面的使用情况。
>
> * D-位6是页面*已被修改*（Dirty）标志。当处理器对一个页面执行写操作时，就会设置对应页表表项的D标志。
>
>   处理器并不会修改页目录项中的D标志。
>
> * AVL-该字段保留专供程序使用。处理器不会修改这几位，以后的升级处理器也不会。
>
> uCore：
>
> <img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1601910629684-42d00fb3-5f96-4bf2-8cd1-fc38f4f2f304.png?x-oss-process=image%2Fresize%2Cw_760%2Climit_0" alt="image.png" style="zoom: 80%;" />
>
> 
>
> lab3中把扇区索引信息放在（）
>
> A 页表项中
>
> B 页目录项中
>
> C 内存中的Page结构中
>
> D 内存中的vma_struct结构中
>
> *答案：A*
>
> *解析：*页表项中的高24位
>
> <img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1601911487182-1e8c69ff-d223-40c9-9e27-d1f10b9b328e.png" alt="image.png" style="zoom:80%;" />

## 实验四、内核线程管理

// TODO：待补充

## 实验五、用户进程管理

// TODO：待补充

## 实验六、调度器

### RR Round Robin 时间片轮转调度算法

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1602573642267-809fc96a-34f5-4f94-83d0-57304b6fd8d4.png?x-oss-process=image%2Fresize%2Cw_746%2Climit_0" alt="image.png" style="zoom:80%;" />

### Stride调度算法

可以证明 Stride Scheduling 对进程的调度次数*正比于*其优先级

#### Stride调度算法的基本思想

1. 为每个runnable的进程设置一个当前状态stride，表示该进程当前的调度权。另外定义其对应的pass值，表示对应进程在调度后，stride需要进行的累加值

2. 每次需要调度时，从当前 runnable 态的进程中选择stride最小的进程调度

3. 对于获得调度的进程P，将对应的stride加上其对应的步长pass（只与进程的优先权有关系）

4. 在一段固定的时间之后，回到步骤2，重新调度当前stride最小的进程

可以证明，如果令 $P.pass=\dfrac{BigStride}{P.priority}$，则该调度方案*为每个进程分配的时间将与其优先级成正比*

（其中 P.priority 表示进程的优先权（大于1），而 BigStride 表示一个预先定义的大常数）

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1602575644831-e7241b27-a209-4ac4-840a-b85e546a8e35.png" alt="img" style="zoom: 50%;" />

> 在具体实现时，有一个需要注意的地方——stride属性的溢出问题
>
> * 在之前的实现里面我们并没有考虑stride的数值范围，而这个值在理论上是不断增加的，在stride溢出以后，基于stride的比较可能会出现错误
>
> 比如假设当前存在两个进程A和B，stride属性采用16位无符号整数进行存储
>
> 当前队列中元素如下（假设当前运行的进程已经被重新放置进运行队列中）：
>
> <img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1602576708285-96fff7c2-c020-4491-9b37-fc286a2b06cf.png" alt="img" style="zoom:150%;" />
>
> 此时应该选择 A 作为调度的进程，而在一轮调度后，队列将如下：
>
> <img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1602576737800-8782f610-aee1-45dd-a230-30c4749b7da0.png" alt="img" style="zoom:150%;" />
>
> 可以看到由于溢出的出现，进程间stride的理论比较和实际比较结果出现了偏差。
>
> 
>
> 我们首先在理论上分析这个问题：令PASS_MAX为当前所有进程里最大的步进值
>
> 则我们可以证明如下结论：对每次Stride调度器的调度步骤中，有其最大的步进值STRIDE_MAX和最小的步进值STRIDE_MIN之差：
>
> STRIDE_MAX – STRIDE_MIN <= PASS_MAX
>
> 有了该结论，在加上之前对优先级有Priority > 1限制，我们有STRIDE_MAX – STRIDE_MIN <= BIG_STRIDE
>
> 于是我们只要将BigStride取在某个范围之内，即可保证对于任意两个 Stride之差都会在机器整数表示的范围之内
>
> 而我们可以通过其与0的比较结构，来得到两个Stride的大小关系
>
> 在上例中，虽然在直接的数值表示上 98 < 65535，但是 98 - 65535 的结果用带符号的16位整数表示的结果为99，与理论值之差相等
>
> 所以在这个意义下 98 > 65535
>
> 基于这种特殊考虑的比较方法，即便Stride有可能溢出，我们*仍能够得到理论上的当前最小Stride，并做出正确的调度决定*
>
> 
>
> **如何避免stride溢出**
>
> ![img](https://cdn.nlark.com/yuque/__latex/8561af958a4feb160a2e882bc266b33d.svg)
>
> stride, pass 是无符号整数  — 改为用**有符号整数**表示（Proc.A.stride – Proc.B.stride）

## 实验七、同步互斥

> ucore实现的信号量机制被用于（）
>
> A 条件变量实现
>
> B mm内存管理实现
>
> C 哲学家问题实现
>
> D 中断机制实现
>
> *答案：ABC*
>
> *解析：*中断机制是支持信号量的，所以不选
>
> 
>
> 关于ucore实现的管程和条件变量的阐述正确的是（）
>
> A 管程中采用信号量用于互斥操作
>
> B 管程中采用信号量用于同步操作
>
> C 管程中采用条件变量用于同步操作
>
> D 属于管程的共享变量访问的函数需要用互斥机制进行保护
>
> *答案：ABCD*

## 实验八、SFS文件系统

> ucore实现的文件系统抽象包括（）
>
> A 文件
>
> B 目录项
>
> C 索引节点
>
> D 安装点
>
> *答案：ABC*
>
> 
>
> ucore实现的simple FS（简称SFS）采用的文件分配机制是（）
>
> A 连续分配
>
> B 链式分配
>
> C 索引分配
>
> D 位图分配
>
> *答案：C*
>
> 
>
> 关于ucore实现的SFS阐述正确的是（）
>
> A SFS的超级块保存在硬盘上，在加载simple FS时会读入内存中
>
> B SFS的free map结构保存在硬盘上，表示硬盘可用的数据块（扇区）
>
> C SFS的root-dir inode结构保存在硬盘上，表示SFS的根目录的元数据信息
>
> D 硬盘上的SFS ，除保存上述三种结构外，剩下的都用于保存文件的数据内容
>
> *答案：ABC*
>
> *解析：*除了前三种结构，剩下的用于保存文件的inode, dir/file的data
>
> ![img](https://cdn.nlark.com/yuque/0/2020/png/1458680/1603184326726-5d4761c6-2420-498d-8ba3-08d6a4446667.png)
>
> 
>
> 关于ucore实现的Virtual FS（简称VFS）阐述正确的是()
>
> A 已支持磁盘文件系统
>
> B 已支持设备文件系统
>
> C 已支持网络文件系统
>
> D 已支持系统状态文件系统
>
> *答案：AB*
>
> *解析：*后两种可实现，但现在还没实现
>
> 
>
> 关于ucore文件系统支持的I/O 设备包括()
>
> A 串口设备
>
> B 并口设备
>
> C CGA设备
>
> D 键盘设备
>
> *答案：ABCD*
