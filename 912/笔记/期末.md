# 数据结构

## 大O记号

即便 $f(n) = O(g(n))$，也未必 $2^{f(n)} = O(2^{g(n)})$ （2014期中）

> :white_check_mark:
>
> $O$ 即使是 $\Theta$，也并不能推出后面的结论，如 $2n=O(n)$，但 $2^{2n}=4^n\neq O(2^n)$

若每一递归实例本身仅需常数时间和空间，则（）函数的渐进时间复杂度等于渐进空间复杂度。（2014期中）

A) 尾递归  B）线性递归    C）二分递归   D）多分支递归

> AB

设图灵机在初始状态下，只有读写头所对单元格为'0'，其余均为'#'；此后，连续地执行increase()算法2014次。

在此期间，读写头累计移动的次数（就相对误差率而言）最接近于（）。（2014期中）

A) 2000   B）4000    C）8000     D）16000     E）32000

> C
>
> 个人理解，每次increase()，读写头←、→、→、←（两边都是#，所以立马回头）

$f(n) = O( g(n))$，当且仅当 $g(n)=\Omega(f(n))$ 。（2011期中）

> :white_check_mark:
>
> 好像没啥问题

若 $f(n) = O(n^2)$ 且 $g(n)=O(n)$，则下列结论正确的是：（2011期中）

A. $f(n) + g(n) = O(n^2)$

B. $f(n) / g(n) = O(n^2)$

C. $g(n)=O(f(n))$

D. $f(n) * g(n) = O(n^3)$

> AD
>
> 常见地，$g(n)$ 甚至可以大于 $f(n)$，除法一定是错的

算法 $g(n)$ 的复杂度为 $\Theta(n)$。若算法 $f(n)$ 中有 $5$ 条调用 $g(n)$ 的指令，则 $f(n)$ 的复杂度为：（2011期中）

 A．$\Theta(n)$    B.$O(n)$    C. $\Omega(n)$  D. 不确定

> B？
>
> 起码是 $\Theta(n)$，但也没说有没有其他复杂度更高的指令，也许题目不完整

## 向量、栈

对有序向量做 Fibonacci 查找，就最坏情况而言，成功查找所需的比较次数与失败查找相等。（2011期中）

> :white_check_mark:
>
> 平均情况下常系数上更优，但最坏情况（也就是每次都失败，还是要比较两次）依旧是不变的

RPN 中各操作数的相对次序，与原中缀表达式完全一致。（2011期中）

> :white_check_mark:
>
> 中缀表达式转RPN，操作数次序还是一样的

对不含括号的中缀表达式求值时，操作符栈的容量可以固定为某一常数。（2011期中）

> :white_check_mark:
>
> 没有括号的话，栈内至多有 $r$ 个操作符，$r$ 是操作符优先级分级数

无论有序向量或有序列表，最坏情况下均可在 $O(\log n)$ 时间内完成一次查找。（2011期中）

> :x:
>
> 列表不行，因为它只能循位置访问

对于同一有序向量，每次折半查找绝不会慢于顺序查找。（2011期中）

> :x:
>
> 顺序查找 $O(1)\sim O(n)$

使用binsearch算法版本C在有序向量{1，3，5，.....2013}中查找，目标为独立均匀分布于[0,2014]内的整数。若平均失败查找长度为F，则平均成功长度S应为（）。（2014期中）

A) 1008F/1007 +1

B）1008F/1007 -1

C）1008(F-1)/1007 +1

D）1008(F+1)/1007 -1

![image.png](https://cdn.nlark.com/yuque/0/2020/png/1458680/1605932703645-90b7e6c6-e7ac-4863-8aec-4055bd651491.png)

> B
>
> **所有Bin和Fib的版本均符合、要查找各元素的数值等概率独立均匀分布也适用**： $(S+1)\cdot n=F\cdot(n+1)$，即 $S=\dfrac{n+1}{n}F-1$
>
> 本题 $1007(S+1)=1008F$

字符串"123XY"中的字符经栈混洗之后，可得到（）个合法的C++变量名（比如"YX321"）（2014期中）

A) 28  B）5  C）6   D）5   E）以上皆非

> B
>
> 合法变量名，只能由 $X$ 或 $Y$ 开头
>
> XY321、X3Y21、X32Y1、X321Y、YX321

evaluate()算法的优先级表中，有的空格项对应于表达式不合法或不合常识的情况，比如（）（2014期中）

A) `pri['\0'][')']`  B）`pri['!']['(']`   C）`pri[')']['!']`   D）`pri['(']['\0']`

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1605934773813-9460fb77-6f48-4855-a393-38bf816983b3.png" alt="image.png" style="zoom: 50%;" />

> ABCD
>
> A不合法，`'\0'`在栈顶，而它本身应当在栈底，意味着栈内没有字符了，当前字符`')'`不可能有匹配的字符了
>
> B不符合常识
>
> C不符合常识，右括号不需要进栈
>
> D不合法，遇到最后的终止符，意味着还有`(`没匹配，表达式不合法

实际上，evaluate()算法居然可以对非法表达式“(12)3+!4*+5”进行求值，其返回值为（2014期中）

A）41  B）89  C）365   D）以上皆非

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1605937268508-ac348f54-a907-4e05-93e7-8e2a09defb66.png?x-oss-process=image%2Fresize%2Cw_486%2Climit_0" alt="image.png" style="zoom:120%;" />

> B
>
> 注意这里 `!` 优先级是最高的，但也不是不入栈，依旧是等到下一个OP（优先级必然不比它高）的时候再出栈

共有几种栈混洗方案，可以使字符序列{‘x’,’o’,’o’,’o’,’x’}的输出保持原样？（2011期中）

 A．12   B. 10    C. 6     D. 5  

> C
>
> 左x先出栈，则后面三个o任意顺序，共有C(3)=6!/3!/4!=5
>
> 右x先出栈，就只有倒序输出一种

对长度为n =Fib(k)-1的有向序列做 Fibonacci 查找。若各元素的数值等概率独立均匀分布，且平均成功查找长度为 L，则失败平均查找长度为：（2011期中）

 A．n(L-1)/(n-1)   B. n(L+1)/(n+1)    C. (n-1)L/n   D. (n+1)L/n  

> B
>
> $S=\dfrac{n+1}{n}F-1$，或者 $F=\dfrac{n}{n+1}(S+1)$

对长度为 Fib(12) – 1 = 143 的有序向量做 Fibonacci 查找，比较操作的次数至多为：（2011期中）

 A．12   B. 11    C. 10   D. 9  

> B
>
> T~2-20~
>
> 长度为 $n=fib(k)-1$ 的向量，**比较长度至多为 $k-1$ 次**
>
> 成功：比较一次，往左 $fib(k-1)$；失败：比较两次，往右 $fib(k-2)$
>
> 最终递归基由 $fib(2)+fib(1)$ 组成
>
> 最多只要 $k-1$ 次

考察表达式求值算法。算法执行过程中的某时刻，若操作符栈中的括号多达 2010 个，则此时栈的规模（含栈底的'\0'）至多可能多达？试说明理由，并示范性地画出当时栈中的内容。（2011期中）

> `\0 + * ^ ( + * ^ ( + * ^ ( ...  + * ^ ( + * ^ !`（ ! 的优先级是最高的）
>
> $1+4\times2010+4=8045$

设整数e独立且均匀地取自[0,25)，现通过调用fibSearch(A，e，0，7),对如下整数向量A[]做查找：（2014期中）

| k    | 0    | 1    | 2    | 3    | 4    | 5    | 6    |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| A[k] | 1    | 3    | 5    | 7    | 9    | 17   | 19   |

试分别计算其在失败情况下的平均查找长度，以及总体的平均查找长度。

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1607340596437-b3695c61-11cb-437a-93b0-87ff6cb76047.png" alt="image.png" style="zoom: 67%;" />

> | `i`      | 1    | 2    | 3    | 4    | 5    | 6    |
> | -------- | ---- | ---- | ---- | ---- | ---- | ---- |
> | `Fib(i)` | 1    | 1    | 2    | 3    | 5    | 8    |
>
> 总长度 $7=Fib(6)-1$，成功 $Fib(5)-1=4$，失败 $Fib(4)-1=2$，以下类似
>
> 最后添加外部节点，查到外部节点的位置即失败。画出**查找树**
>
> 失败：左 $+1$，右 $+2$
>
> 平均失败查找长度 $(4 + 5 + 4 + 4+ 5 + 4×7 + 5 + 5×4)/18  = 75/18 = 4.167$
>
> 成功：成功的节点处 $+2$
>
> 成功查找长度 $2+ 3 +4 + 4 + 5 + 5 + 5 = 28$
>
> 总体平均查找长度 $(75 + 28)/ 25 = 4.12$

## 树、BST

2010 节点组成的 AVL 树，最大高度可达（	）。（2010-521样卷）

> 适用2023的结论：
>
> h高AVL树至少fib(h+3)-1
>
> fib(17) =1597，fib(18) =2584，故高度达不到18-3=15，至多14
>
> AVL树最高 $14$

在包含 2010 个节点的 AVL 树中，最高与最低叶节点之间的深度差最大可达（   ）。  

A. 8        B. 9        C. 10       D. 11         E. 以上皆非

> E
>
> 适用2023的结论：
>
> 包含2023个节点的AVL树最大高度为14，最小深度为 $\lceil \dfrac h2\rceil$，故为7，最大深度差为7

在高度为 2010 的 AVL 树中删除一节点，至多可能造成（	）个节点失衡，至多需做（	）次旋转调整。（2010-521样卷）

> 1	1005
>
> 删除操作失衡 $1$ 个节点，至多需要 $\lfloor\dfrac h2\rfloor$ 次旋转调整：极端情况来自Fib树，删除深度最小的叶节点，一次双旋上升两层，最高层可能只要一次单旋
>
> T~7-17~
>
> ？全是双旋的话，应该是 $\lfloor\dfrac h2\rfloor\cdot2$

若 AVL 树插入元素的过程中发生了旋转操作，则树高必不变。（2016.1期末）

> :white_check_mark:
>
> 插入不变，删除可能减一

将0..2^d^-1插入AVL一定高度为d。（2014期末补充）

> :white_check_mark:
>
> 按递增次序将 $2^{h+1}-1$ 个关键码插入空AVL中，得到的AVL比为满树
>
> $d-1$ 的满树为 $2^d-1$ 个节点，插入 $2^d$ 个节点高度达到 $d$
>
> T~7-20~

在某节点被删除后AVL树的高度即便下降了，这次操作期间也未必做过旋转调整。（2019.1期末）

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1606020680447-626d9c35-9798-4261-8e72-5dbd52eb6d79.png" alt="image.png" style="zoom:50%;" />

> :white_check_mark:
>
> 删除较高的子树一侧，就不需要旋转

对规模为n的AVL树做一次插入操作，最坏情况下可能引发 Ω(logn) 次局部重构。（2019.1期末）

> :x:
>
> 插入只有1次，删除最多 $\Omega(\log n)$

设在某新节点插⼊AVL树后（尚待平衡化时），最低失衡节点为g。若此时g的左、右孩子的平衡因子分别为-1，0，则应通过（ ）旋转使之重新恢复平衡。（2014期末）

\- A）zig；

\- B）zig+zag；

\- C）zag+zig；

\- D）zag；

\- E）不确定

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1606019049734-f0824fb0-e9c1-49b2-963a-0a210e0f2529.png" alt="image.png" style="zoom: 67%;" />

> C

将[1481,1992]区间内的整数逐一插入到空AVL树中，最后该AVL树的高度是：（2012.6期中）

A、7	B、8	C、9	D、10	E、以上都不对

> C
>
> 1992-1481+1=512，$h=\lfloor\log_2512\rceil=9$

在任何情况下，伸展树总能保持每次操作 O(log n) 的平均复杂度。（2016.1期末）

> :white_check_mark:
>
> Splay所有接口均摊复杂度都是 $O(\log n)$，不论是局部性还是理想随机

即便访问序列不满足局部性（比如完全理想的随机），伸展树依然能够保证分摊O(logn)的性能。（2014期末）

> :white_check_mark:

将2014个数插入splay，第一次访问经过2013次旋转，则是单调插入的。（2014期末补充）

> :x:
>
> 如2、1、3、0、4，每次插入单链都要掉个头，但始终是单链

只有在访问序列具有较强的局部性时，伸展树才能保证分摊O(logn) 的性能。（2019.1期末）

> :x:

将{0,1,2,.....,2018}插入一棵空的伸展树后若树高为2018 ，则上述词条必是按单调次序插入的。（2019.1期末）

> :x:

最底局的叶节点一旦被访问（并做过splay调整）之后，伸展树的高度必然随即下降。（2019.1期末）

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1606037529745-9251550d-c8e4-4d38-9405-230357d699eb.png" alt="image.png" style="zoom: 67%;" />

> :x:
>
> 都有可能

若红黑树插入一个元素后，黑高度增加，则双红修正过程中没有拓扑结构变换，只有重染色操作。（2016.1期末）

> :white_check_mark:
>
> 黑高度增加的是RR-2双红修正

红黑树的插入或删除操作，都有可能导致 **Ω(logn) 个节点的颜色反转**。（2019.1期末）

> :white_check_mark:
>
> 插入的RR-2每次给三个结点染色，故有可能导致 $\Omega(\log n)$ 结点颜色反转
>
> 删除的BB-2-B每次给一个结点染色，，故有可能导致 $\Omega(\log n)$ 结点颜色反转
>
> P.S. 就分摊意义而言，重平衡需要重染色的节点不超过 $O(1)$

对红黑树进行插入操作时，进行双红修正，黑高度增加，则____发生重染色，____发生结构调整。（2012.6期中）

> 必然发生重染色，必然不发生结构调整

依次插入[0,N)

1、写出N=9的红黑树

2、写出树高H和N的通项公式（据说习题解析里有）

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1607917313582-c17e0173-5b4b-42f5-ac86-ea2637e774c9.png?x-oss-process=image%2Fresize%2Cw_1920%2Climit_0" alt="红黑树-第 2 页 (1).png" style="zoom: 40%;" />

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1606496986223-96998218-2ead-423c-94d2-5044963bf658.png" alt="image.png" style="zoom:50%;" />

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1606475419880-df9634c4-15a0-4ebf-8261-1ed0040698e1.png" alt="image.png" style="zoom: 50%;" />

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1606475455156-5e37f32f-02dd-4f32-bcaf-7a117e75db24.png" alt="image.png" style="zoom: 50%;" />

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1606475431259-97b0b39b-8d17-49c1-ace0-212d268581a3.png?x-oss-process=image%2Fresize%2Cw_823%2Climit_0" alt="image.png" style="zoom: 80%;" />

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1606475498155-d36b3e32-52a9-49e6-9ab7-fe83d91a121d.png" alt="image.png" style="zoom: 50%;" />

> T~8-13~

红黑树结构，如果不显式记录颜色，通过隐式记录应该如何操作？（2020.1期末）

> 像AVL一样引入平衡因子，定义为：每个节点为根的子树，其**最大高度不超过最小高度的两倍**（高度不超过黑高度的两倍）

高度为 3 的 5 阶 B‐树，至多可存放（	）个关键码，至少需存放（	）个。（2010-521样卷）

> 5阶即(3, 5)-树，关键码（除根节点）范围是(2, 4)
>
> 至多：每个结点4个关键码，5个子树，$(1+5+25)\times 4=124$
>
> 至少：根节点1个，2个子树，其他结点2个关键码，3个子树$(1+2\times 2+2\times3\times 2)=17$
>
> 代公式的话，$log_5(N+1)\leqslant 3\leqslant\log_3\left(\dfrac{N+1}2\right)+1$

将 N 个关键码按随机次序插入 B 树，则期望的分裂次数为 O(log^2^ N)。（2016.1期末）

> :x:
>
> N个关键码若干次插入后，高度为h，内部节点为n，则整个过程分裂操作总次数为n-h
>
> T~8-6~

我们知道，BTree:solveOverflflow()和BTree:solveUnderflflow()在最坏情况下均需下界(logn)的时间，然⽽在B-树⼈意⾜够⻓的⽣命期内，就分摊意义而言二者都仅需要O(1)时间。（2014期末）

![image.png](https://cdn.nlark.com/yuque/0/2020/png/1458680/1608800775325-a66606fa-2cdf-4b37-ad2d-18f4f33383ca.png?x-oss-process=image%2Fresize%2Cw_746%2Climit_0)

> :white_check_mark:
>
> 合并和分裂总次数是$O(n)$的，分摊复杂度即$O(1)$

B树的任一非叶节点内，每个关键码都存在直接后继，且必然来自某个叶节点。（2019.1期末）

> :white_check_mark:

人类拥有的数字化数据数量，在 2010 年已达到 ZB(2^70^ = 10^21^) 量级。若每个字节自成一个关键码，用一颗 16 阶 B-树存放，则可能的高度为（ ）（2016.1期末）

A. 10

B. 20

C. 40

D. 80

E. >80

> B
>
> $\log_{16}(2^{70}+1)\leqslant h\leqslant\log_8\left(\dfrac{2^{70}+1}2\right)+1$，约18~24

将[23, 1481)区间内的整数组成一个2-3-B树，且根节点只有一个关键码，则最终该B-树的高度至少是（2012.6期中）

A、7 	B、8 	C、9 	D、10 	E、以上都不对

> A
> | 高度   | 0    | 1    | 2    | 3     | ...  | h        |
> | ------ | ---- | ---- | ---- | ----- | ---- | -------- |
> | 结点数 | 1    | 2    | 2×3  | 2×3×3 |      | 2×3^h-1^ |
>
> $N+1\leqslant 2\times3^{h-1}$，$h$ 最小为 $7$

考查包含2018个关键码的16阶B-树，约定根节点常驻内存，且在各节点内部采用顺序查找。（2019.1期末）

a) 在单次成功查找的过程中，至多可能需要读多少次磁盘？请列出估算的依据。

b) 在单次成功查找的过程中，至多可能有多少个关键码需要与目标关键码做比较？请列出估算的依据。

> a) B树最高（向下取整） $\log_8(2019/2)+1=4$，**根节点常驻内存，外部节点不计入访存**，故至多4-1=3次访存
>
> b) B数最矮（向上取整） $\log_{16}(2019)=3$，此时B树每层结点最多，每次都比较到最后一个结点（沿右侧链查找），至多比较3×15=45次（看来根节点不算）

选一小题做即可（2020.1期末）

1)2019阶的B树 插入某关键码后树高增加，此时再次删除该关键码后树高一定降低? 给出证明或反例

> 各层结点全是满的，一路上溢到根节点，最后才会导致树高增加
>
> 每次上溢都是取下标为s=m/2的关键码上升一层。m为奇数时，左右孩子均为 (m-1)/2 个；m为偶数时，左右孩子分别为 m/2 和 m/2-1 个
>
> 若m为奇数，根结点就是插入的新关键码，先与其succ交换，再将其删除。这一路上各节点关键码数都是(m-1)/2，删除都会向父结点借关键码，最终传递至根结点，导致树高再降低回来。即m为奇数，必降低
>
> 若m为偶数，则未必

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1607430920668-96ee0759-c67f-4b1a-b160-3d56a3bbf4b7.png?x-oss-process=image%2Fresize%2Cw_1342%2Climit_0" alt="image.png" style="zoom:50%;" />

2)2019阶的B树 删除某关键码后树高降低，此时再次插入该关键码后树高一定增加? 给出证明或反例

> 类似地，m为奇数删除再插入必增加，m为偶数未必

如果每个结点占用 2 个磁盘块因而需要 2 次磁盘访问才能实现读写，那么在一棵有 n 个关键码的 2m 阶 B 树中，每次搜索需要的最大磁盘访问次数是多少？（2010年期末A卷-感觉此卷风格不是邓公）



给定一棵保存有 n 个关键码的 m 阶 B 树。从某一非叶结点中删除一个关键码需要的最大磁盘访问次数是多少？（2010年期末A卷-感觉此卷风格不是邓公）



由 2010 个节点组成的完全二叉树，共有（	）个叶节点。（2010-521样卷）

> 1005

由 5 个互异节点组成、先序遍历序列与层次遍历序列相同的 BST，共有(	)棵。（2010-521样卷）

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1608191072280-f28f9d14-e509-4a23-b4f1-f78c1abc7cda.png?x-oss-process=image%2Fresize%2Cw_430%2Climit_0" alt="image.png" style="zoom:67%;" />

> 左右子树均存在，且左子树除了根节点外，还有再下一层的节点，遍历就不同（如上图）
>
> 根节点为1：2棵
>
> 根节点为2：2棵
>
> 根节点为3：C(2)×C(2=)4棵
>
> 根节点为4：C(3)=5棵
>
> 根节点为5：2棵
>
> C(5)-2-2-4-5-2=42-15=27棵

在由 2010 个节点组成的二叉树中，若单分支节点不超过10个，则对其做迭代式中序遍历时辅助栈的容量为（	）即足够。（2010-521样卷）

![image.png](https://cdn.nlark.com/yuque/0/2020/png/1458680/1607595943599-26a50f9f-13ac-48d7-b7ee-83973d6bd645.png?x-oss-process=image%2Fresize%2Cw_378%2Climit_0)

> 1010
>
> 图上得再画一个叶节点
>
> 最左侧通路1011个节点，最多1010个节点入栈，栈1010就够了

在 BST 中删除两个节点（7B3），则无论先删除哪个节点，最终 BST 的拓扑结构均相同。（2016.1期末）

> :white_check_mark:

如果元素理想随机，那么对二叉搜索树做平衡化处理，对改进其渐进时间复杂度并没有什么卵用。（2016.1期末）

> :x:
>
> BST的理想随机树高有两种计量方式，BBST对于BST的随机组成方式的复杂度改进是有卵用的

由同⼀组共n个词条构成的任意两棵BST，经O(logn)次zig或zag旋转之后，必定可以相互转换。（2014期末）

> :x:
>
> 不超过 n-1 次旋转调整可化最左侧通路，因此不超过 2n-2 次旋转，两树可彼此转换，是 $O(n)$
>
> T~7-14~和T~7-15~

在 kd-search 中，查找区间 R 与任一节点的 4 个孙节点（假设存在）对应区域最多有 2 个相交。（2016.1期末）

> :white_check_mark:
>
> T~8-16~

带权重的最优PFC编码树不仅未必唯一、拓扑结构未必相同，甚至树高也可能不等。（2019.1期末）

> :white_check_mark:
>
> 暂时未找到例子（）P~142~有一个树高增加，wald()反而减少的例子，看来最优PFC树高不等是有可能的罢
>
> 不带权重的话，应该不能不等

若调用BST::remove(e) 将节点x 从常规BST中删除，则所需的时间为被删除之前x的深度。 （2019.1期末）

> :x:
>
> 如果被删除节点有左右孩子，要和它的succ交换，找到succ和更新高度updateHeightAbove()都是交换节点succ的深度

由 5 个互异节点构成的不同的 BST 共有（ ）个  （2016.1期末）

A. 24

B. 30

C. 36

D. 42

E. 120

> D
>
> C(5)=42
>
> 除了n个叶节点的真二叉树种类是C(n-1)以外，都是C(n)

以下数据结构，在插入元素后可能导致 O(log n) 次局部结构调整的是（ ）（2016.1期末）

A. AVL

B. B-树

C. 红黑树

D. 伸展树

E. 以上皆非

> BD
>
> B树连续上溢、Splay旋转到根
>
> 注意红黑树的RR-2会上溢，但RR-2不旋转，只染3个色，不会有结构调整

以下数据结构，空间复杂度为线性的是（ ）（2016.1期末）

A. 2d-tree

B. range tree

C. interval tree

D. segment tree

E. 以上皆非

> ACD

在 BST 中查找 365，以下查找序列中不可能出现的是（ ）（2016.1期末）

A. 912, 204, 911, 265, 344, 380, 365

B. 89, 768, 456, 372, 326, 378, 365

C. 48, 260, 570, 302, 340, 380, 361, 365

D. 726, 521, 201, 328, 384, 319, 365

> BD
>
> B：372, 326, 378段，378不可能在372的左子树中
>
> D：328, 384, 319段，319不可能在328的右子树中

以下数据结构中，空间复杂度不超过线性的有（ ）。（2014期末）

\- A）2d-tree

\- B）3d-tree

\- C）2D range tree

\- D）interval tree

\- E）segment tree

\- F）priority search tree

> ABDEF
>
> 2D range tree空间复杂度 $O(n\log n)$

若将有根有序的多叉树T所对应的二叉树记作B(T)，则T的（）遍历序列与B(T)的（）遍历序列完全相同。（2014期中）

 A）后序....后序     B）后序....中序     C）层序....先序     D）先序....先序     E）以上皆非

> D
>
> 可举例。结论就是**多叉树先序遍历是不变的**
>
> 对应二叉树，指的就是通过长子-兄弟法转成的二叉树
>
> 先序遍历的顺序是父-长子-长子下面的子树-兄弟，与原多叉树遍历是一样的
>
> 而后序遍历，举个栗子：原多叉树（实际是二叉树）根节点A，子节点B、C，长子兄弟法后高度变为2，C成为B的右孩子
>
> 原后序遍历为BCA，而转换后的后序遍历则是CBA

在二叉树（）遍历序列中，祖先节点一定位于其后代节点之前。（2014期中）

A）先序  B）中序      C）后序      D）层次       E）以上皆非

> AD

在Huffman编码算法中，若每次（超）字符合并时均保证左兄弟不小于右兄弟，则在所生成的编码树的层次遍历序列中，（）必然按其频率的非升次序排列。（2014期中）

A）（仅）叶节点      B）（仅）内部节点       C）所有节点       D）以上皆非  

> C
>
> 层序遍历总是大的在前，要是一个较大的节点位于右侧的子树，那它必然更高
>
> （非升是大的在前）P~144~有一个例子可以参考（虽然给出的构造并不满足要求）

在由2014个节点构成的完全二叉树做层次遍历，辅助队列的容量至少应为（   ）；在整个遍历过程中，辅助队列的规模共在（  ）步迭代中处于这一规模。（2014期中）

> 1007	2
>
> 偶数（最后一个内部节点度为1）2次，分别是第1007和第1008个节点；奇数（如2023个节点，是真完全二叉树）1次，出现在第1012个节点处
>
> T~5-18~

对以下各搜索树进行删除操作，哪些树可能会经过Ω(logn)次局部调整，其中n为关键码的数量。（2012.6期中）

A、AVL B、伸展树 C、红黑树 D、B-树 E、都不会

> ABD
>
> 局部调整，指拓扑调整（AVL失衡节点是1个，重平衡要O(logn)；Splay全是O(logn)；B树旋转、合并也可能传播至树根）
>
> 不过按说B树这个系数应该很小（doge）
>
> B树树高：$\log_m(N+1)\leqslant h\leqslant\log_{\lceil m/2\rceil}\left(\dfrac{N+1}2\right)+1$

在不改变 BST 和 BinNode 定义的前提下（BinNode 仅存储 parent, data, lc,rc），设计算法，使得从节点 x 出发，查找值为 Y 的节点 y 的时间复杂度为 o(d)， d 为节点 x 与 y 的距离。要求利用树的局部性，复杂度与总树高无关，否则将不能按满分起评。（2016.1期末）

函数定义式：参量为 BinNode x,y,T，返回值为 BinNode 类型，函数名 **fingerSearch**

(a) 说明算法思路

(b) 写出伪代码

(c) 在图中画出由值为 6 的点查找值为 17 的点的查找路径

(d) 说明算法时间复杂度为 O(d)（若无法达到，说明困难在哪）

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1604215900105-b783ac07-cf3b-4910-913e-d7b8f4e75e6a.png" alt="img" style="zoom: 67%;" />

> ？？？[手指树](https://oi-wiki.org/ds/finger-tree/)
>
> 复杂度 $O(d)$，考到直接寄

以下代码中的int parent[0,n)，是采用父结点表示法存储的任意一颗有根（但未必有序）的多叉树。（2014期中）

```cpp
int f(int parent[], int n) {
    int h = -1;
    for(int i = 0; i < n; i++)
        h = _max(h, g(parent, i));
    return h;
}

int g(int parent[], int i) {
    if(-1 == i)
        return -1;
    return 1 + g(parent, parent[i]);
}
```

A）以上算法f()和g()分别是何功能？

> g[]：计算到根节点的距离，即深度
>
> f[]：计算多叉树的最大深度，即树高

B）在最坏情况下，算法f()的渐进时间复杂度是多少？最坏情况何时出现？

> 单链，此时时间复杂度达 $1+2+\cdots+n=O(n^2)$

C）在不做任何删除的前提下，试通过增加尽可能少的代码，使f()的运行时间降至O(n)，空间不超过O(n)。

> DP:
>
> ```cpp
> int dp[n];
> 
> int f(int parent[], int i) {
>     for(int i = 0; i < n; i++)
>         dp[i] = -1;
>     int h = -1;
>     for(int i = 0; i < n; i++)
>         h = _max(h, g(parent, i));
>     return h;
> }
> 
> int g(int parent[], int i) {
>     if(dp[i] > 0)
>         return dp[i];
>     if(-1 == i)
>         return -1;
>     return dp[i] = 1 + g(parent, parent[i]);
> }
> ```

（2020.1期末）

任给一棵二叉树S和二叉树T，设计一种时间复杂度为O(|S|+|T|)的算法，判断S是否与T的某棵子树同构（节点只存了rc, lc）。

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1607598966741-6ff162ca-c374-44f5-8546-96ab09142ab3.png" alt="image.png" style="zoom:50%;" />

> 同构：若S和T可通过若干次左右孩子互换，即可转化成另一棵二叉树，则称两树同构

给出

（1）算法的简要描述；

> 首先在T中搜索是否存在与S根节点值相同的结点S’
>
> 若存在S’，则比较S与S’是否同构
>
> - S和S’都只有一棵子树，判断这棵子树是否同构
>
> - - S和S’左子树均为空，判断它们的右子树是否同构
>   - S和S’右子树均为空，判断它们的左子树是否同构
>   - S左为空，S’右为空，判断S的右子树与S’的左子树是否同构
>   - S右为空，S’左为空，判断S的左子树与S’的右子树是否同构
>
> - S和S’的左右子树均不为空
>
> - - 若S的左孩子值与S’左孩子值相等，判断S的左子树与S’的左子树且S的右子树与S’的右子树是否同构
>   - 若S的左孩子值与S’右孩子值相等，判断S的左子树与S’的右子树且S的右子树与S’的左子树是否同构

（2）算法的具体步骤；

（3）正确性的证明。



算法设计题（每小题 5 分，共 15 分）（2010年期末A卷-感觉此卷风格不是邓公）

```cpp
设中序线索化二叉树的类声明如下：
template <class Type>  
struct ThreadNode { //中序线索化二叉树的结点类
    int leftThread, rightThread; //线索标志
    ThreadNode<Type> *leftChild, *rightChild; //线索或子女指针
    Type data; //结点中所包含的数据
};  
template <class Type>  
class inOrderThreadTree { //中序线索化二叉树类
  public:
    ThreadNode<Type> * getRoot ( ) { return root; }
    //其他公共成员函数
    ……
  private:
    ThreadNode<Type> *root; //树的根指针
 };
```

了解什么是线索二叉树 ：https://blog.csdn.net/uncleming5371/article/details/54176252

试依据上述类声明，分别编写下面的函数。

(1) ThreadNode<Type> *getPreorderFirst (ThreadNode<Type> *p);

//寻找以 p 为根指针的中序线索化二叉树在前序下的第一个结点。

> ```c++
> template <class Type>
> ThreadNode<Type> *getPreOrderFirst(ThreadNode<Type> *p) {
>        return p;
> }
> ```

(2) ThreadNode<Type> *getPreorderNext (ThreadNode<Type> *p)  

//寻找结点*p 的在中序线索化二叉树中前序下的后继结点。

> ```cpp
> template <class Type> 
> ThreadNode<Type> *getPreorderNext (ThreadNode<Type> *p) {
>        if ( p->leftThread == 0 )	reutrn p->leftChild;	// 有左孩子
>        if ( p->rightThread == 0 )	reutrn p->rightChild;	// 无左孩子，有右孩子
>        while ( p->rightThread != 0 && p->rightChild != NULL )	// 线索树后继节点非空
>            p = p->rightChild;
>        return p->rightChild;
> }
> ```

(3) void preorder (inOrderThreadTree<Type>& T);

//应用以上两个操作，在中序线索化二叉树上做前序遍历。

>```cpp
>template <class Type>
>void preorder( inOrderThreadTree<Type>& T ) {
>        ThreadNode<Type> *p = getRoot();
>        p = getPreOrderFirst( p );
>        while ( p != NULL ) {
>             cout << p->data <<endl;
>             p = getPreorderNext( p );
>        }
>}
>```

## 堆

在使用 Heapify 批量建堆的过程中，改变同层节点的下滤次序对算法的正确性和时间效率都无影响。（2016.1期末）

> :white_check_mark:

Floyd建堆，每次同层之间下滤顺序打乱，不影响复杂度和正确性。（2014期末补充）

> :white_check_mark:

相对于二叉堆，尽管多叉堆的高度更低，但无论是下滤一层还是整个下滤过程，时间成本反而都会增加。（2014期末）

> :x:
>
> 多叉堆堆高降低至 $O(\log_d n)$，下滤增加至 $d\cdot\log_dn=\dfrac d{\ln d}\cdot\ln n$
>
> 如此一来，三叉堆下滤成本仅 $1.89\log_2n$，比二叉堆的 $2\log_2n$ 要小，四叉堆的系数则与二叉堆相同
>
> 注：稠密图PFS的优化，使用 $2+\dfrac en$ 叉堆，性能 $O(e\log_{2+\frac en}n)$ 
>
> 在稀疏图近似为二叉堆（明明是三叉堆？？？）$O(n\log n)$，稠密图近似为 $n$ 叉堆 $O(n^2)$

完全二叉堆删除元素在最坏情况下时间复杂度为 O(log n)，但平均情况下仅为 O(1)。（2016.1期末）

> :x:
>
> 插入操作才是最坏情况下时间复杂度为 O(log n)，但平均情况下仅为 O(1)。
>
> 而删除操作平均为为O(log n)

多叉堆比二叉堆插入慢，删除快。（2014期末补充）

![image.png](https://cdn.nlark.com/yuque/0/2020/png/1458680/1607516497854-e55ee22a-1572-4b01-9490-7a7f54f20a98.png?x-oss-process=image%2Fresize%2Cw_517%2Climit_0)

> :x:
>
> 插入是上滤，插入更快
>
> 删除是下滤，三叉堆删除更快，四叉堆一样，五六七.....叉堆的删除慢

与二叉堆相比，多叉堆 delMax() 操作时间复杂度更高。（2016.1期末）

> :x:

相对于同样规模的完全二叉堆，多叉堆delMax() 操作的时间成本更低。（2019.1期末）

> :x:

PFS每次调用priorUpdate()，总复杂度O(n) 。（2014期末补充）

> :x:
>
> PFS每次可能会多次调用prioriUpdate()，累计调用次数为**所有顶点出度的总和**，即 $O(e)$

PFS过程中，尽管每一步迭代都可能多次调用prioUdpater() ，但累计不过O(e)次。（2019.1期末）

> :white_check_mark:

若用完全二叉堆来实现PFS ，则各顶点在出堆之前，深度只可能逐步减少（或保持）而不致增加。（2019.1期末）

> :x:
>
> 取出堆顶时，要将堆顶元素和最后一个元素交换，对这个被换上来的元素来说，它的下滤就是深度增加的过程

对于任何⼀颗⼆叉树T，其右、左⼦树的规模之⽐“λ=T.re().size()/T.le().size()”称作右偏率。对于（常规）⾼度同为h的AVL树（A），红⿊树（R），左式堆（L），若分别考察其λ所能达到的最⼤值，则在h⾜够⼤之后，三者按此指标的排列次序应是（ ）。（2014期末）

\- A） L<R<A

\- B） L<A<R

\- C） R<A<L

\- D） A<R<L

\- E） 以上皆⾮

> D
>
> 高h的左式堆，极端情况下左孩子仅一个，右孩子h个（有h-1个全是右子节点的左孩子），依旧满足左偏性，λ可达h
>
> AVL接近1:1
>
> 红黑树树高不超过黑高度的两倍，所以可以接近2:1

二叉堆中某个节点秩为 k，则其兄弟节点（假设存在）的秩为（ ）（2016.1期末）

A. k + 1

B. k -1

C. k + (-1)^k^

D. k - (-1)^k^

E. 以上皆非

> D
>
> 0	1/2	3/4	5/6	……
>
> 注意根节点秩0，深度0

给定一个有 n 个数据元素的序列，各元素的值随机分布。若要将该序列的数据调整成为一个堆，那么需要执行的数据比较次数最多是多少？（2010年期末A卷-感觉此卷风格不是邓公）

> $n$ 个节点的堆，树高 $h=\log_2 n$
>
> 对于深度为 $h-1$ 的节点（至多 $2^{h-1}$ 个），比较2次，交换1次，总交换次数 $1\cdot2^{h-1}$ 次
>
> 对于深度为 $h-2$ 的节点（共 $2^{h-2}$ 个），比较4次，交换2次，总比较次数 $2\cdot2^{h-2}$ 次
>
> 对于深度为 $h-3$ 的节点（共 $2^{h-3}$ 个），比较6次，交换3次，总比较次数 $3\cdot2^{h-3}$ 次
>
> ……
>
> 总交换次数 $2^{h+1}-h-2$，总比较次数 $2^{h+2}-2h-4$

与胜者树相比，败者树在重赛过程中，需反复将节点与其兄弟进行比较。（2016.1期末）

> :x:
>
> 败者树重赛只需要与父节点比较，胜者树才需要与兄弟比较

胜者树的根节点即是冠军，而败者树的根节点即是亚军。（2019.1期末）

> :x:
>
> 败者树根节点不一定是亚军，只是两子树冠军之间的较小者，有可能一棵子树内的元素普遍很大（最小为冠军），都算不上全局的亚军（记录冠军的是额外的节点）
>
> 谔谔，亚军是什么，有没有可能是现实生活中的亚军——那这道题有什么意义

对于左式堆 A 和 B，合并后所得二叉堆的右侧链元素一定来自 A 和 B 的右侧链。（2016.1期末）

> :x:
>
> 可能交换

采用Crane算法将左式堆A与B合并为左式堆H ，H右侧链上的节点未必都来自A或B的右侧链。（2019.1期末）

> :white_check_mark:

左式堆中每一对兄弟节点的高度尽管未必“左大右小”，但左兄弟至少不低于右兄弟的一半。（2019.1期末）

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1606969457905-d710fb4c-15bf-4361-a740-78e61956c5d1.png" alt="image.png" style="zoom:67%;" />

> :x:
>
> 左式堆的右偏率可以高达 $h$，如图反例要记住

A B两个左式堆合并成H，H的右子树一定来自A或B的右子树？（2012.6期中）

> :x:

有 2015 个节点的左式堆，左子堆最小规模为（ ）（不计外部节点）（2016.1期末）

A. 10

B. 11

C. 1007

D. 1008

E. 以上皆非

> E
>
> 1

左式堆，左边一定大于等于右边的是（2012.6期中）

A.NPL   B.规模      C.高度       D.外部节点数

> A

左式堆

1）0,1,2.....2014，问左子树至少有几个节点，右子树最高多高（1,2012）

> 左子树至少1个结点，右子树最高2012

2）画出示意图

> 前面有

3）按什么顺序插入0..2014，能成为画的样子

> 2014，2013，0，1，2，...，2012
>
> 左式堆合并的时候，根节点较大的堆，其根节点作为合并后的根节点；合并完检查左倾性
>
> 2014,2013插入后，以2014为根，2013为左子树的堆已经形成，并且在后续操作中，根节点左倾性始终没有被破坏
>
> 考虑右子树
>
> 插入0后，0为根节点
>
> 插入1后，1为根节点，0挂1左子树
>
> 插入2后，2为根节点，1-0挂2左子树，依次类推

## 图

在图的优先级搜索过程中，每次可能调用多次 prioUpdater，但累计调用次数仍为O(e)。（2016.1期末）

> :white_check_mark:
>
> 等于各点出度和

如果把朋友圈视为一无向图，那么即使 A 君看不到你给 B 点的赞，你们仍可能属于同一个双联通分量。（2016.1期末）

> :white_check_mark:

设在有向图G中，存在⼀条⾃顶点v通往u的路径。于是，若在某次DFS中 有dTime(v) < dTime(u)，则这次DFS所⽣成的DFS森林中，v必定是u的祖先。（2014期末）

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1606682332486-2fcac981-4b7f-482c-a635-c08265fb1ccc.png?x-oss-process=image%2Fresize%2Cw_443%2Climit_0" alt="image.png" style="zoom:80%;" />

>:x:
>
>若不是路径，而且就有这样一条边，那么 dTime(v) < dTime(u) 的是FORWARD，而CROSS边 dTime(v) > dTime(u)
>
>但如果是路径，就未必了

在图DFS() 算法中的default分支，将dTime(v)<dTime(u) 改为dTime(v)<fTime(u) 同样可行。（2019.1期末）

> :white_check_mark:
>
> default判断两种边：前向边和跨边，一种完全在括号内，一种完全在括号外，修改后判定还是一样的

在⽆向连通图G中选定⼀个顶点s，并将各顶点v到s的距离记作dist(v)（特别地，dist(s)=0）。于是在G.Bfs(s)过程中，若辅助队列为Q，则dist(Q.front()) + 1 >= dist(Q.rear()) 始终成⽴。（2014期末）

> :white_check_mark:
>
> 通过“BFS=层序遍历理解，深度差不超过1

我们知道，因同⼀顶点的邻居被枚举的次序不同，同⼀有向图G所对应的DFS森林未必唯⼀。然⽽只要起始于G中某顶点s的某次DFS所⽣成的是⼀棵树，则起始于s的任何⼀次DFS都将⽣成⼀棵树。（2014期末）

> :white_check_mark:

BFS、DFS的复杂度可能不是O(N+E)。（2014期末补充）

> :white_check_mark:
>
> 邻接表 $O(N+E)$
>
> 邻接矩阵 $O(n^2)$

经过k条backward边就有k个环。（2014期末补充）

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1604054932941-f60c5b01-15e6-4ca3-9447-e2a7b64fb40a.png" alt="image.png" style="zoom:50%;" />

> :x:
>
> 这个也考过了，环数个数≥后向边数

有向图经DFS后若共有k条边被标记为BACKWARD，则它应恰有k个环路。（2019.1期末）

> :x:

对于同一无向图，起始于顶点s的DFS尽管可能得到结构不同的DFS树，但s在树中的度数必然固定。（2019.1期末）

> :white_check_mark:

对于正权值有向图，如果把所有的边权都平方之后，Dijkstra算法得到的最短路径树方案不变。（2012.6期中）

![image.png](https://cdn.nlark.com/yuque/0/2020/png/1458680/1608090150906-2e77eaba-8936-41cf-bbbb-8d9eaad022fc.png?x-oss-process=image%2Fresize%2Cw_421%2Climit_0)

> :x:
>
> 想想就不可能嘛

有向图的DFS不仅在起点任意，而且每⼀步迭代往往都会有多个顶点可供选择，故所生成的DFS森林并不唯⼀确定，且其中所含（ ）的数量也可能不同。（2014期末）

\- A）树边

\- B）前向边

\- C）后向边

\- D）跨越边

\- E）以上皆非

> BCD
>
> 森林里的树棵树是固定的，故树边也不变

在有向图 G 中，存在一条自顶点 V 通向 u 的路径，且在某次 DFS 中有 dTime[v]<dTime[u]，则在这次 DFS 所生成的 DFS 森林中，v 是否一定是 u 的祖先？若是，请给出证明；若不是，请举出反例。（2016.1期末）

> :x:
>
> 反例即v→s→u，同时还有一条s→v形成一个环
>
> 从s开始DFS，s(1, 6)，v(2, 3)，u(4, 5)，v和u有通路且dTime[v]<dTime[u]，但没有祖先、孩子关系

有向图DFS遍历 (1x6+2x5=16)（2012.6期中）

给了一个7节点的有向图，节点标号为1~7，指定当存在歧义性的时候优先考虑标号小的节点。最后一共有6条树边(T)，1条跨边(C)，两条前向边(F)和两条后向边(B)，而且这题的分值写的是16+25=16，大家懂的。

## 散列

若元素理想随机，则用除余法作为散列函数时，即使区间长度不是素数，也不会影响数据的均匀性。（2016.1期末）

> :white_check_mark:

采用单向平方策略的散列表，只要长度M是素数，则每一组同义词在表中都不会超过 $\lfloor M/2\rfloor$ 个。（2019.1期末）

![image.png](https://cdn.nlark.com/yuque/0/2020/png/1458680/1607509697225-bc45b1db-0547-42be-9005-308ae0cd1589.png?x-oss-process=image%2Fresize%2Cw_527%2Climit_0)

> :x:
>
> 如 $\{0,\,10,\,20,\,\cdots\}$，M 取 $10$，则依次放入 $\{0,\,1,\,4,\,9,\,6,\,5\}$ 等，可以超过 50%

将n个词条逐个插入一个容量为M 、采用线性试探策略、初始为空的散列表，n<M，则无论它们的插入次序如何，最终的*平均成功查找长度都必然一样*。（2019.1期末）

> :white_check_mark:

采用双向平方试探策略时，将散列表长度取作素数 M = 4k + 3，可以极大地降低查找链前 M 个位置冲突的概率，但仍不能杜绝。（2016.1期末）

> :x:
>
> M=4K+3可以保证前M项互异

我们知道，采取双向平方试探策略时，应该将散列表取作素数M = 4k + 3。尽管这样可以极大降低查找链前M个位置发生冲突的概率，但仍不能杜绝。（2014期末）

> :x:

与 MAD 相比，除余法在（ ）有缺陷（2016.1期末）

A. 计算速度

B. 高阶均匀性

C. 不动点

D. 满射性

E. 以上皆非

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1606561520212-f615c301-3fb5-4a25-ad53-6747587f6c2f.png" alt="image.png" style="zoom:67%;" />

> BC

相对于除余法，MAD法在（ ）方面有所改进。（2014期末）

\- A）计算速度

\- B）高阶均匀性

\- C）不动点

\- D）满射性

\- E）以上皆非

> BC

（ ）属于针对闭散列策略的冲突排解方法。（2014期末）

\- A）multiple slots

\- B）linear probing

\- C）overflflow area

\- D）separate chaining

\- E）quadratic probing

\- F）double hashing

> BEF
>
> 线性探测，平方探测，重散列

对闭散列 [0, M), M = 2S，采用如下冲突排列解决方法：（2016.1期末）

• 初始时，c = d = 0

• 探查 key 冲突时，c ← c + 1, d ← d + c，探查 H[(key+d)%M]

则这种算法是否可以保证空间能被 100% 利用？若是，请给出证明；若不是，请举出反例。（**不能保证100%利用**，证明目前看不懂）<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1604215815328-dd2e6dc8-d84a-4f6f-8072-5a76d58fd255.png" alt="img" style="zoom:80%;" />

![image.png](https://cdn.nlark.com/yuque/0/2020/png/1458680/1607609369479-d7edde79-820a-455f-aaae-8f5703deda25.png?x-oss-process=image%2Fresize%2Cw_458%2Climit_0)

散列表（2014期末补充）

1、有若干数字，遵循模13、双向平方、懒惰删除，填写每一次操作后的散列表

2、最后问询问一个数字会发生什么情况（因为所有可用的都满了会产生死循环）



封闭散列（2019.1期末）

某散列表H[0,M=2^s) 采用封闭散列策略（初始令c=d=0 )：对于任何key ，首先试探H[key%M] ；以下，只要冲突，就令c <- c+1 再d <- d+c ，并继而试探H[(key+d)%M]  。以M=2^4=16 为例，关键码key=27 的

前五个试探位置依次是：11、12、14、1、5。但如同对于平方试探策略，我们首先需要确认，这种试探序列是否总能覆盖所有桶单元。若是，请给出证明；否则，试举一（s 和key组合的）反例。



散列表采用取余法+单向平方试探，M=7001，若某一时刻桶中仅有1481个数，却发生了重散列，为什么? 请简单说明，并大致绘制出表中当前状态。（2020.1期末-回忆版本1）

> 发生了重散列，说明 $\lambda>0.5$
>
> 散列内至少有(7001+1)/2-1481=2020个懒惰标记桶，试探链构成了封闭回路（*向上取整*）

一个容量M=4079（素数）的哈希表，使用双向平方试探法，共插入了1231个词条，但在下一次插入时触发了rehash操作，问该哈希表此时的状态及rehash的原因。（2020.1期末-回忆版本2）

> 4079=4K+3，必然可以保证查找链的前M项互异，与上题不同，这里没有装满是不会重散列的
>
> rehash说明散列中至少有4079-1231=2828个懒惰标记桶

散列冲突 (20)（2012.6期中）

给定M=17的散列表，给定了基本策略：求余法、单向平方试探、懒惰删除。

进行了一系列操作，写出每次操作之后的散列表状态。

一开始put进去7个数，中间有一步put(1481)，第八个操作remove(1481)，最后一个操作put()一个数进去。

第一问，如果在上面操作之后查询1481，问将会出现什么情况。

第二问，在不改变基本策略的基础上，给出两种方案解决上述问题。

注意，不能改变那三个基本策略。



跳转表期望高度O(logN)。（2014期末补充）

> :white_check_mark:
>
> 注意区分“跳转表的期望高度”与“各塔的期望高度”

在 n 个节点的跳转表中，塔高的平均值为 O(log n)。（2016.1期末）

> :x:
>
> 平均塔高就是期望塔高

在存有n个词条的跳转表中，各塔高度的期望值为Θ(logn) 。

> :x:
>
> 是 $2$

将硬币换成理想的骰子，且约定投出“6”时新塔才停止生长。于是对于同样存放n个元素的跳转表而言，（ ）的期望值将有所增长，但仍保持O(1）。（2014期末）

\- A）查找过程中，在同一高度连续跳转的次数

\- B）查找过程中，由“向右”到“向下”转折的次数

\- C）查找过程中，沿同⼀座塔连续下行的层数

\- D）（在查找定位之后）为创建⼀座新塔所需的时间

![image.png](https://cdn.nlark.com/yuque/0/2020/png/1458680/1608626100857-01f75ffd-3564-4edb-8bb5-fbd13c83a112.png?x-oss-process=image%2Fresize%2Cw_586%2Climit_0)

> CD
>
> A：横向跳转是 $(1-p)^kp$，原继续生长的概率 $p=0.5$，期望是 $\dfrac{1-p}{p}=1$，现在 $p=5/6$，期望是 $1/5$，减小了
>
> B：从向右到向下转折的次数正比于跳转表的高度，$O(\log n)$（总时间复杂度是 $O(\log n)$，而每次横向跳转是 $O(1)$ 的，纵向塔高也是 $O(1)$ 的，故转折需要有 $O(\log n)$）
>
> C：塔高分布是 $(1-p)p^{k-1}$，期望从 $\dfrac1{1-p}=2$ 变为 $6$，增加了
>
> D：也与塔高相关，变成 $6$ 增加了

## 串

若 KMP 算法不使用改进版的 next 表，最坏情况下时间复杂度可能达到 O(mn)。（2016.1期末）

> :x:
>
> KMP稳定 $O(n+m)$

在BM算法中，对于任一模式串P，0 < gs(j) <= j 对于每个0 <= j < |P| 都成立。（2014期末）

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1606565317943-7ecc9243-3493-4e45-a547-8ec60cfee473.png" alt="image.png" style="zoom:50%;" />

> :x:
>
> gs表是失配后需要的移动量
>
> 如上图j=12，失配后直接移动一个串的长度

字符集变大，概率平均，则bc表比next表好。（2014期末补充）

> :white_check_mark:
>
> 单次匹配成功率小，趋向O(n/m)

相对于KMP算法而言，BM算法更适合于大字符集的应用场合。

> :white_check_mark:

无论是单独借助BC[]表或GS[]表，BM算法在最好情况下都只需要O(|T|/|P|)=O(n/m) 时间。（2019.1期末）

> :white_check_mark:
>
> 而最坏情况，BC+GS后即可限定在O(n+m)，否则可达O(nm)

在KMP匹配的过程中，当主程序运行到i,j的状态时，意味着之前至少做过i次成功匹配以及i-j次失败匹配。（2012.6期中）

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1608627272002-c2a32bdb-359e-4598-bacc-d397237c5d01.png" alt="image.png" style="zoom: 67%;" />

> :x:
>
> **成功次数为 $i$，失败次数不大于 $i-j$**

字符集规模越大的时候，next表比BC表效果越好。（2012.6期中）

> :x:

对小写字母集的串匹配，KMP 算法与蛮力算法在（ ）情况下渐进的时间复杂度相同（2016.1期末）

A. 最好

B. 最坏

C. 平均

D. 以上皆非

> AC
>
> 蛮力算法平均复杂度也是线性的

对随机生成的二进制串，gs 表中 gs[0]=1 的概率为（ ）（2016.1期末）

A. 1/2^m

B. 1/ 2^(m-1)

C. 1 /2^(m+1)

D. 1/m

> B
>
> gs[0]=1表示所有位全等，字符集大小为T，则概率为 1/T^m-1^

写mamammi的改进后next表。（2014期末补充）

> 初始j=0，t=-1
> | -1    | 0    | 1    | 2    | 3    | 4    | 5    | 6    |
> | ----- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
> | *\**  | *m*  | *a*  | *m*  | *a*  | *m*  | *m*  | *i*  |
> | *N/A* | *-1* | 0    | 0    | 1    | 2    | 3    | 1    |
> | *N/A* | *-1* | 0    | -1   | 0    | -1   | 3    | 1    |

写ladygaga的GS表。（2014期末补充）

> | 0    | 1    | 2    | 3    | 4    | 5     | 6     | 7    |
> | ---- | ---- | ---- | ---- | ---- | ----- | ----- | ---- |
> | *l*  | *a*  | *d*  | *y*  | *g*  | *a*   | *g*   | *a*  |
> | 8    | 8    | 8    | 8    | 8    | 5-3=2 | 6-0=6 | *1*  |
>
> g[5]：后缀ga。往前找，45位上也是ga，前一个字符是y，与5的a不匹配，就用这个：5-3=2
>
> g[6]：后缀a。往前找，5位上也是a，前一个字符是g，与6的g匹配；再往前找，1位上也是a，前一个字符是l，和6的g不匹配，就用这个：6-0=6

BARBARA的

> | j         | -1    | 0    | 1    | 2    | 3    | 4    | 5     | 6    |
> | --------- | ----- | ---- | ---- | ---- | ---- | ---- | ----- | ---- |
> | P[j]      | *\**  | *B*  | *A*  | *R*  | *B*  | *A*  | *R*   | *A*  |
> | next[j]   | *N/A* | *-1* | 0    | 0    | 0    | 1    | 2     | 3    |
> | 改next[j] | *N/A* | *-1* | 0    | 0    | -1   | 0    | 0     | 3    |
> | BC[]      |       |      |      |      | B    |      | R     | A    |
> | SS[j]     |       | 0    | 1    | 0    | 0    | 1    | 0     | *7*  |
> | GS[j]     |       | 7    | 7    | 7    | 7    | 7    | 5-3=2 | *1*  |
>
> 注1：BC[]表是BC[A]=6，BC[B]=3，BC[R]=5
>
> 注2：MS[]表是一个字符串表，MS[j]表示以j为结尾，即[0, j]的所有后缀中，与模式串后缀能匹配的最长者；SS[j]是MS[j]的长度
>
> 注3：GS[]表计算过程中，前缀不一定要紧挨着j，如习题P~213~的PHIL*A*DELPH*I*A，计算最后一个I的GS[]时，找的A可以是标红的那个A

MIAMI的next，改next，BC，SS，GS表

> | j         | -1    | 0    | 1    | 2    | 3    | 4    |
> | --------- | ----- | ---- | ---- | ---- | ---- | ---- |
> | P[j]      | *\**  | *M*  | *I*  | *A*  | *M*  | *I*  |
> | next[j]   | *N/A* | *-1* | 0    | 0    | 0    | 1    |
> | 改next[j] | *N/A* | *-1* | 0    | 0    | -1   | 0    |
> | BC[]      |       |      |      | A    | M    | I    |
> | SS[j]     |       | 0    | 2    | 0    | 0    | *5*  |
> | GS[j]     |       | 3    | 3    | 3    | 5    | *1*  |
>
> 注：这个例子比较特殊，不会正确的计算方法，但可以发现GS[0]=GS[1]=GS[2]=3是对的，可能是因为算GS[2]的时候一路找到了-1的*，所以前面全变成2-(-1)=3了？
>
> 如GS[1]=3：
>
> .............*X*AMI............
>
> ​           M*I*AMI
>
> ​              MIAMI
>
> 注意是*从右往左*匹配，在P[1]处失配，*右移*3位
>
> 事实上012这三个地方失配，模式串的位置都是这样的（后缀的MI已经对齐），都是右移3位就对齐了（*前缀等于后缀*）

## 排序

既然可以在 O(n) 时间内找出 n 个数的中位数，快速排序算法 (12-A1) 即可优化至 O(n log n)。（2016.1期末）

> :x:
>
> 实际上不可行

若序列中逆序对个数为 O(n^2^)，则使用快速排序 (12-A1) 须进行的交换次数为 O(n log n)。（2016.1期末）

> :x:
>
> 如 5，4，3，2，1 的逆序对个数为 $O(n^2)$，但若选中间的 $3$ 为轴点，只需要两次交换即可有序，是 $O(n)$

无论g和h互素与否，已经h-有序的序列再经g-排序之后，必然继续保持h-有序。（2014期末）

> :white_check_mark:
>
> 已经h-有序，经过g-排序之后，仍保持h-有序，此时是(h, g)-有序

shell排序若将插入排序改成归并排序，效率变快。（2014期末补充）

> :x:
>
> 插入排序是输入敏感的，改成 $O(n\log n)$ 的归并排序效率反而更低

radix排序将桶排序改成quick排序，仍然正确 。（2014期末补充）

> :x:
>
> radix排序即基数排序，基数排序的底层排序算法必须要稳定

不存在CBA式算法，能够经过少于2n-3次比较操作，即从n个整数中找出最大和次大者。（2014期中）

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1606980213060-8c32d6b9-5a3b-4f67-8f05-421f8ae08ff2.png" alt="image.png" style="zoom:67%;" />

> :x:
>
> 存在不超过 $\lceil3n/2\rceil-2$ 次的算法

存在CBA式算法，能够在O(n)时间内从n个无序整数中找出最大的10%。（2014期中）

> :white_check_mark:
>
> K-选取，尽管常系数大到天上了（又不是排一个数？），但仍说这是 O(n) 的排序

起泡排序过程中，每经过一趟扫描交换，相邻的逆序对必然减少。（2014期中）

> :x:
>
> 是“不至于增加”（总体的逆序对也是单调非增）
>
> 如12896，相邻的逆序对为1
>
> 一趟交换后12869，相邻的逆序对还是1

即便借助二分查找确定每个元素的插入位置，向量的插入排序在最坏情况下仍需Ω(n^2^)时间。（2014期中）

> :white_check_mark:

经快速划分（LGU 版）之后，后缀G中的雷同元素可能调换相对次序，但其余部分的雷同元素绝不会。（2019.1期末）

![image.png](https://cdn.nlark.com/yuque/0/2020/png/1458680/1607506095975-bb85f411-12b4-429f-bc56-8400452f8dd3.png)

> :white_check_mark:
>
> L、G向右延伸，G直接纳入右边一个元素即可，而L是做一次交换，这会导致G中乱序，但L本身不会

只要底层的排序算法是正确且稳定的，则radixSort()也必然是正确且稳定的。（2019.1期末）

> :white_check_mark:

若输入序列包含 Ω(n^2^) 个逆序对，则快速排序算法（LUG 版）至少需要执行 Ω(nlogn) 元素交换操作。（2019.1期末）

> :x:
>
> 5，4，3，2，1，交换2次

采用12-C节中介绍的任何一种增量序列，shellSort() 最后的1-sorting 都只需要 O(n) 时间。（2019.1期末）

![image.png](https://cdn.nlark.com/yuque/0/2020/png/1458680/1608091231660-a34876e5-d104-484c-b631-51b8a158d037.png?x-oss-process=image%2Fresize%2Cw_643%2Climit_0)

> :x:
>
> 希尔本人的序列 $\mathscr{H}_{shell}$，最后一次排序就还是 O(n^2^)

shellSort() 每按照某个增量做过逐列排序，序列中逆序对的总数都会减少（或持平），但绝不致增加。（2019.1期末）

![image.png](https://cdn.nlark.com/yuque/0/2020/png/1458680/1607506927672-c16d07ef-572a-4e67-b937-7c6c23e18eda.png?x-oss-process=image%2Fresize%2Cw_713%2Climit_0)

> :white_check_mark:
>
> 有序性必然不断提高

一个向量的存在主流数，则该数必然是中位数以及频繁数。（似乎AB卷里的另一个是：如果有某数既是中位数又是频繁数，则该数也是主流数）（2012.6期中）

> :white_check_mark:
>
> 如果主流数是众数的话。存在众数，则一定是中位数和频繁数

如果使用了线性复杂度的中位数选取算法，快速排序的复杂度可以保证在最坏情况下也渐进等于O(nlogn)。（2012.6期中）

> :x:
>
> 理论上可以达到 $O(n\log n)$，但实际上做不到。K选取的理论复杂度为 $O(n)$，但常系数过大
>
> 学堂在线：我们在本节中已经得到了最坏时间复杂度为O(n)的中位数选取算法，若把它用于快速排序的轴点选取，得到的快速排序最坏时间复杂度为（ $O(n\log n)$），但实际上（不可行，因为线性时间的中位数选取算法实际效率非常低）

希尔排序，如果序列已经g有序，换个参数再排一遍，依旧g有序。（2012.6期中）

> :white_check_mark:

若借助二分法查找确定每个元素的插入位置，向量的插入排序只需时间O(nlogn)时间。（2011期中）

> :x:

只要是采用基于比较的排序算法，对任何输入序列都至少需要运行Ω(nlogn)时间。（2011期中）

> :x:
>
> 最好 $O(n)$

为从2014个随机元素中挑选出最大的5个，（ ）在最坏情况下所需的比较操作次数最少。（2014期末）

\- A）构建大顶的锦标赛树，再做5次delMax()；

\- B）用Floyd算法构建大顶堆，再做5次delMax()；

\- C）采用选择排序算法，但仅执行前5次迭代；

\- D）采用起泡排序算法，但仅执行前5次迭代

\- E）用linearSelect()算法找出第5大的元素，再遍历⼀趟找出（至多）4个大于它的元素

> A
>
> 锦标赛树的比较次数比堆要少

若仅考察最好情况下的渐进复杂度，则Bubblesort(p163版)，Insertionsort，Mergesort(p168+170版)，Selectionsort的非降排列次序是（）（2014期中）

A）IBMS      B）MIBS       C）SMIB      D）IMSB    E）BIMS

> AE
>
> 最好情况冒泡O(n)=插排O(n)<归并O(nlogn)<选排O(n^2^)

（）算法在最好情况下与最坏情况下的渐进性能相同。（2014期中）

A）Bubblesort(p163版)      B）Insertionsort       C）Mergesort(p168+170版)       D）Selectionsort  

> CD

将有序列表L均分为长Θ(h)的k段，各段分别置乱，则 L.insertionSort()至多只需（）时间（2014期中）

A）Θ(h^2×k^2)       B）Θ(h×k^2^)       C）Θ(h^2^×k)       D）Θ(h×k)

> C
>
> 每一小段 $\Theta(h^2)$，共 $k$ 段

设在List::selectionSort()算法中，将：`insertB(tail,remove(selectMax(head->succ,n)));` 

替换为：`swap(tail->pred->data,selectMax(head->succ,n)->data);`

若输入列表为{1962，1963，... ，2014；1，2，3，，，1960，1961}，

则swap()语 句无实质效果(原地交换)的情况共计出现（  ）次。

> T~3-14~
>
> A[1962]=1910=S[1909]（2014-1962=52，1961-52=1909）
>
> 循环节{1962, 1909, ...}，公差53
>
> 故出现次数为53-1=52次

K-选取（2014期末补充）

将1983个数字取前三大，最少比较多少次

> 锦标赛树叶子结点是比赛选手，内部节点个数代表了比赛次数
>
> 取第一大的比较次数为 1983-1=1982，取第二大、第三大的比较次数正比于树高 log~2~1983=11，故各最少需要比较 11-1=10 次
>
> 1982+10+10=2002

shell排序（2014期末补充）

因为取1,2,4,8,...,2^n会产生最坏情况，因此每次取到偶数就+1或-1，问能不能避免最坏情况

1、每次遇偶数-1如何？

2、每次遇偶数+1如何？



长度为2020的序列仅能用交换进行排序，最坏情况下至少要交换几次? 为什么? （2020.1期末）

> 每次交换循环节最多+1。最坏情况考虑错排序列，一开始循环节为1, 排序完成后循环节为2020, 因此最少需要交换2019次
>
> $F(n)=N_{node}-N_{ring}$，最少交换次数=数组长度-循环节个数
>
> 交换方法，每次进行交换时，仅在一个**可交换环**中交换两个不同节点的位置，即可使得交换次数最少

quickselect(A, k)中，给定n个数并随机置乱得到（无序）序列{a_1, a_2, … , a_n}，问

（1）a_i与a_j进行比较的概率（用n, i, j, k表示）；

（2）（a_i与a_j？或者n个数？）比较次数的期望；

（3）？（2020.1期末）

> 对每种情况需要的比较次数取平均值，比较次数 $E(n)=\displaystyle\dfrac1{n-1}\sum_{k=1}^{n-1}[E(k)+E(n-k)+n]$
>
> 递归基 $E(0)=E(1)=0$
>
> 化简得 $E(n)=\displaystyle n+\dfrac2{n-1}\sum_{k=1}^{n-1}E(k)$
>
> 令 $S(n)=\displaystyle \sum_{k=1}^{n-1}E(k)$，等式即 $S(n)-S(n-1)=n+\dfrac2{n-1}S(n-1)$，即 $S(n)=n+\dfrac{n+1}{n-1}S(n-1)$
>
> 两边同除 $n(n+1)$ 得 $\dfrac{S(n)}{n(n+1)}=\dfrac1{n+1}+\dfrac{1}{n(n-1)}S(n-1)$
>
> 令 $T(n)=\dfrac{S(n)}{n(n+1)}$，则 $T(n)=\dfrac1{n+1}+T(n-1)$，得到 $T(n)=\dfrac13+\dfrac14+\cdots+\dfrac1{n+1}$
>
> 记调和级数为 $H_n$，则 $T(n)=H_{n+1}-\dfrac32$，可求得 $E(n)=2n(H_n-1)=2n(\ln n+\gamma)=O(n\log n)$

就地堆排序 (15)（2012.6期中）

给了一个长度为7的随机整数向量，要求用Floyd算法建堆，然后排序。给了一个大表格，每一行都是向量的一个状态，第一行是建堆之后的状态，然后依次取最大值放到堆后面。



考察如下问题：任给 12 个互异的整数，且其中 10 个已组织为一个有序序列，现需要插入剩余的两个已完成整体排序。若采用基于比较的算法（CBA），最坏情况下至少需要做几次比较？为什么？ （2011期中）

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1606979875891-65153231-8055-4454-811b-cb6f52bc0071.png" alt="image.png" style="zoom: 67%;" />

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1606979902526-7434b3f2-a88f-4d52-abd7-f7ba541b039e.png" alt="image.png" style="zoom:67%;" />

> 第1个数插入10个有序中，有11个可能的位置
>
> 第2个数插入11个有序中，有12个可能的位置
>
> 总情况有11×12=132种
>
> 判定树的树高至少为 $h=\lceil\log_2132\rceil=8$

向量的插入排序由 n 次迭代完成，逐次插入各元素。为插入第 k 个元素，最坏情况需要做 k 次移动，最好情况则无需移动。从期望的角度来看，无需移动操作的迭代次数平均有多少次？为什么？假定个元素是等概率独立均匀分布的。（2011期中）

![image.png](https://cdn.nlark.com/yuque/0/2020/png/1458680/1606989792958-f3f1979b-9de3-4f5a-85c9-38d80c4e3d86.png?x-oss-process=image%2Fresize%2Cw_676%2Climit_0)

> A[k]无需移动，充要条件是A[k]是A[0, k]中的最大元素，其概率为 $\frac1{k+1}$
>
> 期望即 $\sum\frac1{k+1}=\Theta(\log n)$

## 其他

本课程所介绍的一些算法与数据结构，乃是针对实际应用中普遍存在的非随机数据集而设计的；反过来，只要数据集是理想随机的，则大可不必采用。试举三个这样的案例，列出讲义页码，并作简要说明（各不超过两行）。（2019.1期末）

> 1.KMP的next改进就是为了避免出现连续相同失败匹配，而聪明的跳过
>
> 2.Splay的双层伸展是为了避免最坏情况的反复出现。
>
> 3.散列表的模余法区间长度取素数，如果元素理想随机，即使区间长度不是素数，也不会影响数据的均匀性
>
> 4.冒泡排序的改进就是针对序列中某一部分已经有序的情况
>
> 5.快速排序选择pivot采用各种随机选取的方法，就是为了避免在非随机数据集仅仅使用第一个元素当pivot的划分使得左右子问题规模差距悬殊

在本课的学习中，曾出现过许多利用几何分布（算法执行到下一步停止的概率p）进行计算的实例，请举出4处并简要说明之。（2020.1期末）

> 跳转表塔高（期望塔高2），二叉堆上滤（均匀分布时，上滤平均上升1层，比较2次），快排pivot（连续执行字符比对的次数不超过s/(s-1)<2次），字符串蛮力算法（平均时间复杂度线性）

![image.png](https://cdn.nlark.com/yuque/0/2020/png/1458680/1606999632550-e551bcd6-cbc6-4977-88af-f3567a1510f4.png?x-oss-process=image%2Fresize%2Cw_575%2Climit_0)

![image.png](https://cdn.nlark.com/yuque/0/2020/png/1458680/1606998525173-641e7a05-b5e0-44e4-81a0-c92d823d83da.png?x-oss-process=image%2Fresize%2Cw_622%2Climit_0)

![image.png](https://cdn.nlark.com/yuque/0/2020/png/1458680/1607000490154-bff4d863-f0db-4cb8-b6c2-bf8eed6d0357.png?x-oss-process=image%2Fresize%2Cw_626%2Climit_0)

# 操作系统

## 内存-连续内存、非连续内存

（20190520期末）

[ ] 通过mmap系统调用，可以实现通过直接内存访问来访问文件，避免了read/write系统调用的特权级切换开销。

> :white_check_mark:
>
> mmap()系统调用使得进程之间通过映射同一个普通文件实现**共享内存**。普通文件被映射到进程地址空间后，进程可以向访问普通内存一样对文件进行访问，不必再调用read()，write（）等操作。

在内核态中执行的内核线程不需要拥有自己独占的页表。（20190407期中）

> :white_check_mark:
>
> 内核线程并不拥有自己的页表集，它使用一个**普通进程的页表集**。不过，没有必要使一个用户态线性地址对应的TLB表项无效，因为内核线程不访问用户态地址空间。

如没有页机制的虚存管理，则无法实现采用Copy on Write机制的fork系统调用。（20190407期中）

> :white_check_mark:
>
> Unix的新版本利用虚拟内存硬件，允许父进程和子进程**共享映射**到各自地址空间的物理内存，直到其中一个进程实际修改它。这中技术称之为copy-on-write（写时复制）

[ ] 访问频率置换算法(Frequency-based Replacement)综合采用了LRU和LFU算法用于磁盘缓存置换。

> 应该对的（RISC-V的内容）

（20190407期中）

[ ] 二次机会（时钟）页面替换算法需要读取和修改页表项中访问位才能有效实现。

> :white_check_mark:

[ ] 运行在用户态的进程只能通过系统调用才能直接获得操作系统的服务。

> 应该对的（

[ ] 如果父进程比子进程先结束，那么子进程结束后将成为资源无法被回收的僵尸进程。

> :x:
>
> 是孤儿
>
> 孤儿进程：一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。
>
> 僵尸进程：一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程。

试说明描述全局和局部置换算法的不同，并分别各举出⼀种属于全局置换和局部置换的算法。（20190407期中）

> 局部置换：当前进程范围内，占用物理页面的置换；全局置换：不同进程之间，所有可换出的物理页面的置换
>
> 局部：LRU，FIFO，CLOCK，OPT
>
> 全局：工作集置换算法，缺页率置换算法

假定在⼀个虚拟存储系统中某进程分配了4个物理页面，当进程按**c, a, d, b, e, b, a, b, c, d**的序列进行页面访问时，当分别使用时钟置换算法与LRU算法时会出现多少次缺页？要求说明过程。（20190407期中）

> LRU
> | c    | a    | d    | b    | e    | b                  | a                  | b                  | c    | d    |
> | ---- | ---- | ---- | ---- | ---- | ------------------ | ------------------ | ------------------ | ---- | ---- |
> | :x:  | :x:  | :x:  | :x:  | :x:  | :white_check_mark: | :white_check_mark: | :white_check_mark: | :x:  | :x:  |
> | *c   | *c   | *c   | *c   | *e*  | e                  | e                  | e                  | *e   | *d*  |
> |      | a    | a    | a    | *a   | *a                 | a                  | a                  | a    | a    |
> |      |      | d    | d    | d    | d                  | *d                 | *d                 | *c*  | c    |
> |      |      |      | b    | b    | b                  | b                  | b                  | b    | b    |
>
> CLOCK
>
> | c    | a    | d    | b    | e    | b                  | a                  | b                  | c    | d    |
> | ---- | ---- | ---- | ---- | ---- | ------------------ | ------------------ | ------------------ | ---- | ---- |
> | :x:  | :x:  | :x:  | :x:  | :x:  | :white_check_mark: | :white_check_mark: | :white_check_mark: | :x:  | :x:  |
> | *1 c | *1 c | *1 c | *1 c | 1 e  | 1 e                | 1 e                | 1 e                | 1 e  | 0 e  |
> |      | 1 a  | 1 a  | 1 a  | *0 a | *0 a               | *1 a               | *1 a               | 0 a  | 1 d  |
> |      |      | 1 d  | 1 d  | 0 d  | 0 d                | 0 d                | 0 d                | 1 c  | *1 c |
> |      |      |      | 1 b  | 0 b  | 1 b                | 1 b                | 1 b                | *1 b | 0 b  |

什么是Belady现象？请判断OPT、LRU、FIFO、Clock和LFU等各页面置换算法是否存在Belady现象？（20190407期中）

> 当分配的物理页面增加时，缺页率却会上升
>
> 产生Belady的算法：FIFO，CLOCK，改进CLOCK，不恢复计数的LFU（经典序列1 2 3 4 1 2 5 1 2 3 4 5）
>
> 不产生Belady的算法：OPT，LRU，恢复计数的LFU

（20201028期末）

请问，设一个页面访问序列为 0,1,4,2,3,4,1,0,3,2，且物理页帧中最多能容纳 4 个页面，初始时物理页帧为空，请用 FIFO 算法进行模拟，给出每一次访问的情况以及访问后物理页帧的状态，最终给出总缺页次数。

> | 0    | 1    | 4    | 2    | 3    | 4                  | 1                  | 0    | 3                  | 2                  |
> | ---- | ---- | ---- | ---- | ---- | ------------------ | ------------------ | ---- | ------------------ | ------------------ |
> | :x:  | :x:  | :x:  | :x:  | :x:  | :white_check_mark: | :white_check_mark: | :x:  | :white_check_mark: | :white_check_mark: |
> | *0   | *0   | *0   | *0   | *3*  | 3                  | 3                  | 3    | 3                  | 3                  |
> |      | 1    | 1    | 1    | *1   | *1                 | *1                 | *0*  | 0                  | 0                  |
> |      |      | 4    | 4    | 4    | 4                  | 4                  | 4    | *4                 | *4                 |
> |      |      |      | 2    | 2    | 2                  | 2                  | 2    | 2                  | 2                  |

请用 LRU 算法进行模拟，给出每一次访问的情况以及访问后物理页帧 的状态，最终给出总缺页次数。 

> | 0    | 1    | 4    | 2    | 3    | 4                  | 1                  | 0    | 3                  | 2    |
> | ---- | ---- | ---- | ---- | ---- | ------------------ | ------------------ | ---- | ------------------ | ---- |
> | :x:  | :x:  | :x:  | :x:  | :x:  | :white_check_mark: | :white_check_mark: | :x:  | :white_check_mark: | :x:  |
> | *0   | *0   | *0   | *0   | *3*  | 3                  | 3                  | 3    | 3                  | 3    |
> |      | 1    | 1    | 1    | *1   | *1                 | 1                  | 1    | 1                  | 1    |
> |      |      | 4    | 4    | 4    | 4                  | 4                  | *4   | *4                 | *2*  |
> |      |      |      | 2    | 2    | 2                  | *2                 | *0*  | 0                  | 0    |

请问，从应用程序和操作系统在通用 CPU 上实际运行的角度看，如果操作系统采用 LRU 页面置换算法，那相比于采用 FIFO 页面置换算法，其在整体系统执行效率上的结果上一定更好吗？说明理由。（回答字数 150 字）

> LRU在系统局部性较强的时候更具有优势，但是实现LRU需要系统维护一个按最近一次访问时间排序的页面链表，开销相比FIFO来说更大
>
> 如果访问的页面偏随机，使用LRU不见得比FIFO效率更高
>
> 不过有一点好处在于，FIFO会产生Belady现象，而LRU不会

（20201028期末）

假定在某基于二级页表的虚拟页式存储，具有 4GB 物理内存的 32 位计算机系统下，32 位虚拟地址从高到低被划分如下， 10 位页目录序号、10 位页表序号和 12 位页内偏移。页目录和页表大小均为 4096 字节，页目录项和页表项大小为 4 字节。使用自映射方式组织页表。

本题表述中，用 `flags` 表示页表/页目录项的各种标志位，占低 12 位，且 CPU 不基于`flags`的信息来判断某项是页表项还是页目录项。要求回答中所有地址均使用用十六进制表示，如 `0x1edc8000`。

除了自映射，举出一个其他页表组织方式。与自映射相对比，你给出的其他页表组织方式有什么优缺点？要求至少一个优点和一个不足。（回答字数 150 字）

> 一一映射
>
> 优点：逻辑简单直接
>
> 缺点：需要另外的4KB来存储一级页表；若按虚拟地址的地址顺序显示整个页目录表和页表的内容，过程会比较繁琐

假定页目录起始物理地址是 0x1edc8000，并且物理地址 0x1edc8ff0 (=0x1edc8000+1020*4)

开始的页目录项是自映射项。则此处自映射项的内容是 `______ | flags`，该自映射项的虚拟地址是 `______` ？

![image.png](https://cdn.nlark.com/yuque/0/2020/png/1458680/1607580432395-f50a9a3c-02ef-45c6-a052-894421bd7a40.png?x-oss-process=image%2Fresize%2Cw_458%2Climit_0)

> 页目录起始地址开始的4KB空间是页目录页表项的内容：
>
> 自映射项也就是那一个页目录项指向的页刚好是页目录表所在页，其内容也就是页目录表的起始位置
>
> 由于页目录项（或页表项）高20位为下一级页表（或物理页表）的基址，后12位为标志位flag
>
> 因此自映射项的内容为 `0x1edc8 | flags`
>
> 1020=1111111100~2~
>
> 映射的虚拟地址为 `1111111100 1111111100 1111111100 00=0xFF3FCFF0`（后面补 `00` 变成32位）

假定虚拟地址 0x8af4b000 映射到物理地址 0x01572000，则位于虚拟地址 `______` 的页表项内容应该是 `0x01572000 | flags`。位于 0xff1bc500 的页表项，它指向的页的虚拟地址起始于 `______`。

>

## 处理机调度、进程、线程管理

（20190520期末）

[ ] 操作系统通过vfork创建子进程时，需要拷贝父进程的所有页表内容作为子进程的页表内容。

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1606765014601-1adc670d-9291-4f4b-a4eb-c265766a8087.png" alt="image.png" style="zoom:67%;" />

> :x:
>
> `vfork()` 不再创建一个同样的内存映像
>
> COW机制下，fork()不会复制进程的页目录表，而是多个进程共享，只有当某个进程对页进行写操作时，才会引发Page fault单独赋值并分配该页给操作进程

[ ] 信号量与管程都是高层同步互斥机制，无法基于信号量机制来实现管程。

> :x:
>
> ucore中的管程机制就是基于信号量和条件变量来实现的

[ ] 基于mesa机制的管程在执行条件变量的signal操作过程中，不会睡眠。

> :x:
>
> 就是Hansen，真实OS和Java用的那个，A等待条件成立后，依旧要先让B执行完，不能立即执行
>
> 说的是线程B signal资源R后，线程A从wait队列放入entry队列，线程B继续执行

[ ] 基于hoare机制的管程在执行条件变量的signal操作过程中，不会睡眠。

> :white_check_mark:

[ ] 基于spinlock的互斥机制实现中，可以确保处于忙等线程集合将按线程忙等的等待时间顺序依次进入临界区。

> :x:
>
> 显然没有FIFO，运气不好会饥饿

 [ ] 发生进程复制时，新进程的内核堆栈可以先于进程地址空间复制操作之前进行创建。

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1607393248086-f778c604-2cb5-48e4-a51c-e358ab0d935e.png" alt="image.png" style="zoom:80%;" />

> :white_check_mark:
>
> ucore的do_fork先分配内存堆栈，再复制

（20180525期末）

[ ] 在多CPU场景下，多个线程通过自旋锁(spinlock)争抢进入临界区执行，第一个成功进入临界区的线程是第一个执行自旋锁争抢的线程。

> :x:
>
> 第一个执行的时候，临界区可能正被占用。没有FIFO

[ ] 运行在内核态的内核线程共享操作系统内核态中的一个页表。

> :white_check_mark:
>
> 内核线程并不拥有自己的页表集，它使用一个普通进程的页表集（所以什么叫“共享内核态中的一个页表”）
>
> 查了下“*内核页表*”没问题，为所有进程所共享

[ ] 操作系统创建用户进程时需要为此用户进程创建一个*内核栈*用于执行系统调用服务等。

> :white_check_mark:

[ ] 通用操作系统的调度算法的主要目标是低延迟，高吞吐量，公平，负载均衡。

> :white_check_mark:

[ ] 单处理器场景下，*短剩余时间优先*调度算法(SRT)可达到具有*最小平均周转时间*的效果。

> :white_check_mark:

[ ] 单处理器场景下，无法通过打开和关闭中断的机制来保证内核中临界区代码的互斥性。

> :x:
>
> 硬件中断、软件同步、锁

[ ] 信号量可用于解决需要互斥和同步需求的问题。

> :white_check_mark:

[ ] 属于*管程范围*的函数/子程序相互之间*具有互斥性*。

> :white_check_mark:
>
> 由于管程是一个语言成分，因此管程的互斥访问完全由编译程序在编译时自动添加，无须程序员关心，而且保证正确

[ ] 操作系统处于安全状态，一定没有死锁；操作系统处于不安全状态，可能出现死锁。

> :white_check_mark:

[ ] 80386取指地址是base+eip，base是隐藏寄存器，初始化为0xffff0000，eip初始化为0xfff0，故执行的第一条指令是0xfffffff0。

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1607519341652-8d046e2b-4b88-4f9f-92d4-094de8a65c37.png" alt="image.png" style="zoom:80%;" />

> :white_check_mark:
>
> 80386无论是在实模式还是在保护模式下，访问物理内存的方法都是段基址+EIP
>
> 80386 CPU复位的时候，段基址被初始化为0xffff0000，直接和EIP（0xfff0）相加即得到第一条指令0xfffffff0，本题应该是对的
>
> 实模式下，本来只能访问1M的物理空间，而现在却到了4G-16字节处，显然超出了实模式的1M寻址范围限制，其内部电路强行把FFFF0000写入到了隐藏寄存器中的段基址，当代码第一次尝试修改CS寄存器后，CPU的寻址范围才会被限制在1M以内。

[ ] 实模式x86-32 CPU在冷启动后执行的第一条指令的地址由CS段基址加EIP确定，即FFFF_FFF0H =FFFF_0000H + 0000_FFF0H。（20190520期末）

> :x:
>
> 是base+eip
>
> base是一个隐藏寄存器

[ ] 在x86-32中，在内核态通过对EFLAGS的设置可直接屏蔽时钟中断。（20190407期中）

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1607520295505-4bdf5a51-2aee-4025-9eee-66aa3f9e3713.png" alt="image.png" style="zoom:80%;" />

> :white_check_mark:
>
> 标志寄存器（Flag Register）：EFLAGS和8086的16位标志寄存器相比，增加了4个控制位。IF可以控制中断

[ ] 在x86-32中，只有正确设定了段描述符表的相关配置，才能实现中断和异常处理。（20190407期中）

> :x:
>
> 中断描述符表，包括任务门、中断门、陷阱门、调用门描述符，所以这里应该是门描述符表吧？

[ ] 基于动态链接库的应用程序需要编译器能生成地址无关代码并需要OS加载库和程序。（20190407期中）

> :white_check_mark:

[ ] 在x86-32 CPU下，操作系统可以实现让用户态程序直接接收并处理硬件中断。

> :x:
>
> 硬件中断是由内核态接收处理
>
> 应该是x86特权级这个实验的内容
>
> $CPL\leqslant DPL[门]$ 或 $CPL\geqslant DPL[段]$ 时具有访问门的权限
>
> $\max\{CPL,\,RPL\}\leqslant DPL[段]$ 时具有访问段的权限
>
> 不过和中断应该没关系

[ ] 在ucore的bootloader代码实现中，在主引导记录 (master boot record) 格式下的512 字节的引导扇区 (boot sector) 中，除去最后两个字节 0x55AA, 还剩下 510 字节都能用来存放引导代码。（20190407期中）

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1607521431720-d72d9a02-782a-40a7-bbea-876d44519d4b.png" alt="image.png" style="zoom: 67%;" />

>:x:
>
>启动代码不超过446字节，还有64字节的硬盘分区表和2字节的55AA结束符

[ ] 在lab1中实现打印函数调用堆栈信息时，print_debuginfo()的参数不仅可以是 `eip-1 `，还可以是 `eip` 或 `eip-2` 。

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1607523864065-38a6555a-9d3e-48c9-bbe4-9729de845768.png" alt="image.png" style="zoom:67%;" />

> :x:

[ ] 在操作系统中一旦出现死锁, 所有进程都不能运行。

> :x:
>
> 不在循环占用里的进程就可以运行

[ ] 在ucore for x86-32中，子进程通过sys_exit()执行进程退出时，ucore kernel会先释放子进程自身内核堆栈和进程控制块等，再唤醒父进程（或initproc），最后执行iret返回。

> :x:
>
> 子进程释放自身所占的内存空间和相关的内存管理（如页表等）信息所占空间，唤醒父进程
>
> 父进程来负责释放子进程的进程控制块，而不是子进程自己释放掉

**12.** 某系统中共有M种类型资源，每种资源的个数为 R1，R2 ，R3 ，…，RM ，共有N个进程竞争使用这些资源，每个进程对这些资源的需求量为 K1，K2 ，K3 ，…，KM ，每个进程会依次获取这些资源，如下面的伪代码所示：（20190520期末）

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1604334728174-e3a2334a-f32c-4eee-bc65-88e1008f05ef.png" alt="img" style="zoom: 67%;" />

当M=1，N=2时，在下面几种设定中，按照上面的获取方式，这些进程会发生死锁吗？

R1=11， K1=7（	）

R1=11， K1=6（	）

当M=1时，R1 ，N， K1 需要满足（	）不等式关系，才能使得这些进程不发生死锁。

> R1=11， K1=7	会发生死锁，如进程1持有6个，进程2持有5个
>
> R1=11， K1=6	不会发生死锁，如进程1持有5个，进程2持有5个，此时还有一个资源，谁得到了都可以运行并释放资源
>
> $R_1\geqslant N(K_1-1)+1$，这样各进程都持有 $K_1-1$ 个资源的时候，还有资源供进程运行并随后释放资源

（20180525期末）

（12分）设lab6中使用Stride调度算法，取BIGSTRIDE=100，假定各个进程的stride初始化为0。（注：lab6中的stride（32位整数，当前总共走了多少）和pass（32位整数，每一次走多少 pass=BIGSTRIDE/priority, 100>priority>1）的含义和论文原文含义相反）请回答下列问题。

A) 如果不考虑进程stride的值的溢出，那么对于任意两个进程A、B的stride值SA和SB，应当恒有abs(SA-SB) ≤ (\__1\_\_) ，为什么？

B) 考虑到abs(SA-SB)这一性质，假设stride值存在溢出，可将stride值的更新变为：stride = (stride + BIGSTRIDE/priority) mod n

那么，只要n> (\__2\_\_) ，那么stride算法就可以正常运行，为什么？

>1) $abs(SA-SB)\leqslant 100$
>
>   反证：假设 $SA>SB+100$，那么在上一轮调度中，已经有 $SA>SB$ 了，此时本应该调用 $SB$
>
>2) 200
>
>   若真实值 $SB>SA$，且 $SB$ 溢出，$SA$ 没有溢出，那么需要*通过 $SA-SB>100$ 来判断此时发生了溢出*（发现了这个情况，就说明 $SB$ 溢出到负，实际上是 $SB>SA$）
>
>   于是 $SB-SA\leqslant 100$ 且 $SA-(SB-n)>100$，即 $n-100>100$，需 $n>200$

二、临界区 （共 2 题 共 4 分） （20201028期末）

2.（2 分）为了形成临界区，在单核机器上可以使用关中断，在多核机器上可以使用自旋锁。请回答下列问题。 

在单核机器中使用自旋锁可以吗？为什么？（回答字数 150 字）

> 可以。自旋锁是实现保护共享资源而提出的一种锁机制，可以保证在任何时刻最多只能有一个执行单元获得锁，从而保证只有一个执行单元进入临界区
>
> 为什么？单核机器能用有什么为什么？（doge）

 3.（2 分）为了形成临界区，在单核机器上可以使用关中断，在多核机器上可以使用自旋锁。请回答下列问题。 

在多核机器上使用关中断可以吗？为什么？（回答字数 150 字）

> 不可以。每个处理器都有自己的中断，一个处理器关中断了，进程仍可以在其他处理器上运行并进入临界区

三、进程管理 （共 4 题 共 10 分） （20201028期末）

4.（3 分）什么是孤儿进程？（回答字数 100 字） 

> 一个父进程退出，它的一个或多个子进程还在运行，子进程将成为孤儿进程

5.（3 分）什么是僵尸进程？（回答字数 100 字） 

> 一个子进程在父进程还没有调用wait()方法或者waitpid()方法的情况下退出，子进程将成为僵尸进程

四、多处理机调度 （共 2 题 共 6 分） （20201028期末）

8.（3 分） 

在多处理机调度中，就绪任务队列的维护有两种策略： 

单队列：使用无锁数据结构，维护一个全局队列 

多队列：每个核有一个自己的局部队列 

这两种方案相比，分别有什么好处和不足？（回答字数 150 字） 

> 单队列：负载均衡；调度开销大
>
> 多队列：调度开销小；可能忙闲不均

提出一种新的改进方案，避免这两种方案各自的不足之处。（回答字数 150 字） 

> 每个核都有自己的局部队列，设置一个全局处理的算法，定时轮询每个处理器，当有的处理器过忙时，就可以将任务分配到其他相对不忙的处理器上运行

五、嵌套异常 （共 1 题 共 8 分） （20201028期末）

10.（8 分） 由于内核实现代码的错误，导致内核在执行缺页（page fault）处理例程（响应用户进程导致的第一次缺页异常）的过程中再次（第二次）发生缺页异常。假定该内核其他部分编程正确且支持内核态中断。请描述第二次缺页异常产生之后的内核执行过程，以及从第一次缺页异常产生后开始的整个过程中内核栈变化和寄存器的状态变化的情况。（回答字数 200 字） 

> 第二次缺页的内核执行过程：CPU读到第二次缺页异常，根据缺页异常的**中断向量**找到**中断描述符**从而找到对应的**段选择子**，再根据段选择子找到缺页异常**中断服务例程**的起始地址，跳到该地址。接下来CPU会**保存上一次异常相关的现场信息**，即把其eflags，cs，eip压入内核栈
>
> 第一次缺页的内核栈、寄存器变化：第一次缺页之前，程序正运行在用户态，所以要将系统当前正在使用的栈**换成新的内核栈**，接着将当前程序使用的用户态ss和esp压到新的内核栈中**保存**起来。利用内核栈保存相关现场信息，即依次将当前被打断程序使用的eflags，cs，eip压入内核栈；第二次缺页时也将上一次缺页的eflags，cs，eip压入内核栈

六、中断+调度+进程管理 （共 1 题 共 6 分） （20201028期末）

11.（6 分）假定在一台装有类 UNIX 通用操作系统的单核计算机上，任意一个中断从产生到响应处理结束，耗时 1 ms；OS 调度算法是时间片轮转调度算法，调度时间片为 100 ms ；时钟中断周期 10 ms；系统中有 3 个处于就绪态的进程。一个程序从十点整开始运行，恰好60,000 ms 后运行结束，在运行过程中产生了 6,000 次中断。 请根据以上信息回答：该程序的实际占用 CPU 的真实运行时间是否可以计算得出？若可以，给出计算过程和具体结果（单位 ms ，保留整数）；若不可以，给出理由。（回答字数 150字） 

> 总中断处理时间：$6000\times 1ms=6000ms$
>
> 包括该程序，一共有4个进程参与调度
>
> 除去中断处理时间，剩下的时间为：$60000ms-6000ms=54000ms$
>
> 假设其他三个进程都没有产生中断，则该程序实际占用CPU的最大时间为：$54000ms/4=13500ms$

九、基于信号量的同步互斥 （共 1 题 共 14 分） （20201028期末）

19.（14 分）假设某仓库可存放 A、B 两种物品，其容量无限大；任何时刻只允许一个物品进行仓库进行入库操作；要求仓库中 A 物品数量 X 和 B 物品数量 Y 满足不等式： -M ≤ ( X - Y ) ≤ N ，其中 M 和 N 为正整数。请用信号量机制实现 A、B 两种物品入库的处理过程，要求能做到正确且高效的同步与互斥。 

请说明所定义的信号量的含义和初始值，描述需要进行互斥处理的各种行为，描述需要进行同步处理的各种行为；要求用类 C 语言伪代码实现，并给出必要的简明代码注释。 

> ```c++
> // 假设一直是 A 入库，X 从 N 一路减到 0，就不能再减了。随后一个 B 入库，X 加一，这样 A 就能再入库了；另一边类似
> semaphore mutex = 1;	// 互斥访问仓库
> semaphore X = N;	// 至多连续 N 次 A 入库
> semaphore Y = M;	// 至多连续 M 次 B 入库
> 
> void A () {
>     while (1) {
>         P(X);
>         P(mutex);
>         // A 入库
>         V(mutex);
>         V(Y);
>     }
> }
> 
> void B () {
>     while (1) {
>         P(Y);
>         P(mutex);
>         // B 入库
>         V(mutex);
>         V(X);
>     }
> }
> ```

在实现各种锁时，需要让一些 Read-Modify-Write 操作同时进行，且不能被其他线程打断，这就需要用硬件提供的原子操作指令来实现。常见的原子操作指令有 TestAndSet/CompareAndSwap/FetchAndAdd 等，它们的功能描述如下(类 C 伪码实现，每个函数体都是原子的，不能被打断)：

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1607575795099-22a47fe2-90b1-4902-99a4-1263d03705f5.png" alt="image.png" style="zoom:67%;" />

1）用 TestAndSet 原子指令，实现自旋锁。请用类 C 伪码形式补全下面代码中的 `lock` 结构和获取锁`lock_acquire()`、释放锁`lock_release()` 函数。 

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1607575830536-13d6d740-fcd5-48c5-8bae-f26f59c9f436.png" alt="image.png" style="zoom:50%;" />

```c
struct lock {
    int value = 0;
};

struct lock spin;

void lock_acquire(struct lock* spin) {
    while( TestAndSet(spin->value) ) {
        wait();		// 发现是1，则设置为1，返回true，留在循环内
    }
    // 发现是0，则设置为1，返回false，跳出循环，成功独占锁
}

void lock_release(struct lock* spin) {
    spin->value = 0;	// 设置为0，释放锁
}
```

2）用 CompareAndSwap 原子指令，实现自旋锁。请用类 C 伪码形式补全下面代码中的 `lock` 结构和获取锁`lock_acquire()`、释放锁`lock_release()` 函数。

```c
struct lock {
    int value = 0;
};

struct lock spin;

void lock_acquire(struct lock* spin) {
    while( !CompareAndSwap(spin->value, 0, 1) ) {
        wait();		// 发现是1，则设置为1，!false即是true，留在循环内
    }
    // 发现是0，则设置为1，!true即是false，跳出循环，成功独占锁
}

void lock_release(struct lock* spin) {
    spin->value = 0;	// 设置为0，释放锁
}
```

3）使用 `FetchAndAdd` 原子指令原语可实现一种 `ticket lock`，类 C 伪码形式的代码如下。试分析这种锁与自旋锁相比有何优势？ （回答字数 150 字）

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1607575900092-185a44d7-bd35-49a9-8f11-90b2715576a3.png" alt="image.png" style="zoom:67%;" />

> 进程需要先取号，然后当叫号叫到自己了才能使用锁
>
> 实现了FIFO，公平，不会饥饿

## 文件系统

**11.** 请在下面有数字标号的空格中简要写出文件系统实现中文件分配的三种方式及其主要特点（需指明是否有外碎片问题、随机或顺序读取性能的好坏，可靠性差/好），并解释理由。（20190520期末）

连续分配的特点：文件顺序读取性能（---1---），随机读取性能（---2---），（---3---）外碎片。

链式分配的特点：（---4---）外碎片，随机读取性能（---5---），可靠性（---6---）。

索引分配的特点：（---7---）外碎片，随机访问性能（---8---），可靠性（---9---）。

请用小于90个字给出对上面三类分配方式的填写内容的解释理由（---10---）。

> 连续分配：顺序读取性能（好）、随机读取性能（好）、（有）外碎片
>
> 链式分配：（没有）外碎片、随机读取性能（差）、可靠性（差）—— 一个链断了，后面的数据全部丢失
>
> 索引分配：（没有）外碎片、随机访问性能（好）、可靠性（好）

**13.** 设初始情况下，一个一般文件fifile1的当前引用计数值为1，如果先建立fifile1的符号链接（软链接）文件fifile2，再建立fifile1的硬链接文件fifile3，然后再建立fifile3的硬链接文件fifile4。此时，fifile3和fifile4的引用计数值分别是 （---14---）和（---15--- ）。（20190520期末）

> | fifile1 | fifile2 | fifile3 | fifile4 |
> | ------- | ------- | ------- | ------- |
> | 3       | 1       | 3       | 3       |
>
> 软Link不算，且只记录到建立Link那一时刻的状态

[ ] 由于符号链接（软链接）实际上是一类特殊的文件，它的内容就是其所指向的文件或目录的路径，所以符号链接可以指向一个不存在的文件或目录。（20180525期末）

> :white_check_mark:
>
> 可以链接不存在的文件或目录（称为“断链”），还可以循环链接自己（导致递归）

[ ] 文件系统中，用于存储“文件访问控制信息”的合理位置是文件分配表。（20180525期末）

> :x:
>
> 应该放在文件描述符中
>
> 文件分配表FAT是告诉操作系统文件都存放在哪

## 磁盘、I/O

 [ ] 当前ucore lab8中实现的磁盘读写操作采用CPU轮询机制来实现。（20190520期末）



访问频率置换算法(Frequency-based Replacement)综合采用了LRU和LFU算法用于磁盘缓存置换。（20190520期末）

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1606761588404-b6395c3a-45e4-411d-a010-abdac6b41ff3.png" alt="image.png" style="zoom:67%;" />

> :white_check_mark:

（20180525期末）

现有一个RAID磁盘阵列，包含6个磁盘，每个磁盘大小都是2TB，最大写入速度 200 MB/s，

最大读取速度 250 MB/s 的硬盘。用它们分别组成RAID级分别为0、1和5。假设在理想情况下（无中断、异常、预先缓存等外在干扰因素等），请回答下列问题。

A) 用它们组成的RAID0阵列的总可用空间为 (____)，最大写入速度为 (____)，最大读取速度为 (____)；

B) 用它们组成的RAID1阵列的总可用空间为 (____)，最大写入速度为 (____)，最大读取速度为 (____)；

C) 用它们组成的RAID5阵列的总可用空间为 (____)，最大写入速度为 (____)，最大读取速度为 (____)。

> RAID0：可用12TB，写入1200MB/s，读取1500MB/s
>
> RAID1：可用6TB，写入600MB/s，读取1500MB/s（写入3块，读取6块）
>
> RAID5：可用10TB，写入1000MB/s，读取1250MB/s（可用5块）

假定有两个用来存储10TB数据的RAID系统。系统A使用RAID1技术，系统B使用RAID5技术。 （2016.1复习题）

（1）系统A需要比系统B多用多少存储量？ 

（2）假定一个应用需要向磁盘写入一块数据，若磁盘读或写一块数据的时间为30ms，则最坏情况下，在系统A和系统B上写入一块数据分别需要多长时间？ 

（3）哪个系统更可靠？为什么？

> （1）A需要20TB，B（假设使用5个磁盘阵列）需要12.5TB，A比B多7.5TB
>
> （2）A写入不变，还是30ms；系统B在最坏的情况下，写一块数据的时间为2次读和2次写（在RAID5中有“写损失”，即每一次写操作，将产生四个实际的读/写操作，其中两次读旧的数据及奇偶信息，两次写新的数据及奇偶信息），需要120ms
>
> （3）相对来说系统 A 更可靠一些，因为系统对整个磁盘进行了完整备份，所以只有互为镜像的两个盘上的对应数据都损坏时才不能恢复；而系统B是分散记录了原数据的部分冗余信息，如果其中两个磁盘的相同位都损坏了就恢复不出来了

# 计算机组成原理

## 指令、数据

（2016.1复习题）

奇偶校检可以发现并纠正一位错误。

> :x:
>
> 奇偶校验码：发现一位错，无纠正

（2010期末）

CISC 处理器的指令类型一般多于 RISC 处理器。

> :white_check_mark:
>
> CISC是复杂指令系统，RISC是精简指令系统

摩尔定律是指集成电路的频率每 18 个月翻一番。

> :x:
>
> 是集成电路芯片上*所集成的电路的数目*，或者说*微处理器的性能*每18个月翻一倍

微程序是供组合逻辑控制器来执行的一种机器语言程序。

![image.png](https://cdn.nlark.com/yuque/0/2020/png/1458680/1607017710505-bd6646ba-3da7-4cb1-af2d-06d28ece6be3.png?x-oss-process=image%2Fresize%2Cw_420%2Climit_0)

> :x:
>
> 两种控制器是并列关系

能完成乘法运算的处理器都设置有乘法器。

> :x:
>
> 乘法可以在软件上实现，而不需要硬件实现

（2019.1期末）

使用下面的程序初始化，判断前4题的对错。 

```c
int x=random() ； 
int y=random() ；
int z=random() ； 
double dx=(double) x；
double dy=(double) y；
double dz=(double) z； 
```

![image.png](https://cdn.nlark.com/yuque/0/2020/png/1458680/1608110562114-aef1c1f3-96b7-465c-b307-8c61a766eff7.png?x-oss-process=image%2Fresize%2Cw_406%2Climit_0)

`((x >> 1) << 1)<=x`

> :white_check_mark:
>
> 如此一来会丢弃最右边的 $1$。联系有符号数二进制转十进制的计算，符号位是 $1$ 的时候减，而后面都是加，少了最后一位 $1$，不论正负都是减小

`dx+dy+dz==(double) (z+y+x)`

> :x:
>
> z+y+x是有可能溢出的

`dx+dy+dz==dz+dy+dx`

> :x:
>
> 3.14 + 1e20 - 1e20 和 1e20 - 1e20 + 3.14 是不同的

`dx*dy*dz==dz*dy*dx`

> :x:
>
> 这个就比较好接受了
>
> 浮点数加法、乘法都没有结合律，T~3~和T~4~无非就是先算哪两个，也就是在问结合律的事情

在32位的原码、反码和补码三种机器码中补码的表示范围最大。

> :white_check_mark:
>
> 补码只有一个0，负数能多表示一个数

CPI(Cycles Per Instruction) 用来衡量指令执行平均所需要的周期数，CPI越小，代表执行相同的程序所需要的时间越短。

> :x:
>
> 这种题目多来点，就没有对的（）

只要运算器具有加法器和移位功能，再增加一些控制逻辑，就能实现乘除运算。

> :white_check_mark:
>
> 话说并行进位加法器，传播函数 $P_i=X_i+Y_i$ 相当于低位越过本位直接向高位传递，生成函数 $G_i=X_iY_i$ 即均为 $1$ 时不管有无低位进位，本位都向高位进位
>
> 一般讨论的并行进位加法器，也即全先行进位加法器（应该算一个东西吧）

加减交替法可以实现原码除法，比恢复余数法硬件实现简单。

> :white_check_mark:
>
> 恢复除数法会使得除法运算的**实际操作次数不固定**，从而导致控制电路比较复杂。而且在恢复余数时，要**多做一次加法**，降低了除法的执行速度。
>
> 原码不恢复余数法是对恢复余数法的一种改进，它减少了浪费的加法时间，且运算的次数固定，故被广泛采用。
>
> 应该就是个选择，出不了大题？24号晚上看看得了

（2016.1复习题）

Von Neumann 机中____和____均以二进制形式存放在存储器中。

> 指令和数据（应该考过了来着）

（2010期末）

给出十进制数-254 的 IEEE754 标准单精度浮点数表示。（-254）= ____。

>注意 $-254$ 负号直接拿出来，可别写成补码了
>
>-254=-1111 1110=-1.111111*2^7^
>
>符号位1，阶码7+127=134=1000 0110~2~，尾数111111后面全是0
>
>(1 1000 0110 111 111 0000...)~2~=0xC37E0000

某计算机字长 16 位，整数用补码表示，按字编址。某 C 语言定义了 i, j, k 共 3 个 short 型变量，其中有程序段如下：

```c
{
    i = 105;
    j = -12767;
    k = i + j;
}
```


编译器将 i, j, k 三个变量分配到地址分别为 100、101 和 102 三个内存单元中。则上述程序段执行完成后，地址 100 内容为，地址 101 的内容为，地址 102 的内容为。（均用 16 进制表示）。

> 100：105的补码0x69
>
> 101：-12767的补码，绝对值原码0x31DF=0011 0001 1101 1111，故-12767补码1100 1110 0010 0001=0xCE21
>
> 102：105-12767=-12662，-12662的补码是1100 1110 1000 1010=0xCE8A=0x69+0xCE21（所以直接补码加法是正确的，减法要取相反数再做加法，就没啥优势了）

常见的指令寻址方式： ____、____、____ 、____、 ____ 。

> 立即数寻址、直接寻址、间接寻址、寄存器寻址、寄存器间址、变址寻址、基址寻址、相对寻址、堆栈寻址

（2019.1期末）

十进制数66.375在IEEE 754单精度浮点数标准下表示为：____。(16进制表示)。

> 

使用海明码数据传输，设数据位k=3(D3D2D1)，校验位r=4(P4P3P2P1)，数据D3D2D1=011的编码结果为(按照P1P2D1P3D2D3P4的顺序) ：____。

> D~1~：3=1+2，D~2~：5=1+4，D~3~：6=2+4
>
> 因此
>
> P1 = D2 ⊕ D1 = 1 ⊕ 1 = 0
>
> P2 = D3 ⊕ D1 = 0 ⊕ 1 = 1
>
> P3 = D3 ⊕ D2 = 0 ⊕ 1 = 1
>
> P4 = P3 ⊕ P2 ⊕ P1 ⊕ D3 ⊕ D2 ⊕ D1 = 0
>
> P1P2D1P3D2D3P4 = 0111100
>
> 话说，如果是接收方校验呢？海明码有两种，一种是 $2^r\geqslant k+r+1$（408版 $2^3\geqslant 4+3+1$），发现并改正一位错，一种是 $2^{r-1}\geqslant k+r$（912版 $2^{4-1}\geqslant3+4$ 怎么理解？去掉P4，原不等式两边的 $r$ 都换成 $r-1$ 就出来了）
>
> 校验时把校验位与对应的数据位一起亦或
>
> S1 = P1 ⊕ D2 ⊕ D1
>
> S2 = P2 ⊕ D3 ⊕ D1
>
> S3 = P3 ⊕ D3 ⊕ D2
>
> S4 = P4 ⊕ P3 ⊕ P2 ⊕ P1 ⊕ D3 ⊕ D2 ⊕ D1
>
> 0000无错，1xxx有一位错，0xxx有两位错

（2016.1复习题）

 以下哪个不是 Von Neumann 结构

A. ENIAC     B. IBM 360      C. PDP-1     D. Pentium 

> A
>
> ENIAC是第一台通用电子计算机，通过设置6000个开关和其它众多的插头和插座来编程

布斯乘法中，是根据控制位和最低位的组合来判断功能的，若组合为 01 时，应该运算部分积 

A. +0    B. +[x]补    C. -[x]补    D. +[2x]补

> B
>
> 这么记：01~2~=1>0，加；10~2~=-2<0，减

ALU 是通过（    ） 逻辑电路实现的，其功能是（    ） 。

> 组合逻辑；完成算数和逻辑运算

响应中断的流程包含 ：I. 存储 PC	II. 保存所有通用寄存器	III. 恢复 PC 

A. 仅 I, III     B.仅 I, II     C. I, II, III     D. 都不

> A
>
> 不是保存所有通用寄存器，而是保存状态寄存器

相对于微程序控制器，硬布线控制器的特点是 

A. 指令执行速度慢，指令功能的修改和扩展容易 

B. 指令执行速度慢，指令功能的修改和扩展难 

C. 指令执行速度快，指令功能的修改和扩展容易 

D. 指令执行速度快，指令功能的修改和扩展难

> D

某计算机的控制器采用微程序控制方式，微指令中的操作控制字段采用字段直接编码法， 共有 33 个微命令，构成 5 个互斥类，分别包含 7、3、12、5 和 6 个微命令，则操作控制字段至少有 

A. 5 位     B. 6 位     C. 15 位     D. 33 位

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1608113778686-112f287a-60a6-4d99-bc88-30a9d03d061f.png" alt="image.png" style="zoom:80%;" />

> C
>
> 只算位数的话，如下做就好了
>
> 3：2位
>
> 5：3位
>
> 6：3位
>
> 7：3位
>
> 12：4位
>
> 2+3+3+3+4=15

Von Neumann 机中指令和数据均以二进制形式存放在存储器中，CPU 区分它们的依据是 

A. 指令操作码的译码结果 

B. 指令和数据的寻址方式 

C. 指令周期的*不同阶段* 

D. 指令和数据所在的存储单元

> C

下列关于 RISC 的说法错误的是

A. 寻址简单    B. 指令格式规范     C. 指令功能简单     D. 一般采用微程序实现

> D

计算机的最小功能单元是

A. 字节     B. 程序     C. 微操作    D. 指令

> D

（2010期末）

下列选项中，能缩短程序执行时间的是 。 

I．提高 CPU 时钟频率 II．优化数据通路结构 III．对程序进行编译优化

A．仅 I 和 II   B．仅 I 和 III   C．仅 II 和 III   D．I，II，III

> D

某一编码系统中，数据为 8 位。为提高系统的可靠性，希望能发现 2 位出错，并能在仅有 1 位出错时进行纠正，则需要增加的校验位的位数至少是 。 

A．3 位 B．4 位 C．5 位 D．6 位

> C
>
> $2^{r-1}\geqslant k+r$，最小 $r=5$

下列寄存器中，汇编程序员可见的是(	) 

A．存储器地址寄存器（MAR） 

B．程序计数器（PC） 

C．存储器数据寄存器（MDR） 

D．指令寄存器（IR）

> B
>
> 汇编程序员可以通过*指定待执行指令的地址*来设置PC的值，IR、MAR、MDR都是CPU内部工作寄存器，对程序员透明

微程序存放的位置是(	)

A．CPU   B．高速缓冲存储器   C．主存储器   D．磁盘存储器

> A
>
> CPU内部有一个*控制存储器*，里面存放各种微程序段。（否则CPU执行指令的时候，岂不是还得访存？）

（2019.1期末）

假定有4个整数用8位补码分别表示 r1=90H， r2=F2H， r3=FEH， r4=F8H， 若将运算结果存 放在一个8位的寄存器中，则下列运算会发生溢出的是 

A.`rl*r2` 	B.`r2*r3`	 C.`r3*r4` 	D.`r2*r4` 

> 

假定不采用 Cache 和指令预取技术，且机器处于开中断状态，则在下列有关指令执行的叙述中，错误的是 （  ）（2016.1复习题）

A. 每个指令周期中 CPU 都至少访问内存一次 

B. 每个指令周期一定大于或等于一个 CPU 时钟周期 

C. 空操作指令的指令周期中任何寄存器的内容都不会被改变 

D. 当前程序在每条指令执行结束时都可能被外部中断打断

> C
>
> 空指令也要改PC

（2016.1复习题）

指令和数据均存放在内存中，计算机如何从时间和空间上区分它们是指令还是数据？

> 时间上：根据所处阶段是取址还是访存来区分
>
> 空间上：指令和数据分开存放

（2019.1期末）

推导布斯乘法的规则，并依据规则使用5位的整数来计算3× (-6)。 

> 

## 控制器-单多周期和流水线

（2010期末）

控制相关是指流水线的分支指令或其他需要改写 PC 的指令造成的冲突。

> :white_check_mark:

指令流水中使用旁路（Forwarding）技术可减少结构冲突。

> :x:
>
> 减少数据冲突（①旁路技术；②动态调度；③静态调度；④暂停流水线）

**填空**

（2016.1复习题）

流水线中的相关可以分为____相关、____相关、____相关。

> 结构、数据、控制

五段流水线的指令执行步骤分别是取指令(IF)、____ 、____ 、____ 、____ 。

> 取址（IF）	译码（ID）	执行（EXE）	访存（MEM）	写回（WB）

程序局部性原理包括 ____ 局部性和 ____ 局部性。

> 时间、空间

在五级流水线中，有以下三条 MIPS-16E 指令：

```assembly
ADDU R2 R2 R1，
ADDU R1 R3 R2，
ADDIU R3 2
```

若不加入转发电路，则需要插入____个气泡，如果加入转发电路需要____个气泡。本题中的三条指令使用了____和的____寻址方式。

>两个紧挨着的指令，前一个的结果是下一个的数据源：不转发+2气泡；转发+0气泡；转发但Load-use冒险+1气泡
>
>2	0	寄存器寻址	立即数寻址

（2019.1期末）

考虑指令序列：
```assembly
SW R1，7(R2)  	    (指令1，R1寄存器的内容存到R2+7的地址)
ADD R5、R6、R3		(指令2，R5=R6+R3，寄存器值相加)
```
在一个5阶段流水线的MIPS处理器上， 第1个时钟周期执行指令1的取指阶段。指令1会发生访存地址未对齐异常，指令2会发生加法结果溢出异常、那么在第(  )个时钟周期检测到访存地址未对齐异常，在第(  )个时钟周期检测到加法结果溢出异常，最终处理器向操作系统报告(  )异常。

> 4	指令1的访存（MEM）阶段会发现访存地址未对齐的异常
>
> 4	指令2在执行（EXE）阶段结束后会发现溢出异常
>
> 报告“访存地址未对齐的异常”
>
> 一个时钟周期内产生多个异常，**应该先响应前一条指令**

使用我们实验用的板子设计MIPS处理器， 采用标准5级流水线无Cache设计， 每个时钟周期完成一个指令阶段。采用一片SRAM来保存数据与程序(另一片SRAM不使用) ，假设一个时钟周期可以完成SRAM的一次读或者一次写， 执行下面的指令序列：
```assembly
LW R1，0(R2)(指令1，从R2+0位置读入数据到R1中)
SUB R4，R1，R5(指令2，R4=R1-R5)
AND R6，R2、R7(指令3，R6=R2&R7)
ADD R8，R3，R2(指令4，R8=R3+R2)
ADD R9，R1，R2(指令5，R9=R1&R2)
SW R9，I6(R2)(指令6，将R9的数据存入到16+R2的位置)
```
若处理器设计时没有数据旁路，执行完所有的指令需要(   )个时钟周期，增加数据旁路后，执行完所有的指令需要(  )个时钟周期。
> 默认寄存器读口和写口是独立开来的，利用时钟上升沿和下降沿两次触发，使得前半周期使用写口进行寄存器写，后半周期使用读口进行寄存器读
> |      | 1    | 2    | 3         | 4         | 5    | 6    | 7    | 8    | 9         | 10        | 11   | 12   | 13   | 14   |
> | ---- | ---- | ---- | --------- | --------- | ---- | ---- | ---- | ---- | --------- | --------- | ---- | ---- | ---- | ---- |
> | LW   | IF   | ID   | EXE       | MEM       | WB   |      |      |      |           |           |      |      |      |      |
> | SUB  |      | IF   | :balloon: | :balloon: | ID   | EXE  | MEM  | WB   |           |           |      |      |      |      |
> | AND  |      |      | :balloon: | :balloon: | IF   | ID   | EXE  | MEM  | WB        |           |      |      |      |      |
> | ADD  |      |      |           |           |      | IF   | ID   | EXE  | MEM       | WB        |      |      |      |      |
> | ADD  |      |      |           |           |      |      | IF   | ID   | EXE       | MEM       | WB   |      |      |      |
> | SW   |      |      |           |           |      |      |      | IF   | :balloon: | :balloon: | ID   | EXE  | MEM  | WB   |
>
> 需要14个周期
>
> 旁路后还有Load-use冒险，还需要一个气泡，11个周期
>
> |      | 1    | 2    | 3    | 4         | 5    | 6    | 7    | 8    | 9    | 10   | 11   |
> | ---- | ---- | ---- | ---- | --------- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
> | LW   | IF   | ID   | EXE  | MEM       | WB   |      |      |      |      |      |      |
> | SUB  |      | IF   | ID   | :balloon: | EXE  | MEM  | WB   |      |      |      |      |
> | AND  |      |      | IF   | :balloon: | ID   | EXE  | MEM  | WB   |      |      |      |
> | ADD  |      |      |      | :balloon: | IF   | ID   | EXE  | MEM  | WB   |      |      |
> | ADD  |      |      |      |           |      | IF   | ID   | EXE  | MEM  | WB   |      |
> | SW   |      |      |      |           |      |      | IF   | ID   | EXE  | MEM  | WB   |

（2016.1复习题）

不可用于解决控制冲突的是 

A. 插入等待  B. 延迟槽   C. 数据转发   D. 分支预测

> C
>
> ①分支预测：预测成功、预测不成功、动态预测；②暂停流水线；③延迟槽

一台有完整的层次储存器的 MIPS 计算机，LW 指令访存的最少次数为 

A. 0     B.1      C. 2     D. 3

> A
>
> 存储器分层体系结构共**五种**可能的组合
>
> | TLB  | page | cache | 说明                                                     |
> | ---- | ---- | ----- | -------------------------------------------------------- |
> | hit  | hit  | hit   | 全命中，0次访存                                          |
> | hit  | hit  | miss  | cache缺失，访1次主存（访TLB查到）                        |
> | miss | hit  | hit   | TLB缺失，但页本身命中，访1次主存（访cache查到）          |
> | miss | hit  | miss  | TLB缺失，但页本身命中，但是没有cache，访2次主存          |
> | miss | miss | miss  | TLB缺失，页也缺失，cache中必缺失，访1次磁盘，至少2次主存 |

（2010期末）

下面关于多周期 CPU 的描述，正确的是 。

A．指令周期长度固定

B．每个机器周期可完成一条指令

C．多个机器周期完成一条指令

D．其控制器只用组合逻辑电路就能实现

> C

下列关于通过数据转发来解决数据冲突的描述中、正确的是

(流水线阶段标识：EX为执行阶段、MEM为访存阶段， WB为写回阶段)

A.只能转发EX/MEM流水线寄存器到ALU的输入

B.只能转发MEM/WB流水线寄存器到ALU的输入

C.在EX/MEM流水线寄存器和MEM/WB流水线寄存器对应的寄存器都进行转发的时候、选择MEM/WB流水线寄存器的值

D.在EX/MEM流水线寄存器和MEM/WB流水线寄存器对应的寄存器都进行转发的时候、选择EX/MEM流水线寄存器的值

> D
>
> 选择前面的寄存器进行转发，以*尽快*把结果送往需要它的位置，并且MEM/WB寄存器的值*还可以留着往下送*

（2016.1复习题）

数据旁路的含义和目的？

> 含义：在主数据通路外，增设特殊的通路将结果尽快传送到需要使用它的位置
>
> 目的：解决数据冲突

什么是流水线中的结构冲突？MIPS 中在哪些流水阶段中会发生结构冲突？对应的解决途径都有哪些？

> 结构冲突是指，程序在重叠执行的过程中，需要用到相同的资源，但是硬件资源满足不了指令重叠执行的要求，发生硬件资源冲突而产生的冲突
>
> “取址、访存”——寄存器访问冲突、存储器访存冲突（所以不应该是取址、译码、访存吗？）
>
> 暂停流水线，插入等待周期；增加资源；将读口与写口分开

请说明指令周期、机器周期、时钟周期之间的关系。

![image.png](https://cdn.nlark.com/yuque/0/2020/png/1458680/1607163634620-1aba4eca-c0f2-4e2f-ba9b-c5ceb0fd3378.png?x-oss-process=image%2Fresize%2Cw_510%2Climit_0)

> **时钟周期**又叫做振荡周期、节拍周期，定义为时钟晶振频率的倒数。时钟周期是计算机中*最基本的、最小的时间单位*。
>
> **机器周期**：在计算机中，为了便于管理，常把一条指令的执行过程划分为若干个阶段，每一阶段完成一项工作。例如，取指令、存储器读、存储器写等，这每一项工作称为一个基本操作。*完成一个基本操作所需要的时间*称为机器周期。
>
> **指令周期**：取出一条指令并执行这条指令的时间。一般由*若干个机器周期*组成，是从取指令、分析指令到执行完所需的全部时间

## 存储器

（2016.1复习题）

直接映射的 Cache 可以使用 LRU 或 FIFO 的替换方式。

> :x:
>
> 直接映射只有一个块，没得选

动态预测可以增加 Cache 命中率。

> :x:
>
> 这不流水线的吗

段式虚存中的段表存有段长信息，可以检查是否访问地址越界。

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1607680552112-fede490b-05fa-4b69-90af-d178deb0ae4b.png" alt="image.png" style="zoom:50%;" />

> :white_check_mark:

分页系统中增加 TLB 可以提高命中率。

> :x:

容量为 128 字节、采用直接映射方式 Cache 的缺失率和容量为 64 字节、采用 2 路组相联映射方式 Cache 的缺失率相当。

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1607681210495-deb311fe-c323-4c11-a1a4-f1786dbccebc.png" alt="image.png" style="zoom:67%;" />

> :white_check_mark:
>
> 注意容量是64字节，不是64*2

硬盘不同的磁记录方式对于存储容量没有影响。

> :x:

FLASH 和 SRAM 一样都是电易失性存储器。

> :x:
>
> 电易失：动态随机DRAM，静态随机SRAM
>
> 非电易失：闪存FLASH

DMA 可以提高硬盘到内存的载入速率

> :white_check_mark:

（2010期末）

RAID5 和 RAID4 比较，检错纠错能力更高。

> :x:
>
> 没区别

Cache 总容量一定的话，两路组相连组织方式的命中率不低于直接映射方式的命中率。

> :white_check_mark:
>
> 仅一半容量即可与直接映射命中率相当

页式虚拟存储器管理中设置 TLB 可提高访问速度。

> :white_check_mark:

虚拟存储管理中，虚页数和实页数必须相同。

> :x:
>
> 一般虚页多（有未分配的虚拟页面）

（2019.1期末）

处理器缓存Cache与存储器的地址的映射关系是由操作系统来管理的。

> :x:
>
> 缺页倒是操作系统来管理的

使用高速缓存是为了提高主存的容量。

> :x:
>
> 速度

（2016.1复习题）

页式存储，在____ 中设置____ 进行虚实转换。

> 物理主存（应该）	页表

Cache 的缺失种类有：____  、____  、____  、无效缺失。

> 必然缺失、容量缺失、冲突缺失、无效缺失

（2019.1期末）

为了存储256GB的数据， 使用RAID0的方式， 所占用的磁盘空间大小为____， 使用RAID 6的方式(4+2) ， 所占用的磁盘空间大小为____。

> RAID0：256GB
>
> RAID6：256GB*(6/4)=384GB

（2016.1复习题）

假定不采用 Cache 和指令预取技术，且机器处于开中断状态，则在下列有关指令执行的叙述中，错误的是 

A. 每个指令周期中 CPU 都至少访问内存一次 

B. 每个指令周期一定大于或等于一个 CPU 时钟周期 

C. 空操作指令的指令周期中任何寄存器的内容都不会被改变 

D. 当前程序在每条指令执行结束时都可能被外部中断打断

> C

组相联映射 Cache 中，命中率最高的算法 

A. FIFO    B. LRU     C. RAND     D. 都不对

> B

设计一个字长 16 位，容量为 32KW 的内存，需要用几片 2K × 8 bit 的存储芯片 

A. 16    B. 32       C. 64      D. 128 

> B
>
> W是Word
>
> 32kW/2K\*8bit=16\*2=32

下列关于 Cache 与 TLB 的描述中，哪个说法是错误的 

A. TLB 与 Cache 中保存的数据是不同的 

B. TLB 缺失之后，有可能直接在 Cache 中找到页表内容 

C. TLB 缺失会导致程序执行出错，但是 Cache 缺失不会 

D. TLB 和 Cache 的命中率都与程序的访存模式有关

> C
>
> TLB缺失未必缺页

下列有关 RAM 和 ROM 的叙述中，正确的是 

I. RAM 是易失性存储器，ROM 是非易失性存储器 

II. RAM 和 ROM 都采用随机存取方式进行信息访问 

III. RAM 和 ROM 都可用作 Cache 

IV. RAM 和 ROM 都需要进行刷新 

A. 仅 I 和 II     B. 仅 II 和 III     C. 仅 I、II 和 IV      D. 仅 II、III 和 IV

> A
>
> cache是高速的静态存储器SRAM实现的
>
> SRAM使用触发器，不需要刷新；DRAM使用电容，需要刷新

假设某计算机按字编址，Cache 有 4 个行，Cache 和主存之间交换的块为 1 个字。若 Cache 的内容初始为空, 采用 2 路组相联映射方式和 LRU 替换算法。当访问的主存地址依次为 0,4,8,2,0,6,8,6,4,8 时，命中 Cache 的次数是 

A. 1     B. 2     C. 3     D. 4

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1607421063844-81d799da-6e96-4cf7-9d34-741a0891d464.png?x-oss-process=image%2Fresize%2Cw_1342%2Climit_0" alt="image.png" style="zoom:50%;" />

> C

（2010期末）

下面关于高速缓冲存储器（Cache）的描述中，错误的是 。 

A．高速缓冲存储器设置在主存和 CPU 之间

B．高速缓冲存储器由系统程序员编程管理

C．高速缓冲存储器访问速度高于主存储器

D．高速缓冲存储器以块为单位和主存交换数据

> B
>
> Cache对程序员透明

下面有关静态存储器（SRAM）和动态存储器（DRAM）的叙述中，正确的是 。 

I． SRAM 和 DRAM 都是电易失性存储器

II． SRAM 和 DRAM 都采用随机存取方式进行数据访问

III． SRAM 和 DRAM 都可用作 Cache

IV． SRAM 和 DRAM 都需要刷新

A．仅 I 和 II   B．仅 I 和 III   C．仅 II 和 IV   D．仅 III 和 IV

> A

下面的命中和缺失的组合情况，在一次访存过程中，不可能发生的是 。 

A．TLB 未命中，页表未命中，Cache 未命中

B．TLB 未命中，页表命中，Cache 命中

C．TLB 命中，页表命中，Cache 未命中

D．TLB 命中，页表未命中，Cache 命中

> D
>
> 一共五种

某磁盘有 100 个柱面，每个柱面有 10 个磁道，每个磁道有 128 个扇区，每个扇区容量为 512 字节。该磁盘的存储容量是 。 

A．12800B   B．25MB   C．62.5MB   D．625MB

> C
>
> 100\*10\*128\*512B=2^16^KB=62.5MB

（2019.1期末）

下面不属于缓存缺失的情况有 ____ 

A.必然缺失 B.容量缺失 C.页面缺失 D.冲突缺失

> C
>
> 必然、容量、冲突、无效

某计算机主存容量为128KB， 其中ROM区为8KB， 其余为RAM区， 按字节编址。现要用2K×8位的ROM芯片和4K×4位的RAM芯片来设计该存储器， 则需要上述规格的ROM芯片数和RAM芯片数分别是

 A.2、30    B.4、30    C.2、60    Ｄ.4、60  

>D
>
>按字节编址，即8位
>
>8KB/2K*8位：4片ROM
>
>120KB/4K*4位：60片RAM

假定不采用Cache和指令预取技术， 且机器处于开中断状态， 则在下列有关指令执行的叙述中，错误的是  

A.每个指令周期中CPU都至少访问内存一次  

B.每个指令周期一定大于或等于一个CPU时钟周期  

C.空操作指令的指令周期中任何寄存器的内容都不会被改变

D.当前程序在每条指令执行结束时都可能被外部中断打断

> C
>
> 空操作PC也会+1

（2016.1复习题）

除了采用高速芯片外，分别指出存储器、运算器、控制器和 I/O 系统各自可采用什么方法提高机器速度，各举一例简要说明。

> 存储器：多体交叉存储器
>
> 运算器：快速进位链
>
> 控制器：指令流水
>
> IO：DMA

在 DMA 方式中，CPU 和 DMA 接口分时使用主存有几种方法？简要说明其原理和特点。

> 1. 独占总线（停止CPU访问内存）
>
>    这种方法 DMA 在传送一批数据时，独占主存，CPU **放弃了地址线、数据线和有关控制线的使用权**。在一批数据传送完毕后，DMA 接口才把总线的控制权交回给 CPU。显然，这种方法在 DMA 传送过程中，CPU **基本处于不工作状态或保持原状态**
>
> 2. 周期窃取
>
>    这种方法 CPU 按程序的要求访问主存，一旦 I/O 设备有 DMA 请求，则由 I/O 设备**挪用**一个存取周期。此时 CPU **可完成自身的操作，但要停止访存**。显然这种方法既实现了 I/O 传送，又较好地发挥了主存和 CPU 的效率，是一种广泛采用的方法

（2010期末）

简述一次 DMA 传送的过程。

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1607697449285-6682ff92-99a2-41b3-8e81-6e8f188e295b.png" alt="img" style="zoom: 67%;" />

> 预处理：将内存起始地址、设备地址、数据传送个数送至DMA，然后**启动设备**
>
> 数据传输：**继续执行主程序**，同时完成一批数据传送
>
> 后处理：**中断**服务程序进行 DMA结束处理

（2019.1期末）

某计算机系统的内存系统中， 已知Cache访问时间为20ns， 主存访问时间为100ns。CPU执行一段程序时， CPU访问内存系统共5000次， 其中访问主存的次数为450次。那么Cache命中率是____ ，CPU访问内存的平均访问时间是____ 。

> 命中率1-450/5000=91%
>
> 平均访存时间20ns+9%*120ns=30.8ns

假定一台计算机的显示存储器用DRAM芯片实现， 若要求显示分辨率为800*600， 使用RGB颜色， 每种颜色使用1个字节表达， 帧频为60Hz， 显存总带宽的50%用来刷新屏幕，则需要的显存总带宽至少约为____ 。

>800\*600\*3\*8\*60/50%=1382.4Mb/s

假设流水线寄存器或者锁存器的输出延迟为100ps，输入延迟可以不考虑，不使用处理器内部的缓存(Cache) 。各阶段的的延迟如下：

| **IF** | **ID** | **EX** | **MEM** | **WB** |
| ------ | ------ | ------ | ------- | ------ |
| 250ps  | 180ps  | 150ps  | 300ps   | 200ps  |

实现以下7条指令：

\1. addu rd rs rt，

\2. subu rd rs rt， 

\3. ori rt rs imm，

\4. lw rt， rs， imm，

\5. sw rt， rs， imm，

\6. beq rs， rt， imm，

\7. j target

如果设计为单周期的处理器，则处理器的时钟周期至少为_(  )的处理器，则处理器的时钟周期至少为_______ ，多周期处理器最长指令延迟为_______ ；如果设计为多周期(  )如果设计为标准的五阶段流水线，处理器的时钟周期至少为_______ 。



**综合分析题**

（2016.1复习题）

某计算机存储器按字节编址，虚拟（逻辑）地址空间大小为16MB，主存（物理）地址空间大小为1MB，页面大小为4KB；Cache 采用直接映射方式，共8 行；主存与Cache 之间交换的块大小为32B。系统运行到某一时刻时，页表的部分内容和Cache 的部分内容分别如题44-a 图、题44-b 图所示，图中页框号及标记字段的内容为十六进制形式。请回答下列问题。

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1604397798401-1fd12043-75b9-4e2f-95b2-d5dd0242b276.png" alt="img" style="zoom:67%;" />

(1) 虚拟地址共有几位，哪几位表示虚页号？物理地址共有几位，哪几位表示页框号（物理页号）？

> 虚拟地址16MB=2^24^B，共24位
>
> 页大小4KB=2^12^B，页内偏移12位，虚页号即前12位
>
> 物理地址1MB=2^20^B，共20位，20-12=8，物理页号即前8位

(2) 使用物理地址访问Cache 时，物理地址应划分成哪几个字段？要求说明每个字段的位数及在物理地址中的位置。

> cache容量2^8^B=8行×32B/行=2^3^行×2^5^B/行
>
> 主存容量=1MB=2^20^B=2^12^块群×2^3^块/块群×2^5^B/块
>
> 19\~8：标记位；7\~5：索引位；4\~0：块内地址

(3) 虚拟地址001C60H 所在的页面是否在主存中？若在主存中，则该虚拟地址对应的 物理地址是什么？访问该地址时是否Cache 命中？要求说明理由。

> 虚拟页号前12位：001H=1，查表可知虚页号1对应有效位1（在主存中），页框号04H
>
> 对应物理地址04C60H=0000 0100 1100 0110 0000，其中索引位011=3，标记位04CH，查表可知块号为3的Cache有效位为1，但标记位为105H不等于04CH，故没有命中

(4) 假定为该机配置一个4路组相联的TLB 共可存放8个页表项，若其当前内容（十六进制） 

如题44-c图所示，则此时虚拟地址024BACH所在的页面是否存在主存中？要求说明理由。

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1604397845719-d909f8c1-e383-446f-b056-fee769543349.png" alt="img" style="zoom: 67%;" />

> 虚拟地址 024BACH，故虚页号为 024H=0000 0010 0100B
>
> 由于 TLB 只有 8/4=2 个组，故虚页号中高 11 位为 TLB 标记，最低 1 位为 TLB 组号
>
> 它们的值分别为 0000 0010 010B（即 012H）和 0B，因此，该虚拟地址所对应物理页面只可能映射到 TLB 第 0 组
>
> 由于组 0 中存在有效位=1、标记=012H 的项，所以访问 TLB 命中，即虚拟地址 024BACH 所在的页面在主存中

某计算机的主存地址空间大小为 256 MB，按字节编址。指令 Cache 和数据 Cache 分离，均有 8 个 Cache 行，每个 Cache 行大小为 64 B，数据 Cache 采用直接映射方式。现有两个功能相同的程序 A 和 B，其伪代码如下所示：

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1604397906863-8df61896-6771-428a-8113-1dbbd985c905.png" alt="img" style="zoom:67%;" />

假定 int 类型数据用 32 位补码表示，程序编译时 i, j, sum 均分配在寄存器中，数组 a 按行优先方式存放，其首地址为 320（十进制数）。请回答下列问题，要求说明理由或给出计算过程。

（1）若不考虑用于 Cache 一致性维护和替换算法的控制位，则数据 Cache 的总容量为多少？

> 8*64B=512B
>
> cache标记项（19标记位+1有效位）20B（2^28^，28-6-3=19）
>
> 共532B
>
> 怎么觉得应该是8*(64+20)=512+160=672B

（2）数组元素 a\[0][31]和 a\[1][1]各自所在的主存块对应的 Cache 行号分别是多少（Cache 行号从 0 开始）？

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1608124289078-604bc0eb-32fb-4f1d-a5fc-8fffc28a3586.png" alt="image.png" style="zoom:50%;" />

> Cache大小64B=2^6^，块内地址6位
>
> 8=2^3^个Cache行，索引位3位
>
> 主存256MB=2^28^，总长度28位
>
> 标记位28-3-6=19位
>
> 首地址320，每个元素4字节，行优先，故
>
> a\[0][31]的地址为320+31×4=444=110 111100，对应Cache行号为110=6
>
> a\[1][1]的地址为320+257×4=1348=101 01000100，对应Cache行号为101=5

（3）程序 A 和 B 的数据访问命中率各是多少？哪个程序的执行时间更短？

> A访存数据量256×256×4B=2^18^，占2^18^/64=2^12^个内存块，按行优先存放
>
> A逐行访问数组a，未命中次数2^12^，访问命中率为 $(2^{16}-2^{12})/2^{16}=93.7\%$
>
> B逐列访问数组a，由于一行数据量1KB>64B，所以访问第0列每个元素都不命中
>
> 由于数组有256列，数据Cache仅有8行，故访问数组后序列元素时仍然不命中，B的访问命中率为 $0\%$
>
> A 执行时间更短

硬盘的寻道时间是 8ms，转速为 7200RPM，传输速率 5MB/s，每个磁道有 64 个盘区，每个盘区大小 512 字节，控制器延迟为 1.5ms。求： 

(1) 读单盘区的时间； 

(2) 读连续的 8KB 的时间； 

(3) 假如我们有 4 个磁盘能并行的读出数据，那么读取 32KB 需要多少时间？

> 寻道8ms，转半圈4.17ms（注意RPM是分钟转速），控制器延迟1.5ms，加起来13.67ms
>
> （1）13.67ms+512B/5MB=13.77ms
>
> （2）13.67ms+8KB/5MB=15.27ms
>
> （3）32KB并行，每个磁盘读8KB，和（2）一样

（2010期末）

某计算机存储器系统参数如下：

- TLB 共有 256 项，按两路组相连方式组织；
- 64KB 的数据 Cache，块大小为 64B，组织方式也是两路组相连；
- 虚拟地址 32 位，物理地址 24 位；
- 页大小为 4KB。

下图给出了系统的简单示意。

请分别计算其中各字段 A、B、C、D、E、F、G、H 和 I 所占的位数，给出计算过程。

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1604399315305-1fb366a5-4ae2-4638-8d40-9c2efd899ca0.png" alt="img" style="zoom:50%;" />

> 块大小64B=2^6^B，Cache块数=64KB/64B=1K=2^10^块，组数2^10^/2=2^9^
>
> 故C=6，B=9，A=24-9-6=9，E=A=9，每个块本身数据512位，D=512
>
> 页大小4KB=2^12^B，TLB有256项=2^8^，组数=2^8^/2=2^7^
>
> 故H=12，G=7，F=32-12-7=13，TLB中是24位的物理页号，I=物理地址24位-页内偏移12位=12

## I/O、中断、总线

（2010期末）

PCI Express 总线和 PCI 总线结构基本相同，只是提高了总线频率，带宽因此得到了提高

> :x:
>
> PCI是并行总线，所有设备共享带宽
>
> PCI Express是串行总线，每个传输通道独享带宽

同步传输总线使用统一的时钟来协同总线事务

> :white_check_mark:

Blu-Ray 采用的激光波长比 DVD 的波长更短

> :white_check_mark:
>
> Blu-Ray蓝光，DVD红光

（2016.1复习题）

I/O 通道的类型分别是____ 、____  、____ 

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1607698952806-646ae387-7c72-4919-a795-80441035f0fd.png" alt="image.png" style="zoom:67%;" />

> 字节多路（共享）、选择（独占）、数组多路（结合）

（2010期末）

中断处理过程包括关中断、____ 、____、开中断、____、关中断、____ 、开中断、____等步骤

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1607699153176-5c9aa577-954c-40d0-8b0a-dbe5c0106608.png" alt="image.png" style="zoom: 80%;" />

> 关中断；保存断点；判中断源、转中断服务；开中断；执行中断服务程序；关中断；恢复断点；开中断；返回断点

（2019.1期末）

MIPS响应异常和中断的硬件流程包含 I.*保存PC寄存器* Ⅱ.保存所有通用寄存器 III.*恢复PC寄存器* IV.*保存异常原因* V.读取异常原因  

A.I，II，III，   B.II，III，IV，	C.I，III，IV    D.III，IV，Ⅴ 

> C

（2016.1复习题）

下列关于 USB 总线特性的描述中，错误的是 

A. 可实现外设的即插即用和热拔插 

B. 可通过级联方式连接多台外设 

C. 是一种通信总线，连接不同外设 

D. 有 2 根数据线，可同时传输 2 位数据，数据传输率高

> D
>
> 2根数据线是对的（共4根线），但同时传输2位数据是错的，USB是串行的

五个中断，响应优先级为 0>1>2>3>4，处理优先级为 4>0>2>1>3，问 1 的中断屏蔽字（顺序为 43210） 

A. 11110    B. 01101    C. 00011    D. 01010

> D
>
> 看的是处理优先级，不可屏蔽0/2/4，对于中断屏蔽字要设置为0

下列关于中断 I/O 方式和 DMA 方式比较的叙述中，错误的是 

A. 中断 I/O 方式请求的是 CPU 处理时间，DMA 方式请求的是总线使用权 

B. 中断响应发生在一条指令执行结束后，DMA 响应发生在一个总线事务完成后 

C. **中断 I/O 方式下数据传送通过软件完成，DMA 方式下数据传送由硬件完成** 

D. 中断 I/O 方式适用于所有外部设备，DMA 方式仅适用于快速外部设备

> D
>
> 中断并不适用于所有设备，比如高速外设为了提高传输速度，就普遍使用DMA

下列选项中，在 I/O 总线的数据线上传输的信息包括 I. I/O 接口中的命令字 II. I/O 接口中的状态字 III.中断类型号 

A. 仅 I、II     B. 仅 I、III     C. 仅 II、I1II     D. I、II、III

（2010期末）

> D
>
> I：通道允许数据线传输IO命令
>
> II：通过数据线传输设备的各种工作状态
>
> III：中断类型号也需要通过数据线传输

某总线采取菊链仲裁方式，则下列关于总线优先级的描述中，正确的是 。 

A．连接在该总线上的设备得到总线授权的优先级相同。

B．越靠近总线仲裁器的设备优先级越高。

C．越远离总线仲裁器的设备优先级越高。

D．响应速度越快的设备优先级越高。

> B
>
> 菊链仲裁采用链式询问，从最近的设备开始询问

（2019.1期末）

假定某计算机的CPU主频为1GHz、外接外设接口中有一个16位的数据缓存器， 中断服务程序的执行时间为500个时钟周期，则中断能够处理的最大传输带宽为

A.3MB/s	B.4MB/s	C.5MB/s	D.6MB/s

> B
>
> 1s内中断1G/500=2M次/s，16位=2B
>
> 一次中断可以传2B，故能处理的最大带宽为2M*2B=4MB/s

（2016.1复习题）

什么是总线？总线仲裁是什么？总线仲裁的两种方式为？

![image.png](https://cdn.nlark.com/yuque/0/2020/png/1458680/1607701155592-baf5e6b9-4944-4daa-ac49-837cdf10a0dd.png?x-oss-process=image%2Fresize%2Cw_346%2Climit_0)

> 总线是用于连接计算机多个子系统的共享的信息通道
>
> 总线仲裁是多个设备需要使用总线时，如何安排总线
>
> 总线仲裁的两种方式为**集中仲裁**（链式查询（菊链）、计数器定时查询、独立请求）和**分布仲裁**（自举分布式、冲突检测分布式、并行竞争分布式）

若某计算机有5级中断，中断响应优先级为1>2>3>4>5，而中断处理优先级为1>4>5>2>3。要求：（2016.1复习题）

（1）设计各级中断处理程序的中断屏蔽位（假设1为屏蔽，0为开放）； 

（2）若在运行主程序时，同时出现第2、4级中断请求，而在处理第2级中断过程中，又同时出现1、3、5级中断请求，试分析此程序的运行过程。

> |       | 1    | 2    | 3    | 4    | 5    |
> | ----- | ---- | ---- | ---- | ---- | ---- |
> | 中断1 | 1    | 1    | 1    | 1    | 1    |
> | 中断2 | 0    | 1    | 1    | 0    | 0    |
> | 中断3 | 0    | 0    | 1    | 0    | 0    |
> | 中断4 | 0    | 1    | 1    | 1    | 1    |
> | 中断5 | 0    | 1    | 1    | 0    | 1    |
>
> * **关中断**，在2、4中断中排队判优，根据中断*响应*优先级2>4，先响应2级中断：保护现场、保护就屏蔽字、设置新屏蔽字01100
> * **开中断**，由于中断*处理*优先级4>2，立即要响应4级中断，响应后立即处理，处理结束后才回到2级中断服务程序执行
> * 处理2级中断的过程中，发生1、3、5中断，其中3级中断被屏蔽，在1、5中断中排队判优，根据中断*响应*优先级1>5，先响应1级中断
> * 由于中断*处理*优先级1最高，响应1级中断后立即处理，处理结束后才回到2级中断服务程序执行
> * 由于中断*处理*优先级5>2，立即要响应5级中断，响应后立即处理，处理结束后才回到2级中断服务程序执行
> * 2级中断处理结束，返回用户程序
> * 随后开始处理3级中断

# 计算机网络

## 计算机网络体系结构

下列关于网络体系结构叙述错误的是（ ）（2012期末）

a. 计算机网络体系结构是协议的集合

b. 在分层模型中，上层只知道下层的服务，不知道实现

c. 网络体系结构中最广泛使用的是 TCP/IP 模型

d. 同层对等实体的信息交换规则成为协议

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1607253370003-8471f438-b7d2-4b5c-a9ba-51f6396f229b.png" alt="image.png" style="zoom:50%;" />

> A
>
> 是*层次*与*层间*关系的集合（协议只是同层）

分层网络体系结构中，N 层收到 N+1 层 SDU 之后的操作是（ ）（2012期末）

a. 加上 PCI，生成 PDU  

b. 剥除 PCI，生成 PDU  

c. 加上 ICI，生成 PDU  

d. 剥除 ICI，生成 PDU

![image.png](https://cdn.nlark.com/yuque/0/2020/png/1458680/1607254534025-1a123bb0-4274-4ba1-80d6-5edbb646f913.png?x-oss-process=image%2Fresize%2Cw_501%2Climit_0)

> A
>
> 物理层是最底层（Layer 1），应用层是最高层（Layer 5）
>
> S（service）DU：上层的服务单元；P（protocol）DU：下层的协议数据单元
>
> I（interface）CI：接口控制信息；P（protocol）CI：协议控制信息

## 物理层

（2018期末）

物理层四个特性

> 电机归公(doge)
>
> 电气、机械、规程、功能

（2012期末）

下列关于信道叙述错误的是：

a. 没记住  b. 没记住  c. 没记住

d. 信噪比 20dB 即为信号功率除以噪声功率等于 20。

> D
>
> $20dB=10log_{10}(S/N)$，经典30dB，信噪比是1000

定义物理层工作规程与时序的是物理层的哪个特性？

a. 电气特性  b. 机械特性  c. 规程特性  d. 功能特性

> C

## 数据链路层

（2018期末）

数据链路层的基本功能

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1607233158395-3bb986ad-2b20-4f4f-af59-c7ae7561e49c.png" alt="image.png" style="zoom:80%;" />

1-坚持、非坚持、p 坚持的含义

> 1-坚持：空闲则发，忙则监听，冲突随机等待
>
> 非坚持：空闲则发，忙则随机等待，冲突随机等待
>
> p坚持：空闲则p概率发，忙则等待下一个时槽，冲突随机等待

PPP 协议的特点

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1607234237377-21cbc8cb-8847-4e97-8920-7bcd1f601b18.png" alt="image.png" style="zoom: 80%;" />

10M 以太网的波特率

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1607234981917-070edbca-d73d-40aa-9c28-78941e2e5e7a.png" alt="image.png" style="zoom:67%;" />

> 标准10M802.3 LAN采用曼彻斯特编码，每个码元用2个不同相位的电平信号表示
>
> 10Mbps，信号每秒变化20M次，即波特率20M Baud

（2012期末）

下列关于交换技术叙述错误的是：

a. 电路交换在发送与接收方的物理链路上预留带宽

b. 虚电路交换的分组头部需要全局地址信息

c. 数据报交换可能出现分组乱序

d. 报文交换要求有较大缓存

> B

停等协议效率最低的是？

> 距离远，传输速率大，则信道利用率最低

后退 N 帧协议，发送了 0～7 号帧，发送方定时器超时时收到了 0，2，3 号 ACK，发送方需要重发几个帧？

a. 2    b. 3    c. 4    d. 5

> C
>
> GBN累计确认，选择重传“选择”

下列有关 PPP 协议叙述错误的是：

a. 动态分配 IP 地址

b. 面向比特的协议

c. 使用 NCP 协商

d. 支持身份认证

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1607236705113-e8c4c7f9-17c3-4625-965f-50b7209d23f6.png" alt="image.png" style="zoom: 80%;" />

> B
>
> PPP面向字符

先监听，若忙则等待随机一段时间在发送的是什么 MAC 层协议？

a. 四个选项都忘了……

> 非坚持CSMA

数据链路层提供的基本控制功能是？

a. 差错控制  b. 顺序控制  c. 流量控制  d. 拥塞控制

> A
>
> 顺序控制、流量控制可选，没有拥塞控制

使用位填充方法，以 01111110 为位首 flag，数据为 011011111111111111110010，求问传送时要添加几个 0？

a. 1    b. 2    c. 3    d. 4

> C
>
> 位填充“5110”
>
> 0110 11111*0* 11111*0* 11111*0* 10010

10001001 与 10110101 的海明距离？

> 10*0010*01
>
> 10*1101*01
>
> 海明距离为4

在 802.3 标准中，发送帧之前需要：

a. 等待冲突  b. 等待令牌  c. 监听介质  d. 接受一个帧

> C
>
> 802.3是采用CSMA/CD的局域网
>
> CSMA协议规定站点在为发送帧而访问传输信道之前，首先要监听信道有无*载波*

下列有关无线局域网的叙述，错误的是：

a. 实现了载波监听

b. 冲突被发送站发现

c. 使用 MACA 机制

d. 某时刻信道有多个有效数据帧

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1607237570016-13c55d4c-8227-4011-ae3a-7b9787bcf70a.png" alt="image.png" style="zoom:80%;" />

> B
>
> CSMA是发送站发现冲突，于是有1/非/p坚持；无线局域网是接收站发现冲突

10Base-T 以太网的最大网段距离：

a. 2000m    b. 500m    c. 200m  d. 100m

![image.png](https://cdn.nlark.com/yuque/0/2020/png/1458680/1607238279362-aa2f2045-6848-4bce-a19e-e2689bd3dc8d.png?x-oss-process=image%2Fresize%2Cw_526%2Climit_0)

> D
>
> 10Base-n：$100n$ 米的电缆
>
> 10Base-T：$100$ 米的双绞线
>
> 10Base-F：$2000$ 米的光纤

能从 MAC 地址解析出 IP 地址的协议是？

a. ICMP    b. PPP    c. ARP    d. RARP

> 

（2013期末）

以太网的最大最小帧长，为什么要有？

> 以太网的最大帧长为 1500 字节，其存在的原因是：
>
> - 如果帧长过长，会造成接收端的*缓存溢出*，发生错误；
> - 由于以太网是多个主机共享媒介信道，如果帧长过长，也将导致某一主机*占据信道过久，不公平*。 
>
> 以太网的最小帧长需根据实际往返时间而定，一般至少为 46 字节。
>
> - 如果帧长过短，会导致在 CSMA/CD 中*无法检测出碰撞*，所以要求发送帧的最短时间 TXT 要*大于*链路最大的往返时间 *RTT*，根据链路的带宽，可计算出最小帧长

802.3 和 802.11 协议的异同

>802.3 链路层*以太网*的协议，802.11 为*无线*局域网中的协议。 
>
>相同点：
>
>- 两者均是链路层*局域网*标准，都是基于 *MAC* 地址寻址的。在多路访问中，均采用了*载波侦听 CSMA* 的形式。 
>
>不同点： 
>
>- 802.3 是基于有线网络，而 802.11 是基于无线网络。 
>
>- 在多路访问中，802.3 提供了 CD *碰撞检测*机制，检测到碰撞后随机回退；802.11 提供了CA *碰撞避免*机制。 
>
>- 在 802.11 中，由于无线信道衰减强切易受干扰，所以还提供了链路层*确认/重传 ARQ* 机制，提供可靠的连接服务；在 802.3 中只是检测帧是否损坏，属于*不可靠*的无连接服务。 
>
>- 802.3 是基于以太网帧，有*两个* MAC 地址；802.11 是基于 802.11 帧，*三个* MAC 地址机制。

Rdt3.0 提供了哪些可靠的服务？

> ① 校验和位差检测，错误重传 
>
> ② 丢弃冗余数据 
>
> ③ 允许 ACK 出错、重复分组，设置序号 
>
> ④ 允许数据丢失，设置超时时间，超时重传 

循环冗余检测，给定 D=1010101010，G=10011， 求 R 

![image.png](https://cdn.nlark.com/yuque/0/2020/png/1458680/1608210069301-2ce3be39-2d58-47fe-bf50-a786eae2da17.png?x-oss-process=image%2Fresize%2Cw_362%2Climit_0)

> 注意G是4阶，R是4位

（2018期末）

请比较一下在一个电路交换网络中和在一个（负载较轻的）分组交换网络中，沿着k跳的路径发送一个x位消息的延迟情况。电路建立的时间为s秒，每一跳的传播延迟为d秒，分组的大小为p位，数据传输率为b bps。在什么条件下分组网络的延迟比较短？

> （计算传播延迟时，计算“第一个字节发出到第一个字节收到的延迟”，分组交换每经过一个路由器，延迟 $+\dfrac pb$ ）
>
> 电路交换：$s+\dfrac xb+kd$
>
> 分组交换：$\dfrac xb+(k-1)\dfrac pb+kd$
>
> $s>\dfrac{(k-1)p}b$

假定x位用户数据将以一系列分组的形式，在一个分组交换网络中沿着一条共有k跳的路径向前传输，每个分组包含p位数据和h位的头，这里x>>p+h。线路的传输率为b bps，传播延迟忽略不计。请问，什么样的p值使总延迟最小？

> 总时间：$\dfrac{(p+h)x}{pb}+(k-1)\dfrac{p+h}b$
>
> 延迟最小，$p=\sqrt{\dfrac{hx}{k-1}}$

## 网络层

（2018期末）

IP、ARP 协议的特点：

IPV4 和 IPV6 都只对头部校验？

ARP 解析的总是默认网关？

> IPV4只对IP分组头校验，IPV6本身不校验，依赖高层的协议来完成，以免去校验带来的延迟
>
> ARP解析：若目标主机在同一子网内，则用目的地址的IP在ARP表内查找；若不在，则用缺省网关的IP在ARP表内查找

交换方式中哪些属于存储转发

> 分组、报文

（2012期末）

下列关于网络体系结构叙述错误的是：

a. 计算机网络体系结构是协议的集合

b. 在分层模型中，上层只知道下层的服务，不知道实现

c. 网络体系结构中最广泛使用的是 TCP/IP 模型

d. 同层对等实体的信息交换规则成为协议。

> A

一个 1300 字节的 IP 包，包头长度为 20 字节，进入一个 MTU 为 500 的网络中。（2018期末）

 A. 分成三段，偏移量为 0,460,920；

 B. 分成三段，偏移量为 0,480,960；

 C. 分成三段，偏移量为 0,500,1000；

 D. 都不对

> B
>
> 不要除以8吗（

能从 MAC 地址解析出 IP 地址的协议是（ ）（2012期末）

a. ICMP      b. PPP      c. ARP       d. RARP

> D
>
> ARP是将IP映射到MAC，RARP是反向地址解析协议

分层网络体系结构中，N 层收到 N+1 层 SDU 之后的操作是：

a. 加上 PCI，生成 PDU  

b. 剥除 PCI，生成 PDU  

c. 加上 ICI，生成 PDU  

d. 剥除 ICI，生成 PDU

> A

90 字节的 IP 分组封装到以太网中，需要填充多少个字节？

a. 38    b. 10    c. 6    d. 0

> D
>
> 以太网最小帧长46字节，不需要填充

ICMP 属于哪层协议？

a. 数据链路层  b. 网络层  c. 传输层  d. 应用层

> B
>
> 因特网控制报文协议ICMP，网络层，差错报告，如ICMP响应报文、ICMP目标不可达报文等

子网掩码 255.255.248.0，可用最大 IP 数是多少？

> 2^11^=2048，减去全0全1，可用2046

（2013期末）

IPv6 和 IPv4 的区别？前者的偏移地址是多少位？报头格式？

![img](https://cdn.nlark.com/yuque/0/2020/png/1458680/1602425792202-52a2ccc1-2c0e-440a-8405-84b8cfa86ff0.png?x-oss-process=image%2Fresize%2Cw_1300%2Fresize%2Cw_640%2Climit_0)

![image.png](https://cdn.nlark.com/yuque/0/2020/png/1458680/1607257169279-bfff75f7-3ecc-4750-b6f7-66cbb2bb90c8.png?x-oss-process=image%2Fresize%2Cw_613%2Climit_0)

> 区别：
>
> * IPV6有128位，IPV4有32位
> * IPv6 层次化分配 IP 地址，地址空间较大
> * IPv6 的报头长度固定为 40 字节，IPv4 报头长度一般为 20 字节，但不固定，可能达到 60 字节
> * IPv6 没有 checksum，没有分片机制，而是增加了优先级域和流标记域来保证服务质量
>
> 偏移：IPv6 的偏移地址没有，IPv4 的偏移地址为 13 位
>
> 报头格式：IPv6 的报头长度固定为 40 字节，IPv4 报头长度一般为 20 字节，但不固定，可能达到 60 字节

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1607256619477-e8804a1c-f4a6-43c9-9270-1da8a6d7c96d.png" alt="image.png" style="zoom: 67%;" />

（2018期末）

如图所示，5台路由器组成全相连的网络，每台路由器有5个接口，分别连接其它4台路由器和1个局域网，每个局域网最多连接20台计算机，每台计算机分配1个IP地址。如果只有一个IPv4地址块202.112.10.0/24可供分配，请给出一种合理的地址分配方案，分别给出每个局域网的地址空间和路由器每个端口的地址以及它们的掩码。

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1604407170063-3b906034-95a3-4a88-b32c-d21b8cd3b2ae.png" alt="img" style="zoom: 67%;" />

> <img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1608212302406-619f19a1-eec1-4004-b911-dccdc55a307e.png" alt="image.png" style="zoom:50%;" />
>
> 路由器每个端口：0~3只是一条链路的4个IP，共10个链路都需要分配。子网只要四个IP，掩码只要留出最后两位
>
> <img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1608212311687-b4236d76-ac84-4e0e-881d-11235b281abc.png" alt="image.png" style="zoom:50%;" />
>
> 局域网地址空间，掩码留出5位

 假设主机A被连接到一台路由器R1上，R1又连接到另一台路由器R2上，R2被连接到主机B。假定一条TCP消息包含900字节的数据和20字节的TCP头，现在该消息被传递给主机A的IP地址，请它递交给主机B。请写出在三条链路上传输的每个分组中IP头部的Total length，Identification，DF，MF和Fragment offset域。假定链路A-R1可以支持的最大帧长度为1024字节，其中包括14字节帧头；链路R1-R2可以支持最大帧长度为512字节，其中包括8字节的帧头；链路R2-B可以支持的最大帧长度为512字节，其中包括12字节帧头。

> 在路由器之间传递，要TCP头+IP头，共+40
>
> 分片的话，分出来的片都要+20的IP头，即480+20和440+20

![image.png](https://cdn.nlark.com/yuque/0/2020/png/1458680/1608212912884-b7334d49-127e-4fbd-a895-27284060c997.png?x-oss-process=image%2Fresize%2Cw_637%2Climit_0)

## 传输层

（2018期末）

面向连接和面向无连接服务的含义

> 面向连接的服务：当使用服务器传输数据时，首先建立连接，然后使用该连接传送数据。使用完后，关闭连接（顺序性好）
>
> 无连接服务：直接使用服务传输数据，每个包独立地进行路由选择（顺序性差）
>
> 注意，连接本身不意味着可靠

服务原语的四种类型

> 请求、指示（指示状态等）、响应、确认

滑动窗口协议中，若窗口序号由 4 位表示，发送窗口与接受窗口大小相同，则发送窗口最大多大

> 滑动窗口2^4^/2=8

HTTP1.0 中，传输一个文本和三个图片需要建立多少 TCP 连接



一个 TCP 段在 IP 层传输时分成两个包，长度分别为 500，480，问 TCP 段原来长度  

给出子网掩码，问能容纳多少主机



（2012期末）

TCP 端对端通信作用于：

a. 主机之间  b. 网络之间  c. 进程之间  d. 主机到网络

> C

TCP 使用滑动窗口协议实现：

a. 端到端流量控制

b. 全网控制

c. 端到端流量和拥塞控制

d. 差错控制

> C
>
> 包括流量、拥塞两个

对于传输层来说错误的是：

a. TCP 是全双工协议

b. TCP 是字节流协议

c. TCP 和 UDP 协议不能使用同一个端口

d. TSAD 是 IP 和端口的组合

> C
>
> 1. tcp的端口不是物理概念，仅仅是协议栈中的两个字节
> 2. TCP和UDP的端口完全没有任何关系
> 3. TCP和UDP传输协议监听同一个端口后，接收数据互不影响，不冲突，因为数据接收时是根据五元组 {传输协议，源IP，目的IP，源端口，目的端口} 判断接收者的

对于 UDP 协议，如果想实现可靠传输，应在那一层实现？

a. 数据链路层  b. 网络层  c. 传输层  d. 应用层

> D
>
> 传输层无法保证，就只能通过应用层，在其中依旧可以实现类似TCP的确认机制、重传机制、窗口确认机制

TCP 使用慢启动算法，为了

a. 减小拥堵

b. 高速传输

c. 快速探测网络承载力

d. 适应接收窗口的大小

> C

（2013期末）

N=4，编号为 0，1，2，3，…，10，发送几个分组的时延为 2RTT，定时重传时延为 0.4RTT.  

1.GBN：只有分组 2 在发送时丢失，求接下来 N 个发送分组的编号

2.SR：只有分组 2 在发送时丢失，求接下来 N 个发送分组的编号

3.TCP RENO 发送 0 丢失后，估算下一次重发的时间，写出两个编号

![img](https://pic3.zhimg.com/80/v2-de79bf2c38bddb0c1caf5768577648e2_720w.webp)

> TCP RENO有快速恢复，Tahoe没有

HTML 文件，大小为 10kBYTEs；还有 10 个 1kBYTEs 的图片。链路带宽为 10Mbps。  

1.非持久 HTTP 响应时间

2.非持久、5 个并行 TCP 响应时间

3.带流水线

> 

（2018期末）

在滑动窗口协议中，序号位数为 n 位，问当接收窗口大小分别为 1 和 Wr 时，发送窗口的最大大小为多少？给出结论并证明之。

A、B双方已经建立了TCP连接，初始阈值为32K字节(1K = 1024)，最大发送段长MSS为1K字节。发送方向为A->B, B没有数据要发送, B每收到一个数据段都会发出一个应答段。在整个过程中上层一直有数据要发送, 并且都以MSS大小的段发送。A的发送序列号从0开始。

1.在传输过程中, A收到1个ACK为10240的数据段，收到这个应答段后, A处拥塞窗口的大小是多少？

2.当收到ACK为32768的数据段后，A处拥塞窗口的大小是多少？

3.当阈值为32K字节、拥塞窗口为40K字节时, 发送方发生了超时，求超时发生后拥塞窗口的大小和阈值的大小。

> ![image.png](https://cdn.nlark.com/yuque/0/2020/png/1458680/1608213101325-24af49ce-24d7-419f-9552-cd9153f2467a.png?x-oss-process=image%2Fresize%2Cw_441%2Climit_0)<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1608213115945-66386a87-bbcf-4a1f-9848-d01f3d4ff4ed.png" alt="image.png" style="zoom: 67%;" />
>
> 窗口40K的时候超时，阈值就减为20K
>
> 重新开始慢启动，拥塞窗口1K（3个重复ACK执行快重传，而超时是一个ACK都没收到，说明拥塞更严重，需要直接慢启动）

## 应用层

（2018期末）

SMTP 的功能，SNMP 协议中哪个是服务器，哪个是客户端

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1607265581887-5db84893-e7a6-49e8-aa0e-e19b8a844a10.png?x-oss-process=image%2Fresize%2Cw_441%2Climit_0" alt="image.png" style="zoom:150%;" />

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1607265611267-f68b785b-bdb4-4f01-b690-8349274b11d3.png?x-oss-process=image%2Fresize%2Cw_426%2Climit_0" alt="image.png" style="zoom:150%;" />

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1607265623910-cf421adf-f58b-4071-9478-2cd2cc63b9e2.png" alt="image.png" style="zoom:80%;" />

> SMTP是一组用于从源地址到目的地址传送邮件的规则，并且控制信件的中转方式。
>
> SMTP协议属于TCP/IP协议族，它帮助每台计算机在发送或中转信件时找到下一个目的地。
>
> 通过SMTP协议所指定的服务器，我们就可以把E—mail寄到收信人的服务器上了，整个过程只需要几分钟。
>
> SMTP服务器是遵循SMTP协议的发送邮件服务器，用来发送或中转用户发出的电子邮件。

SMTP协议用来( A )；DNS服务器( B )（2007期末）

 A：1.从邮件服务器向用户代理传送信报；2.在邮件服务器间传送信报；3.只定义信报头的格式；4.以上都是

 B：1.通过Web Cache获取资源记录；2.缓存资源记录，并且永不删除；3.不缓存资源记录；4.缓存资源记录，但是经过一段时间后删除；

> A：2	B：4

SMTP封装在哪个协议中？（2007）

A.TCP    B.UDP   C.ICMP   D.IGMP

> A

（2012期末）

 HTTP1.0 协议是：

a. 非坚持，得到一个对象需要一个 RTT  

b. 非坚持，得到一个对象需要 两个 RTT  

c. 坚持，得到一个对象需要一个 RTT  

d. 坚持，得到一个对象需要两个 RTT

> B

HTTP1.0 中，传输一个文本和三个图片需要建立多少 TCP 连接（2018期末）

![image.png](https://cdn.nlark.com/yuque/0/2020/png/1458680/1607258491390-a160bce9-df00-4966-9842-472abd63309a.png?x-oss-process=image%2Fresize%2Cw_346%2Climit_0)

> 1+3=4

对于 EMAIL 下列说法正确的是：

a. 收发均使用 SMTP 协议

b. 发送使用 SMTP 协议，接收使用 POP3/IMAP 协议

c. 发送使用 POP3 协议，接收使用 SMTP 协议

d. 发送和接收均使用 POP3 协议

> B

邮件有关的 4 个协议 （2011期末）

> SMTP	POP3	IMAP	HTTP

SNMP网络管理模型中，被管理站点进行SNMP代理程序，是( A )端，每个被管理站点使用多个变量描述自己的状态，这些变量称为( B )，这些( B )用( C )定义（2002期末）

 A：1.客户；2.服务器；3.对等

 B：1.状态；2.资源；3.信息；4.对象

 C：1.ASN；2.BER；3.TTCN；4.C语言

<img src="https://cdn.nlark.com/yuque/0/2020/png/1458680/1607266510540-3a746ea5-2a9d-49fe-955b-2a5331927975.png?x-oss-process=image%2Fresize%2Cw_692%2Climit_0" alt="image.png" style="zoom:120%;" />

> SNMP：简单网络管理协议
>
> NMP网络管理模型中，被管理站点进行SNMP代理程序，是( 服务器 )端，每个被管理站点使用多个变量描述自己的状态，这些变量称为( 对象 )，这些( 对象 )用( ASN )定义。

SNMP，被管理的机器是(客户|服务器)。（2001期末）

> 被管理的是服务器

SNMP 协议中哪个是服务器，哪个是客户端（2018期末）

> SNMP中被管理的机器是服务器，管理工作站是客户端。

SNMP，被管理（必须/不必须）运行用户代理，主动发报告叫做（MIB/trap）（2007期末）

> 必须	trap

（2013期末）

主机访问 www.sina.com 所需用到的协议

> 应用层：DNS 将服务器主机名解析成 IP 地址；HTTP 协议实现超文本的传输，是 Web 的应用层协议
>
> 传输层：UDP（DNS）、TCP（HTTP）
>
> 网络层：IP 在网络层将数据报交付给服务器主机
>
> 数据链路层：ARP 将 IP 地址解析为 MAC 地址（ARP 严格来说，介于数据链路层与网络层之间，属于 TCP/IP 协议簇）

（2018期末）

给一个 URL：http://info.tsinghua.edu.cn:80/index.jsp

1、说出这个 URL 各个组成部分

> 协议：http
>
> 主机：info.tsinghua.edu.cn
>
> 顶级域名：cn
>
> 端口：80
>
> 路径或文件：/index.jsp

2、一般来说，在浏览器里输入 http://info.tsinghua.edu.cn:80/index.jsp 跟输入 http://166.111.4.98:80/index.jsp 看到的是一样的。

（1）如果输前者能打开，后者打不开，这可能是什么原因？

> IP地址被多个站点共享/站点禁止IP直接访问

（2）如果输前者打不开，后者能打开，这可能是什么原因？

> DNS域名解析出错